2024-07-03 14:14:39,567:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:14:39,567:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:14:39,567:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:14:39,567:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:14:39,671:INFO:PyCaret ClassificationExperiment
2024-07-03 14:14:39,671:INFO:Logging name: clf-default-name
2024-07-03 14:14:39,671:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-03 14:14:39,671:INFO:version 3.3.2
2024-07-03 14:14:39,671:INFO:Initializing setup()
2024-07-03 14:14:39,671:INFO:self.USI: d4c2
2024-07-03 14:14:39,671:INFO:self._variable_keys: {'gpu_param', 'memory', '_available_plots', 'log_plots_param', 'logging_param', 'exp_name_log', 'n_jobs_param', 'seed', 'X_train', 'fold_generator', 'y_test', 'exp_id', 'fold_groups_param', 'idx', 'y', 'pipeline', 'data', 'html_param', 'fold_shuffle_param', 'target_param', 'is_multiclass', 'gpu_n_jobs_param', 'fix_imbalance', '_ml_usecase', 'X', 'X_test', 'y_train', 'USI'}
2024-07-03 14:14:39,671:INFO:Checking environment
2024-07-03 14:14:39,671:INFO:python_version: 3.11.9
2024-07-03 14:14:39,671:INFO:python_build: ('main', 'May 22 2024 17:28:32')
2024-07-03 14:14:39,671:INFO:machine: x86_64
2024-07-03 14:14:39,671:INFO:platform: Linux-6.1.0-22-amd64-x86_64-with-glibc2.36
2024-07-03 14:14:39,672:INFO:Memory: svmem(total=67150065664, available=62076694528, percent=7.6, used=3941269504, free=53539135488, active=2871955456, inactive=9333194752, buffers=431366144, cached=9238294528, shared=385851392, slab=758431744)
2024-07-03 14:14:39,672:INFO:Physical Core: 6
2024-07-03 14:14:39,672:INFO:Logical Core: 12
2024-07-03 14:14:39,672:INFO:Checking libraries
2024-07-03 14:14:39,672:INFO:System:
2024-07-03 14:14:39,672:INFO:    python: 3.11.9 (main, May 22 2024, 17:28:32) [GCC 12.2.0]
2024-07-03 14:14:39,672:INFO:executable: /home/yht/.pyenv/versions/3.11.9/envs/kaggle/bin/python
2024-07-03 14:14:39,672:INFO:   machine: Linux-6.1.0-22-amd64-x86_64-with-glibc2.36
2024-07-03 14:14:39,672:INFO:PyCaret required dependencies:
2024-07-03 14:14:39,687:INFO:                 pip: 24.1.1
2024-07-03 14:14:39,687:INFO:          setuptools: 65.5.0
2024-07-03 14:14:39,687:INFO:             pycaret: 3.3.2
2024-07-03 14:14:39,687:INFO:             IPython: 8.26.0
2024-07-03 14:14:39,687:INFO:          ipywidgets: 8.1.3
2024-07-03 14:14:39,687:INFO:                tqdm: 4.66.4
2024-07-03 14:14:39,687:INFO:               numpy: 1.26.4
2024-07-03 14:14:39,687:INFO:              pandas: 2.1.4
2024-07-03 14:14:39,687:INFO:              jinja2: 3.1.4
2024-07-03 14:14:39,687:INFO:               scipy: 1.11.4
2024-07-03 14:14:39,687:INFO:              joblib: 1.3.2
2024-07-03 14:14:39,687:INFO:             sklearn: 1.4.2
2024-07-03 14:14:39,687:INFO:                pyod: 2.0.1
2024-07-03 14:14:39,687:INFO:            imblearn: 0.12.3
2024-07-03 14:14:39,687:INFO:   category_encoders: 2.6.3
2024-07-03 14:14:39,687:INFO:            lightgbm: 4.4.0
2024-07-03 14:14:39,687:INFO:               numba: 0.60.0
2024-07-03 14:14:39,687:INFO:            requests: 2.32.3
2024-07-03 14:14:39,687:INFO:          matplotlib: 3.7.5
2024-07-03 14:14:39,687:INFO:          scikitplot: 0.3.7
2024-07-03 14:14:39,687:INFO:         yellowbrick: 1.5
2024-07-03 14:14:39,687:INFO:              plotly: 5.22.0
2024-07-03 14:14:39,687:INFO:    plotly-resampler: Not installed
2024-07-03 14:14:39,687:INFO:             kaleido: 0.2.1
2024-07-03 14:14:39,687:INFO:           schemdraw: 0.15
2024-07-03 14:14:39,687:INFO:         statsmodels: 0.14.2
2024-07-03 14:14:39,687:INFO:              sktime: 0.26.0
2024-07-03 14:14:39,687:INFO:               tbats: 1.1.3
2024-07-03 14:14:39,687:INFO:            pmdarima: 2.0.4
2024-07-03 14:14:39,687:INFO:              psutil: 6.0.0
2024-07-03 14:14:39,687:INFO:          markupsafe: 2.1.5
2024-07-03 14:14:39,687:INFO:             pickle5: Not installed
2024-07-03 14:14:39,687:INFO:         cloudpickle: 3.0.0
2024-07-03 14:14:39,687:INFO:         deprecation: 2.1.0
2024-07-03 14:14:39,687:INFO:              xxhash: 3.4.1
2024-07-03 14:14:39,687:INFO:           wurlitzer: 3.1.1
2024-07-03 14:14:39,687:INFO:PyCaret optional dependencies:
2024-07-03 14:14:39,699:INFO:                shap: Not installed
2024-07-03 14:14:39,699:INFO:           interpret: Not installed
2024-07-03 14:14:39,699:INFO:                umap: Not installed
2024-07-03 14:14:39,699:INFO:     ydata_profiling: Not installed
2024-07-03 14:14:39,699:INFO:  explainerdashboard: Not installed
2024-07-03 14:14:39,699:INFO:             autoviz: Not installed
2024-07-03 14:14:39,699:INFO:           fairlearn: Not installed
2024-07-03 14:14:39,699:INFO:          deepchecks: Not installed
2024-07-03 14:14:39,699:INFO:             xgboost: Not installed
2024-07-03 14:14:39,699:INFO:            catboost: Not installed
2024-07-03 14:14:39,699:INFO:              kmodes: Not installed
2024-07-03 14:14:39,699:INFO:             mlxtend: Not installed
2024-07-03 14:14:39,699:INFO:       statsforecast: Not installed
2024-07-03 14:14:39,699:INFO:        tune_sklearn: Not installed
2024-07-03 14:14:39,699:INFO:                 ray: Not installed
2024-07-03 14:14:39,699:INFO:            hyperopt: Not installed
2024-07-03 14:14:39,699:INFO:              optuna: Not installed
2024-07-03 14:14:39,699:INFO:               skopt: Not installed
2024-07-03 14:14:39,699:INFO:              mlflow: Not installed
2024-07-03 14:14:39,699:INFO:              gradio: Not installed
2024-07-03 14:14:39,699:INFO:             fastapi: Not installed
2024-07-03 14:14:39,699:INFO:             uvicorn: Not installed
2024-07-03 14:14:39,699:INFO:              m2cgen: Not installed
2024-07-03 14:14:39,699:INFO:           evidently: Not installed
2024-07-03 14:14:39,699:INFO:               fugue: Not installed
2024-07-03 14:14:39,699:INFO:           streamlit: Not installed
2024-07-03 14:14:39,699:INFO:             prophet: Not installed
2024-07-03 14:14:39,699:INFO:None
2024-07-03 14:14:39,699:INFO:Set up data.
2024-07-03 14:14:39,703:INFO:Set up folding strategy.
2024-07-03 14:14:39,703:INFO:Set up train/test split.
2024-07-03 14:14:39,709:INFO:Set up index.
2024-07-03 14:14:39,709:INFO:Assigning column types.
2024-07-03 14:14:39,712:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-03 14:14:39,745:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-03 14:14:39,747:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 14:14:39,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:14:39,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:14:39,802:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-03 14:14:39,803:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 14:14:39,823:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:14:39,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:14:39,823:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-03 14:14:39,856:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 14:14:39,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:14:39,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:14:39,908:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 14:14:39,927:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:14:39,927:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:14:39,927:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-03 14:14:39,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:14:39,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:14:40,030:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:14:40,030:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:14:40,031:INFO:Preparing preprocessing pipeline...
2024-07-03 14:14:40,032:INFO:Set up simple imputation.
2024-07-03 14:14:40,048:INFO:Finished creating preprocessing pipeline.
2024-07-03 14:14:40,051:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-03 14:14:40,051:INFO:Creating final display dataframe.
2024-07-03 14:14:40,105:INFO:Setup _display_container:                     Description             Value
0                    Session id              8888
1                        Target       Transported
2                   Target type            Binary
3           Original data shape        (8693, 11)
4        Transformed data shape        (8693, 11)
5   Transformed train set shape        (6085, 11)
6    Transformed test set shape        (2608, 11)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              d4c2
2024-07-03 14:14:40,168:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:14:40,168:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:14:40,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:14:40,223:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:14:40,224:INFO:setup() successfully completed in 0.55s...............
2024-07-03 14:14:59,811:INFO:Initializing compare_models()
2024-07-03 14:14:59,812:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f87c3556350>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f87c3556350>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-03 14:14:59,812:INFO:Checking exceptions
2024-07-03 14:14:59,817:INFO:Preparing display monitor
2024-07-03 14:14:59,835:INFO:Initializing Logistic Regression
2024-07-03 14:14:59,835:INFO:Total runtime is 1.3192494710286458e-06 minutes
2024-07-03 14:14:59,837:INFO:SubProcess create_model() called ==================================
2024-07-03 14:14:59,838:INFO:Initializing create_model()
2024-07-03 14:14:59,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f87c3556350>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f87c0a2f490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:14:59,838:INFO:Checking exceptions
2024-07-03 14:14:59,838:INFO:Importing libraries
2024-07-03 14:14:59,838:INFO:Copying training dataset
2024-07-03 14:14:59,842:INFO:Defining folds
2024-07-03 14:14:59,843:INFO:Declaring metric variables
2024-07-03 14:14:59,845:INFO:Importing untrained model
2024-07-03 14:14:59,847:INFO:Logistic Regression Imported successfully
2024-07-03 14:14:59,851:INFO:Starting cross validation
2024-07-03 14:14:59,852:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:15:02,668:INFO:Calculating mean and std
2024-07-03 14:15:02,669:INFO:Creating metrics dataframe
2024-07-03 14:15:02,673:INFO:Uploading results into container
2024-07-03 14:15:02,674:INFO:Uploading model into container now
2024-07-03 14:15:02,674:INFO:_master_model_container: 1
2024-07-03 14:15:02,674:INFO:_display_container: 2
2024-07-03 14:15:02,675:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8888, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-03 14:15:02,675:INFO:create_model() successfully completed......................................
2024-07-03 14:15:02,762:INFO:SubProcess create_model() end ==================================
2024-07-03 14:15:02,762:INFO:Creating metrics dataframe
2024-07-03 14:15:02,767:INFO:Initializing K Neighbors Classifier
2024-07-03 14:15:02,767:INFO:Total runtime is 0.048868008454640705 minutes
2024-07-03 14:15:02,769:INFO:SubProcess create_model() called ==================================
2024-07-03 14:15:02,770:INFO:Initializing create_model()
2024-07-03 14:15:02,770:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f87c3556350>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f87c0a2f490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:15:02,770:INFO:Checking exceptions
2024-07-03 14:15:02,770:INFO:Importing libraries
2024-07-03 14:15:02,770:INFO:Copying training dataset
2024-07-03 14:15:02,777:INFO:Defining folds
2024-07-03 14:15:02,777:INFO:Declaring metric variables
2024-07-03 14:15:02,780:INFO:Importing untrained model
2024-07-03 14:15:02,784:INFO:K Neighbors Classifier Imported successfully
2024-07-03 14:15:02,790:INFO:Starting cross validation
2024-07-03 14:15:02,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:15:03,968:INFO:Calculating mean and std
2024-07-03 14:15:03,969:INFO:Creating metrics dataframe
2024-07-03 14:15:03,970:INFO:Uploading results into container
2024-07-03 14:15:03,971:INFO:Uploading model into container now
2024-07-03 14:15:03,971:INFO:_master_model_container: 2
2024-07-03 14:15:03,971:INFO:_display_container: 2
2024-07-03 14:15:03,971:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-03 14:15:03,971:INFO:create_model() successfully completed......................................
2024-07-03 14:15:04,052:INFO:SubProcess create_model() end ==================================
2024-07-03 14:15:04,052:INFO:Creating metrics dataframe
2024-07-03 14:15:04,057:INFO:Initializing Naive Bayes
2024-07-03 14:15:04,057:INFO:Total runtime is 0.0703702171643575 minutes
2024-07-03 14:15:04,059:INFO:SubProcess create_model() called ==================================
2024-07-03 14:15:04,060:INFO:Initializing create_model()
2024-07-03 14:15:04,060:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f87c3556350>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f87c0a2f490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:15:04,060:INFO:Checking exceptions
2024-07-03 14:15:04,060:INFO:Importing libraries
2024-07-03 14:15:04,060:INFO:Copying training dataset
2024-07-03 14:15:04,065:INFO:Defining folds
2024-07-03 14:15:04,065:INFO:Declaring metric variables
2024-07-03 14:15:04,068:INFO:Importing untrained model
2024-07-03 14:15:04,070:INFO:Naive Bayes Imported successfully
2024-07-03 14:15:04,076:INFO:Starting cross validation
2024-07-03 14:15:04,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:15:04,156:INFO:Calculating mean and std
2024-07-03 14:15:04,157:INFO:Creating metrics dataframe
2024-07-03 14:15:04,159:INFO:Uploading results into container
2024-07-03 14:15:04,159:INFO:Uploading model into container now
2024-07-03 14:15:04,159:INFO:_master_model_container: 3
2024-07-03 14:15:04,159:INFO:_display_container: 2
2024-07-03 14:15:04,160:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-03 14:15:04,160:INFO:create_model() successfully completed......................................
2024-07-03 14:15:04,232:INFO:SubProcess create_model() end ==================================
2024-07-03 14:15:04,233:INFO:Creating metrics dataframe
2024-07-03 14:15:04,238:INFO:Initializing Decision Tree Classifier
2024-07-03 14:15:04,238:INFO:Total runtime is 0.0733825127283732 minutes
2024-07-03 14:15:04,240:INFO:SubProcess create_model() called ==================================
2024-07-03 14:15:04,240:INFO:Initializing create_model()
2024-07-03 14:15:04,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f87c3556350>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f87c0a2f490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:15:04,241:INFO:Checking exceptions
2024-07-03 14:15:04,241:INFO:Importing libraries
2024-07-03 14:15:04,241:INFO:Copying training dataset
2024-07-03 14:15:04,246:INFO:Defining folds
2024-07-03 14:15:04,246:INFO:Declaring metric variables
2024-07-03 14:15:04,249:INFO:Importing untrained model
2024-07-03 14:15:04,252:INFO:Decision Tree Classifier Imported successfully
2024-07-03 14:15:04,256:INFO:Starting cross validation
2024-07-03 14:15:04,257:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:15:04,366:INFO:Calculating mean and std
2024-07-03 14:15:04,367:INFO:Creating metrics dataframe
2024-07-03 14:15:04,368:INFO:Uploading results into container
2024-07-03 14:15:04,369:INFO:Uploading model into container now
2024-07-03 14:15:04,369:INFO:_master_model_container: 4
2024-07-03 14:15:04,369:INFO:_display_container: 2
2024-07-03 14:15:04,369:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8888, splitter='best')
2024-07-03 14:15:04,369:INFO:create_model() successfully completed......................................
2024-07-03 14:15:04,441:INFO:SubProcess create_model() end ==================================
2024-07-03 14:15:04,441:INFO:Creating metrics dataframe
2024-07-03 14:15:04,447:INFO:Initializing SVM - Linear Kernel
2024-07-03 14:15:04,447:INFO:Total runtime is 0.07686776717503865 minutes
2024-07-03 14:15:04,450:INFO:SubProcess create_model() called ==================================
2024-07-03 14:15:04,451:INFO:Initializing create_model()
2024-07-03 14:15:04,451:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f87c3556350>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f87c0a2f490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:15:04,451:INFO:Checking exceptions
2024-07-03 14:15:04,451:INFO:Importing libraries
2024-07-03 14:15:04,451:INFO:Copying training dataset
2024-07-03 14:15:04,456:INFO:Defining folds
2024-07-03 14:15:04,456:INFO:Declaring metric variables
2024-07-03 14:15:04,458:INFO:Importing untrained model
2024-07-03 14:15:04,461:INFO:SVM - Linear Kernel Imported successfully
2024-07-03 14:15:04,468:INFO:Starting cross validation
2024-07-03 14:15:04,469:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:15:04,568:INFO:Calculating mean and std
2024-07-03 14:15:04,569:INFO:Creating metrics dataframe
2024-07-03 14:15:04,570:INFO:Uploading results into container
2024-07-03 14:15:04,570:INFO:Uploading model into container now
2024-07-03 14:15:04,571:INFO:_master_model_container: 5
2024-07-03 14:15:04,571:INFO:_display_container: 2
2024-07-03 14:15:04,571:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8888, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-03 14:15:04,571:INFO:create_model() successfully completed......................................
2024-07-03 14:15:04,645:INFO:SubProcess create_model() end ==================================
2024-07-03 14:15:04,645:INFO:Creating metrics dataframe
2024-07-03 14:15:04,651:INFO:Initializing Ridge Classifier
2024-07-03 14:15:04,651:INFO:Total runtime is 0.08027103741963704 minutes
2024-07-03 14:15:04,654:INFO:SubProcess create_model() called ==================================
2024-07-03 14:15:04,654:INFO:Initializing create_model()
2024-07-03 14:15:04,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f87c3556350>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f87c0a2f490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:15:04,654:INFO:Checking exceptions
2024-07-03 14:15:04,654:INFO:Importing libraries
2024-07-03 14:15:04,654:INFO:Copying training dataset
2024-07-03 14:15:04,659:INFO:Defining folds
2024-07-03 14:15:04,659:INFO:Declaring metric variables
2024-07-03 14:15:04,661:INFO:Importing untrained model
2024-07-03 14:15:04,664:INFO:Ridge Classifier Imported successfully
2024-07-03 14:15:04,669:INFO:Starting cross validation
2024-07-03 14:15:04,670:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:15:04,694:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.52883e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:15:04,700:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.37152e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:15:04,701:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.31264e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:15:04,702:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.40388e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:15:04,703:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.48847e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:15:04,703:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.57491e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:15:04,704:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.5489e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:15:04,713:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.59372e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:15:04,717:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.87456e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:15:04,718:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.36341e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:15:04,749:INFO:Calculating mean and std
2024-07-03 14:15:04,750:INFO:Creating metrics dataframe
2024-07-03 14:15:04,751:INFO:Uploading results into container
2024-07-03 14:15:04,752:INFO:Uploading model into container now
2024-07-03 14:15:04,752:INFO:_master_model_container: 6
2024-07-03 14:15:04,752:INFO:_display_container: 2
2024-07-03 14:15:04,752:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8888, solver='auto',
                tol=0.0001)
2024-07-03 14:15:04,752:INFO:create_model() successfully completed......................................
2024-07-03 14:15:04,826:INFO:SubProcess create_model() end ==================================
2024-07-03 14:15:04,826:INFO:Creating metrics dataframe
2024-07-03 14:15:04,833:INFO:Initializing Random Forest Classifier
2024-07-03 14:15:04,833:INFO:Total runtime is 0.08330557346343993 minutes
2024-07-03 14:15:04,836:INFO:SubProcess create_model() called ==================================
2024-07-03 14:15:04,836:INFO:Initializing create_model()
2024-07-03 14:15:04,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f87c3556350>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f87c0a2f490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:15:04,836:INFO:Checking exceptions
2024-07-03 14:15:04,836:INFO:Importing libraries
2024-07-03 14:15:04,836:INFO:Copying training dataset
2024-07-03 14:15:04,841:INFO:Defining folds
2024-07-03 14:15:04,841:INFO:Declaring metric variables
2024-07-03 14:15:04,843:INFO:Importing untrained model
2024-07-03 14:15:04,845:INFO:Random Forest Classifier Imported successfully
2024-07-03 14:15:04,851:INFO:Starting cross validation
2024-07-03 14:15:04,851:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:15:05,809:INFO:Calculating mean and std
2024-07-03 14:15:05,813:INFO:Creating metrics dataframe
2024-07-03 14:15:05,819:INFO:Uploading results into container
2024-07-03 14:15:05,820:INFO:Uploading model into container now
2024-07-03 14:15:05,822:INFO:_master_model_container: 7
2024-07-03 14:15:05,822:INFO:_display_container: 2
2024-07-03 14:15:05,823:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 14:15:05,823:INFO:create_model() successfully completed......................................
2024-07-03 14:15:05,954:INFO:SubProcess create_model() end ==================================
2024-07-03 14:15:05,954:INFO:Creating metrics dataframe
2024-07-03 14:15:05,960:INFO:Initializing Quadratic Discriminant Analysis
2024-07-03 14:15:05,960:INFO:Total runtime is 0.10208476781845091 minutes
2024-07-03 14:15:05,963:INFO:SubProcess create_model() called ==================================
2024-07-03 14:15:05,963:INFO:Initializing create_model()
2024-07-03 14:15:05,963:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f87c3556350>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f87c0a2f490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:15:05,963:INFO:Checking exceptions
2024-07-03 14:15:05,963:INFO:Importing libraries
2024-07-03 14:15:05,963:INFO:Copying training dataset
2024-07-03 14:15:05,968:INFO:Defining folds
2024-07-03 14:15:05,969:INFO:Declaring metric variables
2024-07-03 14:15:05,971:INFO:Importing untrained model
2024-07-03 14:15:05,973:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-03 14:15:05,978:INFO:Starting cross validation
2024-07-03 14:15:05,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:15:06,004:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:15:06,008:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:15:06,009:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:15:06,011:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:15:06,012:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:15:06,014:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:15:06,015:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:15:06,018:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:15:06,020:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:15:06,022:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:15:06,027:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 14:15:06,038:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 14:15:06,045:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 14:15:06,058:INFO:Calculating mean and std
2024-07-03 14:15:06,058:INFO:Creating metrics dataframe
2024-07-03 14:15:06,060:INFO:Uploading results into container
2024-07-03 14:15:06,060:INFO:Uploading model into container now
2024-07-03 14:15:06,060:INFO:_master_model_container: 8
2024-07-03 14:15:06,060:INFO:_display_container: 2
2024-07-03 14:15:06,060:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-03 14:15:06,060:INFO:create_model() successfully completed......................................
2024-07-03 14:15:06,133:INFO:SubProcess create_model() end ==================================
2024-07-03 14:15:06,133:INFO:Creating metrics dataframe
2024-07-03 14:15:06,139:INFO:Initializing Ada Boost Classifier
2024-07-03 14:15:06,139:INFO:Total runtime is 0.10506529410680134 minutes
2024-07-03 14:15:06,141:INFO:SubProcess create_model() called ==================================
2024-07-03 14:15:06,141:INFO:Initializing create_model()
2024-07-03 14:15:06,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f87c3556350>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f87c0a2f490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:15:06,141:INFO:Checking exceptions
2024-07-03 14:15:06,142:INFO:Importing libraries
2024-07-03 14:15:06,142:INFO:Copying training dataset
2024-07-03 14:15:06,147:INFO:Defining folds
2024-07-03 14:15:06,147:INFO:Declaring metric variables
2024-07-03 14:15:06,150:INFO:Importing untrained model
2024-07-03 14:15:06,153:INFO:Ada Boost Classifier Imported successfully
2024-07-03 14:15:06,158:INFO:Starting cross validation
2024-07-03 14:15:06,158:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:15:06,180:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:15:06,181:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:15:06,184:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:15:06,186:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:15:06,186:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:15:06,191:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:15:06,193:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:15:06,195:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:15:06,198:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:15:06,201:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:15:06,530:INFO:Calculating mean and std
2024-07-03 14:15:06,530:INFO:Creating metrics dataframe
2024-07-03 14:15:06,532:INFO:Uploading results into container
2024-07-03 14:15:06,532:INFO:Uploading model into container now
2024-07-03 14:15:06,532:INFO:_master_model_container: 9
2024-07-03 14:15:06,533:INFO:_display_container: 2
2024-07-03 14:15:06,533:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8888)
2024-07-03 14:15:06,533:INFO:create_model() successfully completed......................................
2024-07-03 14:15:06,610:INFO:SubProcess create_model() end ==================================
2024-07-03 14:15:06,610:INFO:Creating metrics dataframe
2024-07-03 14:15:06,616:INFO:Initializing Gradient Boosting Classifier
2024-07-03 14:15:06,616:INFO:Total runtime is 0.1130200425783793 minutes
2024-07-03 14:15:06,618:INFO:SubProcess create_model() called ==================================
2024-07-03 14:15:06,619:INFO:Initializing create_model()
2024-07-03 14:15:06,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f87c3556350>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f87c0a2f490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:15:06,619:INFO:Checking exceptions
2024-07-03 14:15:06,619:INFO:Importing libraries
2024-07-03 14:15:06,619:INFO:Copying training dataset
2024-07-03 14:15:06,624:INFO:Defining folds
2024-07-03 14:15:06,624:INFO:Declaring metric variables
2024-07-03 14:15:06,626:INFO:Importing untrained model
2024-07-03 14:15:06,629:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 14:15:06,635:INFO:Starting cross validation
2024-07-03 14:15:06,635:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:15:07,511:INFO:Calculating mean and std
2024-07-03 14:15:07,512:INFO:Creating metrics dataframe
2024-07-03 14:15:07,514:INFO:Uploading results into container
2024-07-03 14:15:07,514:INFO:Uploading model into container now
2024-07-03 14:15:07,515:INFO:_master_model_container: 10
2024-07-03 14:15:07,515:INFO:_display_container: 2
2024-07-03 14:15:07,515:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 14:15:07,515:INFO:create_model() successfully completed......................................
2024-07-03 14:15:07,590:INFO:SubProcess create_model() end ==================================
2024-07-03 14:15:07,590:INFO:Creating metrics dataframe
2024-07-03 14:15:07,597:INFO:Initializing Linear Discriminant Analysis
2024-07-03 14:15:07,597:INFO:Total runtime is 0.12936444679896036 minutes
2024-07-03 14:15:07,599:INFO:SubProcess create_model() called ==================================
2024-07-03 14:15:07,599:INFO:Initializing create_model()
2024-07-03 14:15:07,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f87c3556350>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f87c0a2f490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:15:07,599:INFO:Checking exceptions
2024-07-03 14:15:07,599:INFO:Importing libraries
2024-07-03 14:15:07,599:INFO:Copying training dataset
2024-07-03 14:15:07,604:INFO:Defining folds
2024-07-03 14:15:07,604:INFO:Declaring metric variables
2024-07-03 14:15:07,607:INFO:Importing untrained model
2024-07-03 14:15:07,610:INFO:Linear Discriminant Analysis Imported successfully
2024-07-03 14:15:07,615:INFO:Starting cross validation
2024-07-03 14:15:07,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:15:07,705:INFO:Calculating mean and std
2024-07-03 14:15:07,706:INFO:Creating metrics dataframe
2024-07-03 14:15:07,707:INFO:Uploading results into container
2024-07-03 14:15:07,708:INFO:Uploading model into container now
2024-07-03 14:15:07,708:INFO:_master_model_container: 11
2024-07-03 14:15:07,708:INFO:_display_container: 2
2024-07-03 14:15:07,708:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-03 14:15:07,708:INFO:create_model() successfully completed......................................
2024-07-03 14:15:07,785:INFO:SubProcess create_model() end ==================================
2024-07-03 14:15:07,785:INFO:Creating metrics dataframe
2024-07-03 14:15:07,791:INFO:Initializing Extra Trees Classifier
2024-07-03 14:15:07,792:INFO:Total runtime is 0.13260782162348428 minutes
2024-07-03 14:15:07,794:INFO:SubProcess create_model() called ==================================
2024-07-03 14:15:07,795:INFO:Initializing create_model()
2024-07-03 14:15:07,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f87c3556350>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f87c0a2f490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:15:07,795:INFO:Checking exceptions
2024-07-03 14:15:07,795:INFO:Importing libraries
2024-07-03 14:15:07,795:INFO:Copying training dataset
2024-07-03 14:15:07,800:INFO:Defining folds
2024-07-03 14:15:07,800:INFO:Declaring metric variables
2024-07-03 14:15:07,802:INFO:Importing untrained model
2024-07-03 14:15:07,805:INFO:Extra Trees Classifier Imported successfully
2024-07-03 14:15:07,809:INFO:Starting cross validation
2024-07-03 14:15:07,810:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:15:08,599:INFO:Calculating mean and std
2024-07-03 14:15:08,600:INFO:Creating metrics dataframe
2024-07-03 14:15:08,601:INFO:Uploading results into container
2024-07-03 14:15:08,601:INFO:Uploading model into container now
2024-07-03 14:15:08,602:INFO:_master_model_container: 12
2024-07-03 14:15:08,602:INFO:_display_container: 2
2024-07-03 14:15:08,602:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8888, verbose=0,
                     warm_start=False)
2024-07-03 14:15:08,602:INFO:create_model() successfully completed......................................
2024-07-03 14:15:08,674:INFO:SubProcess create_model() end ==================================
2024-07-03 14:15:08,674:INFO:Creating metrics dataframe
2024-07-03 14:15:08,683:INFO:Initializing Light Gradient Boosting Machine
2024-07-03 14:15:08,683:INFO:Total runtime is 0.1474702994028727 minutes
2024-07-03 14:15:08,686:INFO:SubProcess create_model() called ==================================
2024-07-03 14:15:08,686:INFO:Initializing create_model()
2024-07-03 14:15:08,686:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f87c3556350>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f87c0a2f490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:15:08,686:INFO:Checking exceptions
2024-07-03 14:15:08,686:INFO:Importing libraries
2024-07-03 14:15:08,686:INFO:Copying training dataset
2024-07-03 14:15:08,692:INFO:Defining folds
2024-07-03 14:15:08,692:INFO:Declaring metric variables
2024-07-03 14:15:08,698:INFO:Importing untrained model
2024-07-03 14:15:08,704:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-03 14:15:08,715:INFO:Starting cross validation
2024-07-03 14:15:08,716:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:22:05,771:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:22:05,772:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:22:05,772:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:22:05,772:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:22:05,872:INFO:PyCaret ClassificationExperiment
2024-07-03 14:22:05,872:INFO:Logging name: clf-default-name
2024-07-03 14:22:05,872:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-03 14:22:05,872:INFO:version 3.3.2
2024-07-03 14:22:05,872:INFO:Initializing setup()
2024-07-03 14:22:05,872:INFO:self.USI: 15fc
2024-07-03 14:22:05,872:INFO:self._variable_keys: {'USI', '_ml_usecase', 'logging_param', 'data', 'target_param', 'memory', 'X', 'y_test', 'fold_shuffle_param', 'fold_generator', 'n_jobs_param', 'seed', 'y_train', 'exp_name_log', 'fix_imbalance', 'html_param', 'gpu_n_jobs_param', 'X_train', '_available_plots', 'X_test', 'y', 'pipeline', 'fold_groups_param', 'exp_id', 'gpu_param', 'idx', 'is_multiclass', 'log_plots_param'}
2024-07-03 14:22:05,872:INFO:Checking environment
2024-07-03 14:22:05,872:INFO:python_version: 3.11.9
2024-07-03 14:22:05,872:INFO:python_build: ('main', 'May 22 2024 17:28:32')
2024-07-03 14:22:05,872:INFO:machine: x86_64
2024-07-03 14:22:05,872:INFO:platform: Linux-6.1.0-22-amd64-x86_64-with-glibc2.36
2024-07-03 14:22:05,872:INFO:Memory: svmem(total=67150065664, available=62152404992, percent=7.4, used=3871555584, free=53606170624, active=2928930816, inactive=9219366912, buffers=432648192, cached=9239691264, shared=379518976, slab=760885248)
2024-07-03 14:22:05,873:INFO:Physical Core: 6
2024-07-03 14:22:05,873:INFO:Logical Core: 12
2024-07-03 14:22:05,873:INFO:Checking libraries
2024-07-03 14:22:05,873:INFO:System:
2024-07-03 14:22:05,873:INFO:    python: 3.11.9 (main, May 22 2024, 17:28:32) [GCC 12.2.0]
2024-07-03 14:22:05,873:INFO:executable: /home/yht/.pyenv/versions/3.11.9/envs/kaggle/bin/python
2024-07-03 14:22:05,873:INFO:   machine: Linux-6.1.0-22-amd64-x86_64-with-glibc2.36
2024-07-03 14:22:05,873:INFO:PyCaret required dependencies:
2024-07-03 14:22:05,887:INFO:                 pip: 24.1.1
2024-07-03 14:22:05,887:INFO:          setuptools: 65.5.0
2024-07-03 14:22:05,887:INFO:             pycaret: 3.3.2
2024-07-03 14:22:05,887:INFO:             IPython: 8.26.0
2024-07-03 14:22:05,887:INFO:          ipywidgets: 8.1.3
2024-07-03 14:22:05,887:INFO:                tqdm: 4.66.4
2024-07-03 14:22:05,887:INFO:               numpy: 1.26.4
2024-07-03 14:22:05,887:INFO:              pandas: 2.1.4
2024-07-03 14:22:05,887:INFO:              jinja2: 3.1.4
2024-07-03 14:22:05,887:INFO:               scipy: 1.11.4
2024-07-03 14:22:05,887:INFO:              joblib: 1.3.2
2024-07-03 14:22:05,887:INFO:             sklearn: 1.4.2
2024-07-03 14:22:05,887:INFO:                pyod: 2.0.1
2024-07-03 14:22:05,887:INFO:            imblearn: 0.12.3
2024-07-03 14:22:05,887:INFO:   category_encoders: 2.6.3
2024-07-03 14:22:05,887:INFO:            lightgbm: 4.4.0
2024-07-03 14:22:05,887:INFO:               numba: 0.60.0
2024-07-03 14:22:05,887:INFO:            requests: 2.32.3
2024-07-03 14:22:05,887:INFO:          matplotlib: 3.7.5
2024-07-03 14:22:05,887:INFO:          scikitplot: 0.3.7
2024-07-03 14:22:05,887:INFO:         yellowbrick: 1.5
2024-07-03 14:22:05,887:INFO:              plotly: 5.22.0
2024-07-03 14:22:05,888:INFO:    plotly-resampler: Not installed
2024-07-03 14:22:05,888:INFO:             kaleido: 0.2.1
2024-07-03 14:22:05,888:INFO:           schemdraw: 0.15
2024-07-03 14:22:05,888:INFO:         statsmodels: 0.14.2
2024-07-03 14:22:05,888:INFO:              sktime: 0.26.0
2024-07-03 14:22:05,888:INFO:               tbats: 1.1.3
2024-07-03 14:22:05,888:INFO:            pmdarima: 2.0.4
2024-07-03 14:22:05,888:INFO:              psutil: 6.0.0
2024-07-03 14:22:05,888:INFO:          markupsafe: 2.1.5
2024-07-03 14:22:05,888:INFO:             pickle5: Not installed
2024-07-03 14:22:05,888:INFO:         cloudpickle: 3.0.0
2024-07-03 14:22:05,888:INFO:         deprecation: 2.1.0
2024-07-03 14:22:05,888:INFO:              xxhash: 3.4.1
2024-07-03 14:22:05,888:INFO:           wurlitzer: 3.1.1
2024-07-03 14:22:05,888:INFO:PyCaret optional dependencies:
2024-07-03 14:22:05,899:INFO:                shap: Not installed
2024-07-03 14:22:05,899:INFO:           interpret: Not installed
2024-07-03 14:22:05,899:INFO:                umap: Not installed
2024-07-03 14:22:05,899:INFO:     ydata_profiling: Not installed
2024-07-03 14:22:05,899:INFO:  explainerdashboard: Not installed
2024-07-03 14:22:05,899:INFO:             autoviz: Not installed
2024-07-03 14:22:05,899:INFO:           fairlearn: Not installed
2024-07-03 14:22:05,899:INFO:          deepchecks: Not installed
2024-07-03 14:22:05,899:INFO:             xgboost: Not installed
2024-07-03 14:22:05,899:INFO:            catboost: Not installed
2024-07-03 14:22:05,899:INFO:              kmodes: Not installed
2024-07-03 14:22:05,899:INFO:             mlxtend: Not installed
2024-07-03 14:22:05,899:INFO:       statsforecast: Not installed
2024-07-03 14:22:05,899:INFO:        tune_sklearn: Not installed
2024-07-03 14:22:05,899:INFO:                 ray: Not installed
2024-07-03 14:22:05,899:INFO:            hyperopt: Not installed
2024-07-03 14:22:05,899:INFO:              optuna: Not installed
2024-07-03 14:22:05,899:INFO:               skopt: Not installed
2024-07-03 14:22:05,899:INFO:              mlflow: Not installed
2024-07-03 14:22:05,899:INFO:              gradio: Not installed
2024-07-03 14:22:05,899:INFO:             fastapi: Not installed
2024-07-03 14:22:05,899:INFO:             uvicorn: Not installed
2024-07-03 14:22:05,899:INFO:              m2cgen: Not installed
2024-07-03 14:22:05,899:INFO:           evidently: Not installed
2024-07-03 14:22:05,899:INFO:               fugue: Not installed
2024-07-03 14:22:05,899:INFO:           streamlit: Not installed
2024-07-03 14:22:05,899:INFO:             prophet: Not installed
2024-07-03 14:22:05,899:INFO:None
2024-07-03 14:22:05,899:INFO:Set up data.
2024-07-03 14:22:05,903:INFO:Set up folding strategy.
2024-07-03 14:22:05,904:INFO:Set up train/test split.
2024-07-03 14:22:05,909:INFO:Set up index.
2024-07-03 14:22:05,909:INFO:Assigning column types.
2024-07-03 14:22:05,912:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-03 14:22:05,944:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-03 14:22:05,946:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 14:22:05,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:22:05,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:22:05,999:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-03 14:22:06,000:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 14:22:06,019:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:22:06,019:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:22:06,020:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-03 14:22:06,052:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 14:22:06,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:22:06,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:22:06,104:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 14:22:06,123:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:22:06,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:22:06,123:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-03 14:22:06,173:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:22:06,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:22:06,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:22:06,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:22:06,224:INFO:Preparing preprocessing pipeline...
2024-07-03 14:22:06,225:INFO:Set up simple imputation.
2024-07-03 14:22:06,244:INFO:Finished creating preprocessing pipeline.
2024-07-03 14:22:06,247:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-03 14:22:06,247:INFO:Creating final display dataframe.
2024-07-03 14:22:06,308:INFO:Setup _display_container:                     Description             Value
0                    Session id              8888
1                        Target       Transported
2                   Target type            Binary
3           Original data shape        (8693, 11)
4        Transformed data shape        (8693, 11)
5   Transformed train set shape        (6085, 11)
6    Transformed test set shape        (2608, 11)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              15fc
2024-07-03 14:22:06,378:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:22:06,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:22:06,432:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:22:06,432:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:22:06,434:INFO:setup() successfully completed in 0.56s...............
2024-07-03 14:22:06,437:INFO:Initializing compare_models()
2024-07-03 14:22:06,437:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f71287eb490>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f71287eb490>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-03 14:22:06,437:INFO:Checking exceptions
2024-07-03 14:22:06,442:INFO:Preparing display monitor
2024-07-03 14:22:06,462:INFO:Initializing Logistic Regression
2024-07-03 14:22:06,462:INFO:Total runtime is 3.0159950256347657e-06 minutes
2024-07-03 14:22:06,465:INFO:SubProcess create_model() called ==================================
2024-07-03 14:22:06,465:INFO:Initializing create_model()
2024-07-03 14:22:06,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f71287eb490>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71249fda90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:22:06,465:INFO:Checking exceptions
2024-07-03 14:22:06,465:INFO:Importing libraries
2024-07-03 14:22:06,465:INFO:Copying training dataset
2024-07-03 14:22:06,471:INFO:Defining folds
2024-07-03 14:22:06,471:INFO:Declaring metric variables
2024-07-03 14:22:06,473:INFO:Importing untrained model
2024-07-03 14:22:06,475:INFO:Logistic Regression Imported successfully
2024-07-03 14:22:06,480:INFO:Starting cross validation
2024-07-03 14:22:06,481:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:22:10,288:INFO:Calculating mean and std
2024-07-03 14:22:10,294:INFO:Creating metrics dataframe
2024-07-03 14:22:10,304:INFO:Uploading results into container
2024-07-03 14:22:10,306:INFO:Uploading model into container now
2024-07-03 14:22:10,308:INFO:_master_model_container: 1
2024-07-03 14:22:10,308:INFO:_display_container: 2
2024-07-03 14:22:10,310:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8888, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-03 14:22:10,310:INFO:create_model() successfully completed......................................
2024-07-03 14:22:10,536:INFO:SubProcess create_model() end ==================================
2024-07-03 14:22:10,536:INFO:Creating metrics dataframe
2024-07-03 14:22:10,564:INFO:Initializing K Neighbors Classifier
2024-07-03 14:22:10,565:INFO:Total runtime is 0.06837369998296103 minutes
2024-07-03 14:22:10,577:INFO:SubProcess create_model() called ==================================
2024-07-03 14:22:10,578:INFO:Initializing create_model()
2024-07-03 14:22:10,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f71287eb490>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71249fda90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:22:10,579:INFO:Checking exceptions
2024-07-03 14:22:10,579:INFO:Importing libraries
2024-07-03 14:22:10,579:INFO:Copying training dataset
2024-07-03 14:22:10,607:INFO:Defining folds
2024-07-03 14:22:10,607:INFO:Declaring metric variables
2024-07-03 14:22:10,621:INFO:Importing untrained model
2024-07-03 14:22:10,634:INFO:K Neighbors Classifier Imported successfully
2024-07-03 14:22:10,658:INFO:Starting cross validation
2024-07-03 14:22:10,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:22:12,244:INFO:Calculating mean and std
2024-07-03 14:22:12,245:INFO:Creating metrics dataframe
2024-07-03 14:22:12,246:INFO:Uploading results into container
2024-07-03 14:22:12,247:INFO:Uploading model into container now
2024-07-03 14:22:12,247:INFO:_master_model_container: 2
2024-07-03 14:22:12,247:INFO:_display_container: 2
2024-07-03 14:22:12,247:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-03 14:22:12,247:INFO:create_model() successfully completed......................................
2024-07-03 14:22:12,310:INFO:SubProcess create_model() end ==================================
2024-07-03 14:22:12,310:INFO:Creating metrics dataframe
2024-07-03 14:22:12,317:INFO:Initializing Naive Bayes
2024-07-03 14:22:12,317:INFO:Total runtime is 0.09757474660873414 minutes
2024-07-03 14:22:12,319:INFO:SubProcess create_model() called ==================================
2024-07-03 14:22:12,319:INFO:Initializing create_model()
2024-07-03 14:22:12,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f71287eb490>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71249fda90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:22:12,319:INFO:Checking exceptions
2024-07-03 14:22:12,319:INFO:Importing libraries
2024-07-03 14:22:12,319:INFO:Copying training dataset
2024-07-03 14:22:12,324:INFO:Defining folds
2024-07-03 14:22:12,324:INFO:Declaring metric variables
2024-07-03 14:22:12,327:INFO:Importing untrained model
2024-07-03 14:22:12,329:INFO:Naive Bayes Imported successfully
2024-07-03 14:22:12,334:INFO:Starting cross validation
2024-07-03 14:22:12,335:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:22:12,424:INFO:Calculating mean and std
2024-07-03 14:22:12,425:INFO:Creating metrics dataframe
2024-07-03 14:22:12,427:INFO:Uploading results into container
2024-07-03 14:22:12,427:INFO:Uploading model into container now
2024-07-03 14:22:12,428:INFO:_master_model_container: 3
2024-07-03 14:22:12,428:INFO:_display_container: 2
2024-07-03 14:22:12,428:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-03 14:22:12,428:INFO:create_model() successfully completed......................................
2024-07-03 14:22:12,488:INFO:SubProcess create_model() end ==================================
2024-07-03 14:22:12,488:INFO:Creating metrics dataframe
2024-07-03 14:22:12,494:INFO:Initializing Decision Tree Classifier
2024-07-03 14:22:12,494:INFO:Total runtime is 0.10052339633305868 minutes
2024-07-03 14:22:12,496:INFO:SubProcess create_model() called ==================================
2024-07-03 14:22:12,496:INFO:Initializing create_model()
2024-07-03 14:22:12,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f71287eb490>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71249fda90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:22:12,496:INFO:Checking exceptions
2024-07-03 14:22:12,496:INFO:Importing libraries
2024-07-03 14:22:12,496:INFO:Copying training dataset
2024-07-03 14:22:12,501:INFO:Defining folds
2024-07-03 14:22:12,501:INFO:Declaring metric variables
2024-07-03 14:22:12,504:INFO:Importing untrained model
2024-07-03 14:22:12,506:INFO:Decision Tree Classifier Imported successfully
2024-07-03 14:22:12,511:INFO:Starting cross validation
2024-07-03 14:22:12,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:22:12,633:INFO:Calculating mean and std
2024-07-03 14:22:12,634:INFO:Creating metrics dataframe
2024-07-03 14:22:12,635:INFO:Uploading results into container
2024-07-03 14:22:12,635:INFO:Uploading model into container now
2024-07-03 14:22:12,635:INFO:_master_model_container: 4
2024-07-03 14:22:12,636:INFO:_display_container: 2
2024-07-03 14:22:12,636:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8888, splitter='best')
2024-07-03 14:22:12,636:INFO:create_model() successfully completed......................................
2024-07-03 14:22:12,697:INFO:SubProcess create_model() end ==================================
2024-07-03 14:22:12,697:INFO:Creating metrics dataframe
2024-07-03 14:22:12,703:INFO:Initializing SVM - Linear Kernel
2024-07-03 14:22:12,703:INFO:Total runtime is 0.10401909351348877 minutes
2024-07-03 14:22:12,707:INFO:SubProcess create_model() called ==================================
2024-07-03 14:22:12,707:INFO:Initializing create_model()
2024-07-03 14:22:12,707:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f71287eb490>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71249fda90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:22:12,707:INFO:Checking exceptions
2024-07-03 14:22:12,707:INFO:Importing libraries
2024-07-03 14:22:12,707:INFO:Copying training dataset
2024-07-03 14:22:12,713:INFO:Defining folds
2024-07-03 14:22:12,713:INFO:Declaring metric variables
2024-07-03 14:22:12,716:INFO:Importing untrained model
2024-07-03 14:22:12,718:INFO:SVM - Linear Kernel Imported successfully
2024-07-03 14:22:12,723:INFO:Starting cross validation
2024-07-03 14:22:12,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:22:12,833:INFO:Calculating mean and std
2024-07-03 14:22:12,834:INFO:Creating metrics dataframe
2024-07-03 14:22:12,835:INFO:Uploading results into container
2024-07-03 14:22:12,836:INFO:Uploading model into container now
2024-07-03 14:22:12,836:INFO:_master_model_container: 5
2024-07-03 14:22:12,836:INFO:_display_container: 2
2024-07-03 14:22:12,836:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8888, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-03 14:22:12,836:INFO:create_model() successfully completed......................................
2024-07-03 14:22:12,895:INFO:SubProcess create_model() end ==================================
2024-07-03 14:22:12,895:INFO:Creating metrics dataframe
2024-07-03 14:22:12,903:INFO:Initializing Ridge Classifier
2024-07-03 14:22:12,903:INFO:Total runtime is 0.10734607378641764 minutes
2024-07-03 14:22:12,905:INFO:SubProcess create_model() called ==================================
2024-07-03 14:22:12,906:INFO:Initializing create_model()
2024-07-03 14:22:12,906:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f71287eb490>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71249fda90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:22:12,906:INFO:Checking exceptions
2024-07-03 14:22:12,906:INFO:Importing libraries
2024-07-03 14:22:12,906:INFO:Copying training dataset
2024-07-03 14:22:12,911:INFO:Defining folds
2024-07-03 14:22:12,911:INFO:Declaring metric variables
2024-07-03 14:22:12,915:INFO:Importing untrained model
2024-07-03 14:22:12,917:INFO:Ridge Classifier Imported successfully
2024-07-03 14:22:12,922:INFO:Starting cross validation
2024-07-03 14:22:12,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:22:12,947:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.37152e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:22:12,948:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.52883e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:22:12,953:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.31264e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:22:12,955:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.5489e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:22:12,957:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.57491e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:22:12,959:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.40388e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:22:12,965:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.48847e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:22:12,966:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.59372e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:22:12,969:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.87456e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:22:12,971:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.36341e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:22:13,005:INFO:Calculating mean and std
2024-07-03 14:22:13,006:INFO:Creating metrics dataframe
2024-07-03 14:22:13,007:INFO:Uploading results into container
2024-07-03 14:22:13,007:INFO:Uploading model into container now
2024-07-03 14:22:13,008:INFO:_master_model_container: 6
2024-07-03 14:22:13,008:INFO:_display_container: 2
2024-07-03 14:22:13,008:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8888, solver='auto',
                tol=0.0001)
2024-07-03 14:22:13,008:INFO:create_model() successfully completed......................................
2024-07-03 14:22:13,067:INFO:SubProcess create_model() end ==================================
2024-07-03 14:22:13,067:INFO:Creating metrics dataframe
2024-07-03 14:22:13,074:INFO:Initializing Random Forest Classifier
2024-07-03 14:22:13,074:INFO:Total runtime is 0.1101967175801595 minutes
2024-07-03 14:22:13,076:INFO:SubProcess create_model() called ==================================
2024-07-03 14:22:13,077:INFO:Initializing create_model()
2024-07-03 14:22:13,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f71287eb490>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71249fda90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:22:13,077:INFO:Checking exceptions
2024-07-03 14:22:13,077:INFO:Importing libraries
2024-07-03 14:22:13,077:INFO:Copying training dataset
2024-07-03 14:22:13,082:INFO:Defining folds
2024-07-03 14:22:13,082:INFO:Declaring metric variables
2024-07-03 14:22:13,085:INFO:Importing untrained model
2024-07-03 14:22:13,087:INFO:Random Forest Classifier Imported successfully
2024-07-03 14:22:13,091:INFO:Starting cross validation
2024-07-03 14:22:13,092:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:22:14,243:INFO:Calculating mean and std
2024-07-03 14:22:14,247:INFO:Creating metrics dataframe
2024-07-03 14:22:14,253:INFO:Uploading results into container
2024-07-03 14:22:14,255:INFO:Uploading model into container now
2024-07-03 14:22:14,256:INFO:_master_model_container: 7
2024-07-03 14:22:14,257:INFO:_display_container: 2
2024-07-03 14:22:14,258:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 14:22:14,258:INFO:create_model() successfully completed......................................
2024-07-03 14:22:14,420:INFO:SubProcess create_model() end ==================================
2024-07-03 14:22:14,421:INFO:Creating metrics dataframe
2024-07-03 14:22:14,453:INFO:Initializing Quadratic Discriminant Analysis
2024-07-03 14:22:14,453:INFO:Total runtime is 0.1331777334213257 minutes
2024-07-03 14:22:14,465:INFO:SubProcess create_model() called ==================================
2024-07-03 14:22:14,466:INFO:Initializing create_model()
2024-07-03 14:22:14,466:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f71287eb490>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71249fda90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:22:14,467:INFO:Checking exceptions
2024-07-03 14:22:14,467:INFO:Importing libraries
2024-07-03 14:22:14,467:INFO:Copying training dataset
2024-07-03 14:22:14,492:INFO:Defining folds
2024-07-03 14:22:14,493:INFO:Declaring metric variables
2024-07-03 14:22:14,506:INFO:Importing untrained model
2024-07-03 14:22:14,519:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-03 14:22:14,543:INFO:Starting cross validation
2024-07-03 14:22:14,546:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:22:14,649:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:22:14,661:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:22:14,663:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:22:14,668:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:22:14,669:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:22:14,673:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:22:14,673:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:22:14,687:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:22:14,704:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:22:14,711:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:22:14,776:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 14:22:14,789:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 14:22:14,807:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 14:22:14,834:INFO:Calculating mean and std
2024-07-03 14:22:14,838:INFO:Creating metrics dataframe
2024-07-03 14:22:14,844:INFO:Uploading results into container
2024-07-03 14:22:14,845:INFO:Uploading model into container now
2024-07-03 14:22:14,846:INFO:_master_model_container: 8
2024-07-03 14:22:14,846:INFO:_display_container: 2
2024-07-03 14:22:14,847:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-03 14:22:14,847:INFO:create_model() successfully completed......................................
2024-07-03 14:22:15,007:INFO:SubProcess create_model() end ==================================
2024-07-03 14:22:15,008:INFO:Creating metrics dataframe
2024-07-03 14:22:15,041:INFO:Initializing Ada Boost Classifier
2024-07-03 14:22:15,041:INFO:Total runtime is 0.14298152526219687 minutes
2024-07-03 14:22:15,052:INFO:SubProcess create_model() called ==================================
2024-07-03 14:22:15,053:INFO:Initializing create_model()
2024-07-03 14:22:15,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f71287eb490>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71249fda90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:22:15,054:INFO:Checking exceptions
2024-07-03 14:22:15,054:INFO:Importing libraries
2024-07-03 14:22:15,054:INFO:Copying training dataset
2024-07-03 14:22:15,079:INFO:Defining folds
2024-07-03 14:22:15,079:INFO:Declaring metric variables
2024-07-03 14:22:15,086:INFO:Importing untrained model
2024-07-03 14:22:15,091:INFO:Ada Boost Classifier Imported successfully
2024-07-03 14:22:15,099:INFO:Starting cross validation
2024-07-03 14:22:15,100:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:22:15,126:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:22:15,127:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:22:15,130:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:22:15,131:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:22:15,131:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:22:15,135:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:22:15,136:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:22:15,137:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:22:15,139:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:22:15,141:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:22:15,503:INFO:Calculating mean and std
2024-07-03 14:22:15,504:INFO:Creating metrics dataframe
2024-07-03 14:22:15,506:INFO:Uploading results into container
2024-07-03 14:22:15,506:INFO:Uploading model into container now
2024-07-03 14:22:15,506:INFO:_master_model_container: 9
2024-07-03 14:22:15,506:INFO:_display_container: 2
2024-07-03 14:22:15,506:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8888)
2024-07-03 14:22:15,507:INFO:create_model() successfully completed......................................
2024-07-03 14:22:15,563:INFO:SubProcess create_model() end ==================================
2024-07-03 14:22:15,563:INFO:Creating metrics dataframe
2024-07-03 14:22:15,570:INFO:Initializing Gradient Boosting Classifier
2024-07-03 14:22:15,570:INFO:Total runtime is 0.15179044405619305 minutes
2024-07-03 14:22:15,572:INFO:SubProcess create_model() called ==================================
2024-07-03 14:22:15,572:INFO:Initializing create_model()
2024-07-03 14:22:15,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f71287eb490>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71249fda90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:22:15,572:INFO:Checking exceptions
2024-07-03 14:22:15,572:INFO:Importing libraries
2024-07-03 14:22:15,572:INFO:Copying training dataset
2024-07-03 14:22:15,577:INFO:Defining folds
2024-07-03 14:22:15,577:INFO:Declaring metric variables
2024-07-03 14:22:15,580:INFO:Importing untrained model
2024-07-03 14:22:15,583:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 14:22:15,588:INFO:Starting cross validation
2024-07-03 14:22:15,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:22:17,952:INFO:Calculating mean and std
2024-07-03 14:22:17,953:INFO:Creating metrics dataframe
2024-07-03 14:22:17,955:INFO:Uploading results into container
2024-07-03 14:22:17,955:INFO:Uploading model into container now
2024-07-03 14:22:17,955:INFO:_master_model_container: 10
2024-07-03 14:22:17,955:INFO:_display_container: 2
2024-07-03 14:22:17,956:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 14:22:17,956:INFO:create_model() successfully completed......................................
2024-07-03 14:22:18,013:INFO:SubProcess create_model() end ==================================
2024-07-03 14:22:18,013:INFO:Creating metrics dataframe
2024-07-03 14:22:18,020:INFO:Initializing Linear Discriminant Analysis
2024-07-03 14:22:18,020:INFO:Total runtime is 0.1926354726155599 minutes
2024-07-03 14:22:18,023:INFO:SubProcess create_model() called ==================================
2024-07-03 14:22:18,023:INFO:Initializing create_model()
2024-07-03 14:22:18,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f71287eb490>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71249fda90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:22:18,023:INFO:Checking exceptions
2024-07-03 14:22:18,023:INFO:Importing libraries
2024-07-03 14:22:18,023:INFO:Copying training dataset
2024-07-03 14:22:18,028:INFO:Defining folds
2024-07-03 14:22:18,028:INFO:Declaring metric variables
2024-07-03 14:22:18,031:INFO:Importing untrained model
2024-07-03 14:22:18,033:INFO:Linear Discriminant Analysis Imported successfully
2024-07-03 14:22:18,038:INFO:Starting cross validation
2024-07-03 14:22:18,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:22:18,139:INFO:Calculating mean and std
2024-07-03 14:22:18,141:INFO:Creating metrics dataframe
2024-07-03 14:22:18,143:INFO:Uploading results into container
2024-07-03 14:22:18,143:INFO:Uploading model into container now
2024-07-03 14:22:18,144:INFO:_master_model_container: 11
2024-07-03 14:22:18,144:INFO:_display_container: 2
2024-07-03 14:22:18,144:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-03 14:22:18,144:INFO:create_model() successfully completed......................................
2024-07-03 14:22:18,218:INFO:SubProcess create_model() end ==================================
2024-07-03 14:22:18,218:INFO:Creating metrics dataframe
2024-07-03 14:22:18,225:INFO:Initializing Extra Trees Classifier
2024-07-03 14:22:18,225:INFO:Total runtime is 0.19605391025543215 minutes
2024-07-03 14:22:18,228:INFO:SubProcess create_model() called ==================================
2024-07-03 14:22:18,228:INFO:Initializing create_model()
2024-07-03 14:22:18,228:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f71287eb490>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71249fda90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:22:18,228:INFO:Checking exceptions
2024-07-03 14:22:18,228:INFO:Importing libraries
2024-07-03 14:22:18,228:INFO:Copying training dataset
2024-07-03 14:22:18,232:INFO:Defining folds
2024-07-03 14:22:18,233:INFO:Declaring metric variables
2024-07-03 14:22:18,235:INFO:Importing untrained model
2024-07-03 14:22:18,237:INFO:Extra Trees Classifier Imported successfully
2024-07-03 14:22:18,241:INFO:Starting cross validation
2024-07-03 14:22:18,242:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:22:19,788:INFO:Calculating mean and std
2024-07-03 14:22:19,789:INFO:Creating metrics dataframe
2024-07-03 14:22:19,790:INFO:Uploading results into container
2024-07-03 14:22:19,791:INFO:Uploading model into container now
2024-07-03 14:22:19,791:INFO:_master_model_container: 12
2024-07-03 14:22:19,791:INFO:_display_container: 2
2024-07-03 14:22:19,792:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8888, verbose=0,
                     warm_start=False)
2024-07-03 14:22:19,792:INFO:create_model() successfully completed......................................
2024-07-03 14:22:19,855:INFO:SubProcess create_model() end ==================================
2024-07-03 14:22:19,855:INFO:Creating metrics dataframe
2024-07-03 14:22:19,863:INFO:Initializing Light Gradient Boosting Machine
2024-07-03 14:22:19,863:INFO:Total runtime is 0.22335336605707806 minutes
2024-07-03 14:22:19,866:INFO:SubProcess create_model() called ==================================
2024-07-03 14:22:19,866:INFO:Initializing create_model()
2024-07-03 14:22:19,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f71287eb490>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f71249fda90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:22:19,866:INFO:Checking exceptions
2024-07-03 14:22:19,866:INFO:Importing libraries
2024-07-03 14:22:19,866:INFO:Copying training dataset
2024-07-03 14:22:19,874:INFO:Defining folds
2024-07-03 14:22:19,874:INFO:Declaring metric variables
2024-07-03 14:22:19,877:INFO:Importing untrained model
2024-07-03 14:22:19,880:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-03 14:22:19,886:INFO:Starting cross validation
2024-07-03 14:22:19,887:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-03 14:27:44,307:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:44,307:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:44,307:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:44,307:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:44,409:INFO:PyCaret ClassificationExperiment
2024-07-03 14:27:44,409:INFO:Logging name: clf-default-name
2024-07-03 14:27:44,409:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-03 14:27:44,409:INFO:version 3.3.2
2024-07-03 14:27:44,409:INFO:Initializing setup()
2024-07-03 14:27:44,409:INFO:self.USI: 9f58
2024-07-03 14:27:44,409:INFO:self._variable_keys: {'fold_generator', 'USI', 'exp_name_log', '_available_plots', 'is_multiclass', 'logging_param', 'X', 'X_test', 'gpu_n_jobs_param', 'data', 'fold_shuffle_param', 'memory', 'y', 'gpu_param', 'html_param', 'target_param', 'seed', 'pipeline', 'exp_id', '_ml_usecase', 'n_jobs_param', 'fold_groups_param', 'idx', 'fix_imbalance', 'y_test', 'X_train', 'log_plots_param', 'y_train'}
2024-07-03 14:27:44,410:INFO:Checking environment
2024-07-03 14:27:44,410:INFO:python_version: 3.11.9
2024-07-03 14:27:44,410:INFO:python_build: ('main', 'May 22 2024 17:28:32')
2024-07-03 14:27:44,410:INFO:machine: x86_64
2024-07-03 14:27:44,410:INFO:platform: Linux-6.1.0-22-amd64-x86_64-with-glibc2.36
2024-07-03 14:27:44,410:INFO:Memory: svmem(total=67150065664, available=61966786560, percent=7.7, used=3919110144, free=53402083328, active=2941931520, inactive=9274044416, buffers=433692672, cached=9395179520, shared=517591040, slab=769736704)
2024-07-03 14:27:44,410:INFO:Physical Core: 6
2024-07-03 14:27:44,410:INFO:Logical Core: 12
2024-07-03 14:27:44,410:INFO:Checking libraries
2024-07-03 14:27:44,410:INFO:System:
2024-07-03 14:27:44,410:INFO:    python: 3.11.9 (main, May 22 2024, 17:28:32) [GCC 12.2.0]
2024-07-03 14:27:44,410:INFO:executable: /home/yht/.pyenv/versions/3.11.9/envs/kaggle/bin/python
2024-07-03 14:27:44,410:INFO:   machine: Linux-6.1.0-22-amd64-x86_64-with-glibc2.36
2024-07-03 14:27:44,410:INFO:PyCaret required dependencies:
2024-07-03 14:27:44,424:INFO:                 pip: 24.1.1
2024-07-03 14:27:44,424:INFO:          setuptools: 65.5.0
2024-07-03 14:27:44,424:INFO:             pycaret: 3.3.2
2024-07-03 14:27:44,424:INFO:             IPython: 8.26.0
2024-07-03 14:27:44,424:INFO:          ipywidgets: 8.1.3
2024-07-03 14:27:44,424:INFO:                tqdm: 4.66.4
2024-07-03 14:27:44,424:INFO:               numpy: 1.26.4
2024-07-03 14:27:44,424:INFO:              pandas: 2.1.4
2024-07-03 14:27:44,424:INFO:              jinja2: 3.1.4
2024-07-03 14:27:44,425:INFO:               scipy: 1.11.4
2024-07-03 14:27:44,425:INFO:              joblib: 1.3.2
2024-07-03 14:27:44,425:INFO:             sklearn: 1.4.2
2024-07-03 14:27:44,425:INFO:                pyod: 2.0.1
2024-07-03 14:27:44,425:INFO:            imblearn: 0.12.3
2024-07-03 14:27:44,425:INFO:   category_encoders: 2.6.3
2024-07-03 14:27:44,425:INFO:            lightgbm: 4.4.0
2024-07-03 14:27:44,425:INFO:               numba: 0.60.0
2024-07-03 14:27:44,425:INFO:            requests: 2.32.3
2024-07-03 14:27:44,425:INFO:          matplotlib: 3.7.5
2024-07-03 14:27:44,425:INFO:          scikitplot: 0.3.7
2024-07-03 14:27:44,425:INFO:         yellowbrick: 1.5
2024-07-03 14:27:44,425:INFO:              plotly: 5.22.0
2024-07-03 14:27:44,425:INFO:    plotly-resampler: Not installed
2024-07-03 14:27:44,425:INFO:             kaleido: 0.2.1
2024-07-03 14:27:44,425:INFO:           schemdraw: 0.15
2024-07-03 14:27:44,425:INFO:         statsmodels: 0.14.2
2024-07-03 14:27:44,425:INFO:              sktime: 0.26.0
2024-07-03 14:27:44,425:INFO:               tbats: 1.1.3
2024-07-03 14:27:44,425:INFO:            pmdarima: 2.0.4
2024-07-03 14:27:44,425:INFO:              psutil: 6.0.0
2024-07-03 14:27:44,425:INFO:          markupsafe: 2.1.5
2024-07-03 14:27:44,425:INFO:             pickle5: Not installed
2024-07-03 14:27:44,425:INFO:         cloudpickle: 3.0.0
2024-07-03 14:27:44,425:INFO:         deprecation: 2.1.0
2024-07-03 14:27:44,425:INFO:              xxhash: 3.4.1
2024-07-03 14:27:44,425:INFO:           wurlitzer: 3.1.1
2024-07-03 14:27:44,425:INFO:PyCaret optional dependencies:
2024-07-03 14:27:44,436:INFO:                shap: Not installed
2024-07-03 14:27:44,436:INFO:           interpret: Not installed
2024-07-03 14:27:44,436:INFO:                umap: Not installed
2024-07-03 14:27:44,436:INFO:     ydata_profiling: Not installed
2024-07-03 14:27:44,436:INFO:  explainerdashboard: Not installed
2024-07-03 14:27:44,436:INFO:             autoviz: Not installed
2024-07-03 14:27:44,436:INFO:           fairlearn: Not installed
2024-07-03 14:27:44,436:INFO:          deepchecks: Not installed
2024-07-03 14:27:44,436:INFO:             xgboost: Not installed
2024-07-03 14:27:44,436:INFO:            catboost: Not installed
2024-07-03 14:27:44,436:INFO:              kmodes: Not installed
2024-07-03 14:27:44,436:INFO:             mlxtend: Not installed
2024-07-03 14:27:44,436:INFO:       statsforecast: Not installed
2024-07-03 14:27:44,436:INFO:        tune_sklearn: Not installed
2024-07-03 14:27:44,436:INFO:                 ray: Not installed
2024-07-03 14:27:44,436:INFO:            hyperopt: Not installed
2024-07-03 14:27:44,436:INFO:              optuna: Not installed
2024-07-03 14:27:44,436:INFO:               skopt: Not installed
2024-07-03 14:27:44,436:INFO:              mlflow: Not installed
2024-07-03 14:27:44,436:INFO:              gradio: Not installed
2024-07-03 14:27:44,436:INFO:             fastapi: Not installed
2024-07-03 14:27:44,436:INFO:             uvicorn: Not installed
2024-07-03 14:27:44,436:INFO:              m2cgen: Not installed
2024-07-03 14:27:44,436:INFO:           evidently: Not installed
2024-07-03 14:27:44,436:INFO:               fugue: Not installed
2024-07-03 14:27:44,437:INFO:           streamlit: Not installed
2024-07-03 14:27:44,437:INFO:             prophet: Not installed
2024-07-03 14:27:44,437:INFO:None
2024-07-03 14:27:44,437:INFO:Set up GPU usage.
2024-07-03 14:27:44,437:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:44,437:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-07-03 14:27:44,437:INFO:Set up data.
2024-07-03 14:27:44,441:INFO:Set up folding strategy.
2024-07-03 14:27:44,441:INFO:Set up train/test split.
2024-07-03 14:27:44,446:INFO:Set up index.
2024-07-03 14:27:44,446:INFO:Assigning column types.
2024-07-03 14:27:44,450:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-03 14:27:44,450:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:44,481:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-03 14:27:44,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:44,482:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:44,483:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 14:27:44,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:44,500:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:44,504:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:44,505:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:27:50,975:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:27:50,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,009:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-03 14:27:51,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,009:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 14:27:51,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,025:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,029:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:27:51,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:27:51,090:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-03 14:27:51,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,123:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,123:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,123:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 14:27:51,124:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,139:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,142:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:27:51,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:27:51,253:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,441:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,444:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 14:27:51,445:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,532:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:51,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:27:51,935:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:27:51,936:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-03 14:27:51,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:52,116:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:52,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:52,119:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:52,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:52,208:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:52,209:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:27:52,297:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:27:52,297:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:52,335:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:52,335:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:52,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:52,352:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:52,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:52,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:27:52,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:27:52,420:INFO:Preparing preprocessing pipeline...
2024-07-03 14:27:52,421:INFO:Set up simple imputation.
2024-07-03 14:27:52,478:INFO:Finished creating preprocessing pipeline.
2024-07-03 14:27:52,493:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-03 14:27:52,493:INFO:Creating final display dataframe.
2024-07-03 14:27:52,791:INFO:Setup _display_container:                     Description             Value
0                    Session id              8888
1                        Target       Transported
2                   Target type            Binary
3           Original data shape        (8693, 11)
4        Transformed data shape        (8693, 11)
5   Transformed train set shape        (6085, 11)
6    Transformed test set shape        (2608, 11)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              9f58
2024-07-03 14:27:52,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:52,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:52,984:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:52,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:53,070:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:53,088:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:53,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:27:53,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:27:53,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:53,487:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:53,487:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:53,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:53,504:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:53,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 14:27:53,508:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:27:53,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 14:27:53,584:INFO:setup() successfully completed in 9.18s...............
2024-07-03 14:27:53,588:INFO:Initializing compare_models()
2024-07-03 14:27:53,588:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-03 14:27:53,588:INFO:Checking exceptions
2024-07-03 14:27:53,593:INFO:Preparing display monitor
2024-07-03 14:27:53,614:INFO:Initializing Logistic Regression
2024-07-03 14:27:53,615:INFO:Total runtime is 2.4199485778808595e-06 minutes
2024-07-03 14:27:53,617:INFO:SubProcess create_model() called ==================================
2024-07-03 14:27:53,618:INFO:Initializing create_model()
2024-07-03 14:27:53,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4ed10e3c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:27:53,618:INFO:Checking exceptions
2024-07-03 14:27:53,618:INFO:Importing libraries
2024-07-03 14:27:53,618:INFO:Copying training dataset
2024-07-03 14:27:53,637:INFO:Defining folds
2024-07-03 14:27:53,637:INFO:Declaring metric variables
2024-07-03 14:27:53,648:INFO:Importing untrained model
2024-07-03 14:27:53,661:INFO:Logistic Regression Imported successfully
2024-07-03 14:27:53,685:INFO:Starting cross validation
2024-07-03 14:27:53,688:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:27:56,997:INFO:Calculating mean and std
2024-07-03 14:27:57,000:INFO:Creating metrics dataframe
2024-07-03 14:27:57,002:INFO:Uploading results into container
2024-07-03 14:27:57,002:INFO:Uploading model into container now
2024-07-03 14:27:57,003:INFO:_master_model_container: 1
2024-07-03 14:27:57,003:INFO:_display_container: 2
2024-07-03 14:27:57,003:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8888, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-03 14:27:57,003:INFO:create_model() successfully completed......................................
2024-07-03 14:27:57,082:INFO:SubProcess create_model() end ==================================
2024-07-03 14:27:57,082:INFO:Creating metrics dataframe
2024-07-03 14:27:57,087:INFO:Initializing K Neighbors Classifier
2024-07-03 14:27:57,087:INFO:Total runtime is 0.05786801973978678 minutes
2024-07-03 14:27:57,089:INFO:SubProcess create_model() called ==================================
2024-07-03 14:27:57,089:INFO:Initializing create_model()
2024-07-03 14:27:57,090:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4ed10e3c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:27:57,090:INFO:Checking exceptions
2024-07-03 14:27:57,090:INFO:Importing libraries
2024-07-03 14:27:57,090:INFO:Copying training dataset
2024-07-03 14:27:57,096:INFO:Defining folds
2024-07-03 14:27:57,096:INFO:Declaring metric variables
2024-07-03 14:27:57,098:INFO:Importing untrained model
2024-07-03 14:27:57,101:INFO:K Neighbors Classifier Imported successfully
2024-07-03 14:27:57,108:INFO:Starting cross validation
2024-07-03 14:27:57,109:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:27:57,972:INFO:Calculating mean and std
2024-07-03 14:27:57,973:INFO:Creating metrics dataframe
2024-07-03 14:27:57,975:INFO:Uploading results into container
2024-07-03 14:27:57,975:INFO:Uploading model into container now
2024-07-03 14:27:57,975:INFO:_master_model_container: 2
2024-07-03 14:27:57,975:INFO:_display_container: 2
2024-07-03 14:27:57,976:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-03 14:27:57,976:INFO:create_model() successfully completed......................................
2024-07-03 14:27:58,037:INFO:SubProcess create_model() end ==================================
2024-07-03 14:27:58,037:INFO:Creating metrics dataframe
2024-07-03 14:27:58,043:INFO:Initializing Naive Bayes
2024-07-03 14:27:58,043:INFO:Total runtime is 0.07380244334538777 minutes
2024-07-03 14:27:58,045:INFO:SubProcess create_model() called ==================================
2024-07-03 14:27:58,045:INFO:Initializing create_model()
2024-07-03 14:27:58,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4ed10e3c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:27:58,045:INFO:Checking exceptions
2024-07-03 14:27:58,045:INFO:Importing libraries
2024-07-03 14:27:58,045:INFO:Copying training dataset
2024-07-03 14:27:58,050:INFO:Defining folds
2024-07-03 14:27:58,050:INFO:Declaring metric variables
2024-07-03 14:27:58,052:INFO:Importing untrained model
2024-07-03 14:27:58,054:INFO:Naive Bayes Imported successfully
2024-07-03 14:27:58,059:INFO:Starting cross validation
2024-07-03 14:27:58,059:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:27:58,314:INFO:Calculating mean and std
2024-07-03 14:27:58,315:INFO:Creating metrics dataframe
2024-07-03 14:27:58,316:INFO:Uploading results into container
2024-07-03 14:27:58,317:INFO:Uploading model into container now
2024-07-03 14:27:58,317:INFO:_master_model_container: 3
2024-07-03 14:27:58,317:INFO:_display_container: 2
2024-07-03 14:27:58,317:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-03 14:27:58,317:INFO:create_model() successfully completed......................................
2024-07-03 14:27:58,381:INFO:SubProcess create_model() end ==================================
2024-07-03 14:27:58,381:INFO:Creating metrics dataframe
2024-07-03 14:27:58,387:INFO:Initializing Decision Tree Classifier
2024-07-03 14:27:58,387:INFO:Total runtime is 0.07954392433166503 minutes
2024-07-03 14:27:58,390:INFO:SubProcess create_model() called ==================================
2024-07-03 14:27:58,390:INFO:Initializing create_model()
2024-07-03 14:27:58,390:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4ed10e3c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:27:58,390:INFO:Checking exceptions
2024-07-03 14:27:58,390:INFO:Importing libraries
2024-07-03 14:27:58,390:INFO:Copying training dataset
2024-07-03 14:27:58,395:INFO:Defining folds
2024-07-03 14:27:58,395:INFO:Declaring metric variables
2024-07-03 14:27:58,397:INFO:Importing untrained model
2024-07-03 14:27:58,400:INFO:Decision Tree Classifier Imported successfully
2024-07-03 14:27:58,405:INFO:Starting cross validation
2024-07-03 14:27:58,405:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:27:58,777:INFO:Calculating mean and std
2024-07-03 14:27:58,777:INFO:Creating metrics dataframe
2024-07-03 14:27:58,778:INFO:Uploading results into container
2024-07-03 14:27:58,779:INFO:Uploading model into container now
2024-07-03 14:27:58,779:INFO:_master_model_container: 4
2024-07-03 14:27:58,779:INFO:_display_container: 2
2024-07-03 14:27:58,779:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8888, splitter='best')
2024-07-03 14:27:58,779:INFO:create_model() successfully completed......................................
2024-07-03 14:27:58,837:INFO:SubProcess create_model() end ==================================
2024-07-03 14:27:58,837:INFO:Creating metrics dataframe
2024-07-03 14:27:58,844:INFO:Initializing SVM - Linear Kernel
2024-07-03 14:27:58,844:INFO:Total runtime is 0.08715509176254271 minutes
2024-07-03 14:27:58,846:INFO:SubProcess create_model() called ==================================
2024-07-03 14:27:58,846:INFO:Initializing create_model()
2024-07-03 14:27:58,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4ed10e3c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:27:58,847:INFO:Checking exceptions
2024-07-03 14:27:58,847:INFO:Importing libraries
2024-07-03 14:27:58,847:INFO:Copying training dataset
2024-07-03 14:27:58,851:INFO:Defining folds
2024-07-03 14:27:58,851:INFO:Declaring metric variables
2024-07-03 14:27:58,854:INFO:Importing untrained model
2024-07-03 14:27:58,856:INFO:SVM - Linear Kernel Imported successfully
2024-07-03 14:27:58,860:INFO:Starting cross validation
2024-07-03 14:27:58,861:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:27:59,226:INFO:Calculating mean and std
2024-07-03 14:27:59,227:INFO:Creating metrics dataframe
2024-07-03 14:27:59,228:INFO:Uploading results into container
2024-07-03 14:27:59,228:INFO:Uploading model into container now
2024-07-03 14:27:59,228:INFO:_master_model_container: 5
2024-07-03 14:27:59,229:INFO:_display_container: 2
2024-07-03 14:27:59,229:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8888, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-03 14:27:59,229:INFO:create_model() successfully completed......................................
2024-07-03 14:27:59,289:INFO:SubProcess create_model() end ==================================
2024-07-03 14:27:59,289:INFO:Creating metrics dataframe
2024-07-03 14:27:59,294:INFO:Initializing Ridge Classifier
2024-07-03 14:27:59,295:INFO:Total runtime is 0.09466777245203653 minutes
2024-07-03 14:27:59,297:INFO:SubProcess create_model() called ==================================
2024-07-03 14:27:59,297:INFO:Initializing create_model()
2024-07-03 14:27:59,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4ed10e3c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:27:59,297:INFO:Checking exceptions
2024-07-03 14:27:59,297:INFO:Importing libraries
2024-07-03 14:27:59,297:INFO:Copying training dataset
2024-07-03 14:27:59,302:INFO:Defining folds
2024-07-03 14:27:59,302:INFO:Declaring metric variables
2024-07-03 14:27:59,304:INFO:Importing untrained model
2024-07-03 14:27:59,306:INFO:Ridge Classifier Imported successfully
2024-07-03 14:27:59,311:INFO:Starting cross validation
2024-07-03 14:27:59,311:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:27:59,324:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.37152e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:27:59,399:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.52883e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:27:59,522:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.31264e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:27:59,645:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.5489e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:27:59,768:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.57491e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:27:59,892:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.40388e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:28:00,015:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.48847e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:28:00,139:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.59372e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:28:00,266:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.87456e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:28:00,362:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.36341e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 14:28:00,380:INFO:Calculating mean and std
2024-07-03 14:28:00,381:INFO:Creating metrics dataframe
2024-07-03 14:28:00,382:INFO:Uploading results into container
2024-07-03 14:28:00,382:INFO:Uploading model into container now
2024-07-03 14:28:00,383:INFO:_master_model_container: 6
2024-07-03 14:28:00,383:INFO:_display_container: 2
2024-07-03 14:28:00,383:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8888, solver='auto',
                tol=0.0001)
2024-07-03 14:28:00,383:INFO:create_model() successfully completed......................................
2024-07-03 14:28:00,440:INFO:SubProcess create_model() end ==================================
2024-07-03 14:28:00,440:INFO:Creating metrics dataframe
2024-07-03 14:28:00,446:INFO:Initializing Random Forest Classifier
2024-07-03 14:28:00,446:INFO:Total runtime is 0.11386557817459106 minutes
2024-07-03 14:28:00,449:INFO:SubProcess create_model() called ==================================
2024-07-03 14:28:00,449:INFO:Initializing create_model()
2024-07-03 14:28:00,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4ed10e3c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:28:00,449:INFO:Checking exceptions
2024-07-03 14:28:00,449:INFO:Importing libraries
2024-07-03 14:28:00,449:INFO:Copying training dataset
2024-07-03 14:28:00,455:INFO:Defining folds
2024-07-03 14:28:00,455:INFO:Declaring metric variables
2024-07-03 14:28:00,457:INFO:Importing untrained model
2024-07-03 14:28:00,459:INFO:Random Forest Classifier Imported successfully
2024-07-03 14:28:00,464:INFO:Starting cross validation
2024-07-03 14:28:00,465:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:28:03,109:INFO:Calculating mean and std
2024-07-03 14:28:03,110:INFO:Creating metrics dataframe
2024-07-03 14:28:03,112:INFO:Uploading results into container
2024-07-03 14:28:03,112:INFO:Uploading model into container now
2024-07-03 14:28:03,112:INFO:_master_model_container: 7
2024-07-03 14:28:03,112:INFO:_display_container: 2
2024-07-03 14:28:03,113:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 14:28:03,113:INFO:create_model() successfully completed......................................
2024-07-03 14:28:03,173:INFO:SubProcess create_model() end ==================================
2024-07-03 14:28:03,173:INFO:Creating metrics dataframe
2024-07-03 14:28:03,179:INFO:Initializing Quadratic Discriminant Analysis
2024-07-03 14:28:03,179:INFO:Total runtime is 0.15941415230433145 minutes
2024-07-03 14:28:03,182:INFO:SubProcess create_model() called ==================================
2024-07-03 14:28:03,182:INFO:Initializing create_model()
2024-07-03 14:28:03,182:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4ed10e3c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:28:03,182:INFO:Checking exceptions
2024-07-03 14:28:03,182:INFO:Importing libraries
2024-07-03 14:28:03,182:INFO:Copying training dataset
2024-07-03 14:28:03,187:INFO:Defining folds
2024-07-03 14:28:03,187:INFO:Declaring metric variables
2024-07-03 14:28:03,189:INFO:Importing untrained model
2024-07-03 14:28:03,191:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-03 14:28:03,195:INFO:Starting cross validation
2024-07-03 14:28:03,196:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:28:03,208:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:28:03,262:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:28:03,310:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:28:03,361:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:28:03,382:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 14:28:03,405:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:28:03,449:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:28:03,473:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 14:28:03,495:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:28:03,537:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:28:03,583:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:28:03,606:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 14:28:03,630:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 14:28:03,659:INFO:Calculating mean and std
2024-07-03 14:28:03,660:INFO:Creating metrics dataframe
2024-07-03 14:28:03,663:INFO:Uploading results into container
2024-07-03 14:28:03,663:INFO:Uploading model into container now
2024-07-03 14:28:03,664:INFO:_master_model_container: 8
2024-07-03 14:28:03,664:INFO:_display_container: 2
2024-07-03 14:28:03,664:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-03 14:28:03,664:INFO:create_model() successfully completed......................................
2024-07-03 14:28:03,749:INFO:SubProcess create_model() end ==================================
2024-07-03 14:28:03,749:INFO:Creating metrics dataframe
2024-07-03 14:28:03,756:INFO:Initializing Ada Boost Classifier
2024-07-03 14:28:03,756:INFO:Total runtime is 0.1690239389737447 minutes
2024-07-03 14:28:03,758:INFO:SubProcess create_model() called ==================================
2024-07-03 14:28:03,758:INFO:Initializing create_model()
2024-07-03 14:28:03,758:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4ed10e3c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:28:03,758:INFO:Checking exceptions
2024-07-03 14:28:03,759:INFO:Importing libraries
2024-07-03 14:28:03,759:INFO:Copying training dataset
2024-07-03 14:28:03,765:INFO:Defining folds
2024-07-03 14:28:03,765:INFO:Declaring metric variables
2024-07-03 14:28:03,768:INFO:Importing untrained model
2024-07-03 14:28:03,771:INFO:Ada Boost Classifier Imported successfully
2024-07-03 14:28:03,777:INFO:Starting cross validation
2024-07-03 14:28:03,778:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:28:03,790:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:28:03,958:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:28:04,117:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:28:04,280:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:28:04,440:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:28:04,604:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:28:04,763:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:28:04,923:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:28:05,082:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:28:05,242:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 14:28:05,399:INFO:Calculating mean and std
2024-07-03 14:28:05,399:INFO:Creating metrics dataframe
2024-07-03 14:28:05,400:INFO:Uploading results into container
2024-07-03 14:28:05,401:INFO:Uploading model into container now
2024-07-03 14:28:05,401:INFO:_master_model_container: 9
2024-07-03 14:28:05,401:INFO:_display_container: 2
2024-07-03 14:28:05,401:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8888)
2024-07-03 14:28:05,401:INFO:create_model() successfully completed......................................
2024-07-03 14:28:05,458:INFO:SubProcess create_model() end ==================================
2024-07-03 14:28:05,458:INFO:Creating metrics dataframe
2024-07-03 14:28:05,464:INFO:Initializing Gradient Boosting Classifier
2024-07-03 14:28:05,465:INFO:Total runtime is 0.1975014011065165 minutes
2024-07-03 14:28:05,467:INFO:SubProcess create_model() called ==================================
2024-07-03 14:28:05,467:INFO:Initializing create_model()
2024-07-03 14:28:05,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4ed10e3c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:28:05,467:INFO:Checking exceptions
2024-07-03 14:28:05,467:INFO:Importing libraries
2024-07-03 14:28:05,467:INFO:Copying training dataset
2024-07-03 14:28:05,472:INFO:Defining folds
2024-07-03 14:28:05,472:INFO:Declaring metric variables
2024-07-03 14:28:05,474:INFO:Importing untrained model
2024-07-03 14:28:05,477:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 14:28:05,481:INFO:Starting cross validation
2024-07-03 14:28:05,482:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:28:09,823:INFO:Calculating mean and std
2024-07-03 14:28:09,824:INFO:Creating metrics dataframe
2024-07-03 14:28:09,825:INFO:Uploading results into container
2024-07-03 14:28:09,825:INFO:Uploading model into container now
2024-07-03 14:28:09,826:INFO:_master_model_container: 10
2024-07-03 14:28:09,826:INFO:_display_container: 2
2024-07-03 14:28:09,826:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 14:28:09,826:INFO:create_model() successfully completed......................................
2024-07-03 14:28:09,892:INFO:SubProcess create_model() end ==================================
2024-07-03 14:28:09,892:INFO:Creating metrics dataframe
2024-07-03 14:28:09,899:INFO:Initializing Linear Discriminant Analysis
2024-07-03 14:28:09,900:INFO:Total runtime is 0.27141873439153036 minutes
2024-07-03 14:28:09,903:INFO:SubProcess create_model() called ==================================
2024-07-03 14:28:09,903:INFO:Initializing create_model()
2024-07-03 14:28:09,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4ed10e3c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:28:09,903:INFO:Checking exceptions
2024-07-03 14:28:09,903:INFO:Importing libraries
2024-07-03 14:28:09,903:INFO:Copying training dataset
2024-07-03 14:28:09,908:INFO:Defining folds
2024-07-03 14:28:09,908:INFO:Declaring metric variables
2024-07-03 14:28:09,910:INFO:Importing untrained model
2024-07-03 14:28:09,912:INFO:Linear Discriminant Analysis Imported successfully
2024-07-03 14:28:09,917:INFO:Starting cross validation
2024-07-03 14:28:09,918:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:28:10,400:INFO:Calculating mean and std
2024-07-03 14:28:10,402:INFO:Creating metrics dataframe
2024-07-03 14:28:10,404:INFO:Uploading results into container
2024-07-03 14:28:10,405:INFO:Uploading model into container now
2024-07-03 14:28:10,405:INFO:_master_model_container: 11
2024-07-03 14:28:10,405:INFO:_display_container: 2
2024-07-03 14:28:10,406:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-03 14:28:10,406:INFO:create_model() successfully completed......................................
2024-07-03 14:28:10,490:INFO:SubProcess create_model() end ==================================
2024-07-03 14:28:10,490:INFO:Creating metrics dataframe
2024-07-03 14:28:10,497:INFO:Initializing Extra Trees Classifier
2024-07-03 14:28:10,497:INFO:Total runtime is 0.28138330777486165 minutes
2024-07-03 14:28:10,500:INFO:SubProcess create_model() called ==================================
2024-07-03 14:28:10,501:INFO:Initializing create_model()
2024-07-03 14:28:10,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4ed10e3c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:28:10,501:INFO:Checking exceptions
2024-07-03 14:28:10,501:INFO:Importing libraries
2024-07-03 14:28:10,501:INFO:Copying training dataset
2024-07-03 14:28:10,507:INFO:Defining folds
2024-07-03 14:28:10,507:INFO:Declaring metric variables
2024-07-03 14:28:10,510:INFO:Importing untrained model
2024-07-03 14:28:10,513:INFO:Extra Trees Classifier Imported successfully
2024-07-03 14:28:10,519:INFO:Starting cross validation
2024-07-03 14:28:10,520:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:28:12,857:INFO:Calculating mean and std
2024-07-03 14:28:12,858:INFO:Creating metrics dataframe
2024-07-03 14:28:12,860:INFO:Uploading results into container
2024-07-03 14:28:12,860:INFO:Uploading model into container now
2024-07-03 14:28:12,861:INFO:_master_model_container: 12
2024-07-03 14:28:12,861:INFO:_display_container: 2
2024-07-03 14:28:12,861:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8888, verbose=0,
                     warm_start=False)
2024-07-03 14:28:12,861:INFO:create_model() successfully completed......................................
2024-07-03 14:28:12,920:INFO:SubProcess create_model() end ==================================
2024-07-03 14:28:12,920:INFO:Creating metrics dataframe
2024-07-03 14:28:12,927:INFO:Initializing Light Gradient Boosting Machine
2024-07-03 14:28:12,927:INFO:Total runtime is 0.32188016176223755 minutes
2024-07-03 14:28:12,929:INFO:SubProcess create_model() called ==================================
2024-07-03 14:28:12,930:INFO:Initializing create_model()
2024-07-03 14:28:12,930:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4ed10e3c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:28:12,930:INFO:Checking exceptions
2024-07-03 14:28:12,930:INFO:Importing libraries
2024-07-03 14:28:12,930:INFO:Copying training dataset
2024-07-03 14:28:12,934:INFO:Defining folds
2024-07-03 14:28:12,934:INFO:Declaring metric variables
2024-07-03 14:28:12,937:INFO:Importing untrained model
2024-07-03 14:28:12,939:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-03 14:28:12,944:INFO:Starting cross validation
2024-07-03 14:28:12,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:28:12,975:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 14:28:12,975:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 14:28:12,977:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 14:28:12,978:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 14:28:13,193:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 14:28:13,193:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 14:28:13,249:WARNING:1 warning generated.
2024-07-03 14:28:13,573:WARNING:1 warning generated.
2024-07-03 14:28:13,986:WARNING:1 warning generated.
2024-07-03 14:28:14,073:WARNING:1 warning generated.
2024-07-03 14:28:14,147:WARNING:1 warning generated.
2024-07-03 14:28:14,227:WARNING:1 warning generated.
2024-07-03 14:28:14,309:WARNING:1 warning generated.
2024-07-03 14:28:14,726:WARNING:1 warning generated.
2024-07-03 14:28:15,164:WARNING:1 warning generated.
2024-07-03 14:28:15,392:WARNING:1 warning generated.
2024-07-03 14:28:15,500:WARNING:1 warning generated.
2024-07-03 14:28:15,888:WARNING:1 warning generated.
2024-07-03 14:28:16,319:WARNING:1 warning generated.
2024-07-03 14:28:16,546:WARNING:1 warning generated.
2024-07-03 14:28:16,711:WARNING:1 warning generated.
2024-07-03 14:28:17,150:WARNING:1 warning generated.
2024-07-03 14:28:17,558:WARNING:1 warning generated.
2024-07-03 14:28:17,704:WARNING:1 warning generated.
2024-07-03 14:28:17,785:WARNING:1 warning generated.
2024-07-03 14:28:18,057:WARNING:1 warning generated.
2024-07-03 14:28:18,451:WARNING:1 warning generated.
2024-07-03 14:28:18,846:WARNING:1 warning generated.
2024-07-03 14:28:18,936:WARNING:1 warning generated.
2024-07-03 14:28:19,023:WARNING:1 warning generated.
2024-07-03 14:28:19,105:WARNING:1 warning generated.
2024-07-03 14:28:19,550:WARNING:1 warning generated.
2024-07-03 14:28:20,005:WARNING:1 warning generated.
2024-07-03 14:28:20,178:WARNING:1 warning generated.
2024-07-03 14:28:20,627:WARNING:1 warning generated.
2024-07-03 14:28:20,944:WARNING:1 warning generated.
2024-07-03 14:28:21,235:WARNING:1 warning generated.
2024-07-03 14:28:21,313:WARNING:1 warning generated.
2024-07-03 14:28:21,975:WARNING:1 warning generated.
2024-07-03 14:28:22,375:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 14:28:22,378:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 14:28:22,378:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000276 secs. 1 sparse feature groups
2024-07-03 14:28:22,378:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 14:28:22,378:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 14:28:24,134:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 14:28:24,134:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 14:28:24,135:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 14:28:24,136:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 14:28:24,349:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 14:28:24,350:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 14:28:24,410:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 14:28:24,416:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 14:28:24,417:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000892 secs. 1 sparse feature groups
2024-07-03 14:28:24,418:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 14:28:24,418:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 14:28:25,854:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 14:28:25,854:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 14:28:25,856:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-03 14:28:25,856:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 14:28:26,056:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 14:28:26,056:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 14:28:26,109:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 14:28:26,114:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 14:28:26,116:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000947 secs. 1 sparse feature groups
2024-07-03 14:28:26,116:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 14:28:26,117:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 14:28:27,789:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 14:28:27,789:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 14:28:27,789:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 14:28:27,789:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 14:28:27,847:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 14:28:27,847:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 14:28:27,852:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 14:28:27,853:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 14:28:27,854:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000244 secs. 1 sparse feature groups
2024-07-03 14:28:27,854:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 14:28:27,854:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 14:28:29,379:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 14:28:29,380:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 14:28:29,381:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-03 14:28:29,382:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 14:28:29,598:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 14:28:29,598:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 14:28:29,659:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 14:28:29,664:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 14:28:29,666:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000953 secs. 1 sparse feature groups
2024-07-03 14:28:29,666:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 14:28:29,667:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 14:28:31,097:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 14:28:31,097:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 14:28:31,097:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-03 14:28:31,097:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 14:28:31,153:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 14:28:31,154:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 14:28:31,159:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 14:28:31,160:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 14:28:31,160:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000223 secs. 1 sparse feature groups
2024-07-03 14:28:31,160:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 14:28:31,160:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 14:28:32,848:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 14:28:32,849:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 14:28:32,850:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 14:28:32,850:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 14:28:33,063:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 14:28:33,063:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 14:28:33,119:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 14:28:33,125:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 14:28:33,126:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000974 secs. 1 sparse feature groups
2024-07-03 14:28:33,127:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 14:28:33,127:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 14:28:34,709:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 14:28:34,709:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 14:28:34,711:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-03 14:28:34,711:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 14:28:34,927:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 14:28:34,927:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 14:28:34,983:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 14:28:34,989:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 14:28:34,990:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000963 secs. 1 sparse feature groups
2024-07-03 14:28:34,991:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 14:28:34,991:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 14:28:36,674:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 14:28:36,675:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 14:28:36,676:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 14:28:36,676:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 14:28:36,885:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 14:28:36,885:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 14:28:36,955:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 14:28:36,961:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 14:28:36,964:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.002454 secs. 1 sparse feature groups
2024-07-03 14:28:36,964:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 14:28:36,965:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 14:28:38,709:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 14:28:38,709:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 14:28:38,710:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 14:28:38,710:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 14:28:38,767:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 14:28:38,767:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 14:28:38,772:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 14:28:38,773:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 14:28:38,773:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000223 secs. 1 sparse feature groups
2024-07-03 14:28:38,774:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 14:28:38,774:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 14:28:40,210:INFO:Calculating mean and std
2024-07-03 14:28:40,214:INFO:Creating metrics dataframe
2024-07-03 14:28:40,219:INFO:Uploading results into container
2024-07-03 14:28:40,221:INFO:Uploading model into container now
2024-07-03 14:28:40,222:INFO:_master_model_container: 13
2024-07-03 14:28:40,222:INFO:_display_container: 2
2024-07-03 14:28:40,223:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=8888, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-07-03 14:28:40,223:INFO:create_model() successfully completed......................................
2024-07-03 14:28:40,387:INFO:SubProcess create_model() end ==================================
2024-07-03 14:28:40,387:INFO:Creating metrics dataframe
2024-07-03 14:28:40,425:INFO:Initializing Dummy Classifier
2024-07-03 14:28:40,425:INFO:Total runtime is 0.7801786184310913 minutes
2024-07-03 14:28:40,436:INFO:SubProcess create_model() called ==================================
2024-07-03 14:28:40,437:INFO:Initializing create_model()
2024-07-03 14:28:40,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4ed10e3c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:28:40,439:INFO:Checking exceptions
2024-07-03 14:28:40,439:INFO:Importing libraries
2024-07-03 14:28:40,439:INFO:Copying training dataset
2024-07-03 14:28:40,463:INFO:Defining folds
2024-07-03 14:28:40,466:INFO:Declaring metric variables
2024-07-03 14:28:40,477:INFO:Importing untrained model
2024-07-03 14:28:40,490:INFO:Dummy Classifier Imported successfully
2024-07-03 14:28:40,514:INFO:Starting cross validation
2024-07-03 14:28:40,517:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:28:41,011:INFO:Calculating mean and std
2024-07-03 14:28:41,012:INFO:Creating metrics dataframe
2024-07-03 14:28:41,013:INFO:Uploading results into container
2024-07-03 14:28:41,013:INFO:Uploading model into container now
2024-07-03 14:28:41,013:INFO:_master_model_container: 14
2024-07-03 14:28:41,013:INFO:_display_container: 2
2024-07-03 14:28:41,014:INFO:DummyClassifier(constant=None, random_state=8888, strategy='prior')
2024-07-03 14:28:41,014:INFO:create_model() successfully completed......................................
2024-07-03 14:28:41,070:INFO:SubProcess create_model() end ==================================
2024-07-03 14:28:41,070:INFO:Creating metrics dataframe
2024-07-03 14:28:41,079:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-03 14:28:41,086:INFO:Initializing create_model()
2024-07-03 14:28:41,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:28:41,086:INFO:Checking exceptions
2024-07-03 14:28:41,087:INFO:Importing libraries
2024-07-03 14:28:41,087:INFO:Copying training dataset
2024-07-03 14:28:41,092:INFO:Defining folds
2024-07-03 14:28:41,092:INFO:Declaring metric variables
2024-07-03 14:28:41,092:INFO:Importing untrained model
2024-07-03 14:28:41,092:INFO:Declaring custom model
2024-07-03 14:28:41,093:INFO:Random Forest Classifier Imported successfully
2024-07-03 14:28:41,094:INFO:Cross validation set to False
2024-07-03 14:28:41,094:INFO:Fitting Model
2024-07-03 14:28:41,291:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 14:28:41,291:INFO:create_model() successfully completed......................................
2024-07-03 14:28:41,368:INFO:_master_model_container: 14
2024-07-03 14:28:41,368:INFO:_display_container: 2
2024-07-03 14:28:41,369:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 14:28:41,369:INFO:compare_models() successfully completed......................................
2024-07-03 14:45:48,642:INFO:Initializing tune_model()
2024-07-03 14:45:48,642:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=gbc, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-03 14:45:48,642:INFO:Checking exceptions
2024-07-03 14:46:38,215:INFO:Initializing create_model()
2024-07-03 14:46:38,215:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:46:38,215:INFO:Checking exceptions
2024-07-03 14:46:38,229:INFO:Importing libraries
2024-07-03 14:46:38,229:INFO:Copying training dataset
2024-07-03 14:46:38,234:INFO:Defining folds
2024-07-03 14:46:38,234:INFO:Declaring metric variables
2024-07-03 14:46:38,237:INFO:Importing untrained model
2024-07-03 14:46:38,240:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 14:46:38,246:INFO:Starting cross validation
2024-07-03 14:46:38,246:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:46:42,610:INFO:Calculating mean and std
2024-07-03 14:46:42,611:INFO:Creating metrics dataframe
2024-07-03 14:46:42,614:INFO:Finalizing model
2024-07-03 14:46:43,068:INFO:Uploading results into container
2024-07-03 14:46:43,069:INFO:Uploading model into container now
2024-07-03 14:46:43,078:INFO:_master_model_container: 15
2024-07-03 14:46:43,078:INFO:_display_container: 3
2024-07-03 14:46:43,079:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 14:46:43,079:INFO:create_model() successfully completed......................................
2024-07-03 14:47:04,856:INFO:Initializing create_model()
2024-07-03 14:47:04,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=gbc, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:47:04,857:INFO:Checking exceptions
2024-07-03 14:47:04,868:INFO:Importing libraries
2024-07-03 14:47:04,868:INFO:Copying training dataset
2024-07-03 14:47:04,875:INFO:Defining folds
2024-07-03 14:47:04,875:INFO:Declaring metric variables
2024-07-03 14:47:04,879:INFO:Importing untrained model
2024-07-03 14:47:04,882:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 14:47:04,888:INFO:Starting cross validation
2024-07-03 14:47:04,889:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:47:06,869:INFO:Calculating mean and std
2024-07-03 14:47:06,870:INFO:Creating metrics dataframe
2024-07-03 14:47:06,873:INFO:Finalizing model
2024-07-03 14:47:07,321:INFO:Uploading results into container
2024-07-03 14:47:07,322:INFO:Uploading model into container now
2024-07-03 14:47:07,328:INFO:_master_model_container: 16
2024-07-03 14:47:07,328:INFO:_display_container: 4
2024-07-03 14:47:07,329:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 14:47:07,329:INFO:create_model() successfully completed......................................
2024-07-03 14:47:21,647:INFO:Initializing tune_model()
2024-07-03 14:47:21,647:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=gbc, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-03 14:47:21,648:INFO:Checking exceptions
2024-07-03 14:48:30,743:INFO:Initializing tune_model()
2024-07-03 14:48:30,743:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=gbc, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-03 14:48:30,743:INFO:Checking exceptions
2024-07-03 14:49:02,445:INFO:Initializing tune_model()
2024-07-03 14:49:02,445:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-03 14:49:02,445:INFO:Checking exceptions
2024-07-03 14:49:02,460:INFO:Copying training dataset
2024-07-03 14:49:02,465:INFO:Checking base model
2024-07-03 14:49:02,465:INFO:Base model : Gradient Boosting Classifier
2024-07-03 14:49:02,467:INFO:Declaring metric variables
2024-07-03 14:49:02,470:INFO:Defining Hyperparameters
2024-07-03 14:49:02,547:INFO:Tuning with n_jobs=-1
2024-07-03 14:49:02,548:INFO:Initializing RandomizedSearchCV
2024-07-03 14:49:40,174:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.2, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.001}
2024-07-03 14:49:40,175:INFO:Hyperparameter search completed
2024-07-03 14:49:40,175:INFO:SubProcess create_model() called ==================================
2024-07-03 14:49:40,175:INFO:Initializing create_model()
2024-07-03 14:49:40,175:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4edc94eed0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'n_estimators': 160, 'min_samples_split': 7, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.2, 'max_features': 'log2', 'max_depth': 9, 'learning_rate': 0.001})
2024-07-03 14:49:40,176:INFO:Checking exceptions
2024-07-03 14:49:40,176:INFO:Importing libraries
2024-07-03 14:49:40,176:INFO:Copying training dataset
2024-07-03 14:49:40,182:INFO:Defining folds
2024-07-03 14:49:40,182:INFO:Declaring metric variables
2024-07-03 14:49:40,185:INFO:Importing untrained model
2024-07-03 14:49:40,185:INFO:Declaring custom model
2024-07-03 14:49:40,188:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 14:49:40,192:INFO:Starting cross validation
2024-07-03 14:49:40,192:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:49:51,047:INFO:Calculating mean and std
2024-07-03 14:49:51,048:INFO:Creating metrics dataframe
2024-07-03 14:49:51,052:INFO:Finalizing model
2024-07-03 14:49:52,199:INFO:Uploading results into container
2024-07-03 14:49:52,200:INFO:Uploading model into container now
2024-07-03 14:49:52,200:INFO:_master_model_container: 17
2024-07-03 14:49:52,200:INFO:_display_container: 5
2024-07-03 14:49:52,201:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 14:49:52,201:INFO:create_model() successfully completed......................................
2024-07-03 14:49:52,293:INFO:SubProcess create_model() end ==================================
2024-07-03 14:49:52,293:INFO:choose_better activated
2024-07-03 14:49:52,296:INFO:SubProcess create_model() called ==================================
2024-07-03 14:49:52,296:INFO:Initializing create_model()
2024-07-03 14:49:52,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:49:52,296:INFO:Checking exceptions
2024-07-03 14:49:52,297:INFO:Importing libraries
2024-07-03 14:49:52,297:INFO:Copying training dataset
2024-07-03 14:49:52,302:INFO:Defining folds
2024-07-03 14:49:52,302:INFO:Declaring metric variables
2024-07-03 14:49:52,302:INFO:Importing untrained model
2024-07-03 14:49:52,302:INFO:Declaring custom model
2024-07-03 14:49:52,303:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 14:49:52,303:INFO:Starting cross validation
2024-07-03 14:49:52,303:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:49:56,638:INFO:Calculating mean and std
2024-07-03 14:49:56,639:INFO:Creating metrics dataframe
2024-07-03 14:49:56,640:INFO:Finalizing model
2024-07-03 14:49:57,092:INFO:Uploading results into container
2024-07-03 14:49:57,093:INFO:Uploading model into container now
2024-07-03 14:49:57,093:INFO:_master_model_container: 18
2024-07-03 14:49:57,093:INFO:_display_container: 6
2024-07-03 14:49:57,093:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 14:49:57,093:INFO:create_model() successfully completed......................................
2024-07-03 14:49:57,166:INFO:SubProcess create_model() end ==================================
2024-07-03 14:49:57,166:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.7896
2024-07-03 14:49:57,166:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.7936
2024-07-03 14:49:57,167:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-07-03 14:49:57,167:INFO:choose_better completed
2024-07-03 14:49:57,173:INFO:_master_model_container: 18
2024-07-03 14:49:57,174:INFO:_display_container: 5
2024-07-03 14:49:57,174:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 14:49:57,174:INFO:tune_model() successfully completed......................................
2024-07-03 14:56:34,229:INFO:Initializing tune_model()
2024-07-03 14:56:34,229:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-03 14:56:34,229:INFO:Checking exceptions
2024-07-03 14:56:34,255:INFO:Copying training dataset
2024-07-03 14:56:34,259:INFO:Checking base model
2024-07-03 14:56:34,259:INFO:Base model : Gradient Boosting Classifier
2024-07-03 14:56:34,263:INFO:Declaring metric variables
2024-07-03 14:56:34,266:INFO:Defining Hyperparameters
2024-07-03 14:56:34,344:INFO:Tuning with n_jobs=-1
2024-07-03 14:56:34,344:INFO:Initializing RandomizedSearchCV
2024-07-03 14:57:01,993:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.2, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.001}
2024-07-03 14:57:01,994:INFO:Hyperparameter search completed
2024-07-03 14:57:01,995:INFO:SubProcess create_model() called ==================================
2024-07-03 14:57:01,995:INFO:Initializing create_model()
2024-07-03 14:57:01,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4ed9287510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'n_estimators': 160, 'min_samples_split': 7, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.2, 'max_features': 'log2', 'max_depth': 9, 'learning_rate': 0.001})
2024-07-03 14:57:01,995:INFO:Checking exceptions
2024-07-03 14:57:01,995:INFO:Importing libraries
2024-07-03 14:57:01,995:INFO:Copying training dataset
2024-07-03 14:57:02,003:INFO:Defining folds
2024-07-03 14:57:02,003:INFO:Declaring metric variables
2024-07-03 14:57:02,006:INFO:Importing untrained model
2024-07-03 14:57:02,006:INFO:Declaring custom model
2024-07-03 14:57:02,011:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 14:57:02,018:INFO:Starting cross validation
2024-07-03 14:57:02,018:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:57:13,502:INFO:Calculating mean and std
2024-07-03 14:57:13,503:INFO:Creating metrics dataframe
2024-07-03 14:57:13,506:INFO:Finalizing model
2024-07-03 14:57:14,660:INFO:Uploading results into container
2024-07-03 14:57:14,661:INFO:Uploading model into container now
2024-07-03 14:57:14,661:INFO:_master_model_container: 19
2024-07-03 14:57:14,661:INFO:_display_container: 6
2024-07-03 14:57:14,662:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 14:57:14,662:INFO:create_model() successfully completed......................................
2024-07-03 14:57:14,750:INFO:SubProcess create_model() end ==================================
2024-07-03 14:57:14,750:INFO:choose_better activated
2024-07-03 14:57:14,752:INFO:SubProcess create_model() called ==================================
2024-07-03 14:57:14,753:INFO:Initializing create_model()
2024-07-03 14:57:14,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 14:57:14,753:INFO:Checking exceptions
2024-07-03 14:57:14,754:INFO:Importing libraries
2024-07-03 14:57:14,754:INFO:Copying training dataset
2024-07-03 14:57:14,758:INFO:Defining folds
2024-07-03 14:57:14,759:INFO:Declaring metric variables
2024-07-03 14:57:14,759:INFO:Importing untrained model
2024-07-03 14:57:14,759:INFO:Declaring custom model
2024-07-03 14:57:14,759:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 14:57:14,759:INFO:Starting cross validation
2024-07-03 14:57:14,760:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 14:57:19,120:INFO:Calculating mean and std
2024-07-03 14:57:19,121:INFO:Creating metrics dataframe
2024-07-03 14:57:19,122:INFO:Finalizing model
2024-07-03 14:57:19,576:INFO:Uploading results into container
2024-07-03 14:57:19,577:INFO:Uploading model into container now
2024-07-03 14:57:19,577:INFO:_master_model_container: 20
2024-07-03 14:57:19,577:INFO:_display_container: 7
2024-07-03 14:57:19,577:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 14:57:19,577:INFO:create_model() successfully completed......................................
2024-07-03 14:57:19,651:INFO:SubProcess create_model() end ==================================
2024-07-03 14:57:19,652:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.7896
2024-07-03 14:57:19,652:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.7936
2024-07-03 14:57:19,652:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-07-03 14:57:19,652:INFO:choose_better completed
2024-07-03 14:57:19,659:INFO:_master_model_container: 20
2024-07-03 14:57:19,659:INFO:_display_container: 6
2024-07-03 14:57:19,659:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 14:57:19,659:INFO:tune_model() successfully completed......................................
2024-07-03 14:57:32,153:INFO:Initializing evaluate_model()
2024-07-03 14:57:32,153:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-07-03 14:57:32,163:INFO:Initializing plot_model()
2024-07-03 14:57:32,163:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 14:57:32,163:INFO:Checking exceptions
2024-07-03 14:57:32,166:INFO:Preloading libraries
2024-07-03 14:57:32,177:INFO:Copying training dataset
2024-07-03 14:57:32,177:INFO:Plot type: pipeline
2024-07-03 14:57:32,283:INFO:Visual Rendered Successfully
2024-07-03 14:57:32,382:INFO:plot_model() successfully completed......................................
2024-07-03 14:57:45,382:INFO:Initializing plot_model()
2024-07-03 14:57:45,382:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=parameter, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 14:57:45,382:INFO:Checking exceptions
2024-07-03 14:57:45,388:INFO:Preloading libraries
2024-07-03 14:57:45,398:INFO:Copying training dataset
2024-07-03 14:57:45,398:INFO:Plot type: parameter
2024-07-03 14:57:45,401:INFO:Visual Rendered Successfully
2024-07-03 14:57:45,485:INFO:plot_model() successfully completed......................................
2024-07-03 14:57:49,925:INFO:Initializing plot_model()
2024-07-03 14:57:49,925:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 14:57:49,925:INFO:Checking exceptions
2024-07-03 14:57:49,928:INFO:Preloading libraries
2024-07-03 14:57:49,938:INFO:Copying training dataset
2024-07-03 14:57:49,938:INFO:Plot type: auc
2024-07-03 14:57:49,999:INFO:Fitting Model
2024-07-03 14:57:50,000:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2024-07-03 14:57:50,000:INFO:Scoring test/hold-out set
2024-07-03 14:57:50,183:INFO:Visual Rendered Successfully
2024-07-03 14:57:50,264:INFO:plot_model() successfully completed......................................
2024-07-03 14:57:52,089:INFO:Initializing plot_model()
2024-07-03 14:57:52,089:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 14:57:52,089:INFO:Checking exceptions
2024-07-03 14:57:52,093:INFO:Preloading libraries
2024-07-03 14:57:52,103:INFO:Copying training dataset
2024-07-03 14:57:52,103:INFO:Plot type: confusion_matrix
2024-07-03 14:57:52,168:INFO:Fitting Model
2024-07-03 14:57:52,168:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2024-07-03 14:57:52,168:INFO:Scoring test/hold-out set
2024-07-03 14:57:52,311:INFO:Visual Rendered Successfully
2024-07-03 14:57:52,393:INFO:plot_model() successfully completed......................................
2024-07-03 14:58:06,071:INFO:Initializing plot_model()
2024-07-03 14:58:06,072:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=threshold, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 14:58:06,072:INFO:Checking exceptions
2024-07-03 14:58:06,076:INFO:Preloading libraries
2024-07-03 14:58:06,085:INFO:Copying training dataset
2024-07-03 14:58:06,085:INFO:Plot type: threshold
2024-07-03 14:58:06,146:INFO:Fitting Model
2024-07-03 14:58:59,382:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2024-07-03 14:58:59,397:INFO:Scoring test/hold-out set
2024-07-03 14:58:59,612:INFO:Visual Rendered Successfully
2024-07-03 14:58:59,695:INFO:plot_model() successfully completed......................................
2024-07-03 14:59:04,517:INFO:Initializing plot_model()
2024-07-03 14:59:04,517:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pr, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 14:59:04,517:INFO:Checking exceptions
2024-07-03 14:59:04,521:INFO:Preloading libraries
2024-07-03 14:59:04,530:INFO:Copying training dataset
2024-07-03 14:59:04,530:INFO:Plot type: pr
2024-07-03 14:59:04,591:INFO:Fitting Model
2024-07-03 14:59:04,592:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2024-07-03 14:59:04,592:INFO:Scoring test/hold-out set
2024-07-03 14:59:04,768:INFO:Visual Rendered Successfully
2024-07-03 14:59:04,844:INFO:plot_model() successfully completed......................................
2024-07-03 14:59:09,294:INFO:Initializing plot_model()
2024-07-03 14:59:09,294:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=error, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 14:59:09,294:INFO:Checking exceptions
2024-07-03 14:59:09,298:INFO:Preloading libraries
2024-07-03 14:59:09,307:INFO:Copying training dataset
2024-07-03 14:59:09,307:INFO:Plot type: error
2024-07-03 14:59:09,368:INFO:Fitting Model
2024-07-03 14:59:09,368:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2024-07-03 14:59:09,368:INFO:Scoring test/hold-out set
2024-07-03 14:59:09,877:INFO:Visual Rendered Successfully
2024-07-03 14:59:10,096:INFO:plot_model() successfully completed......................................
2024-07-03 14:59:15,031:INFO:Initializing plot_model()
2024-07-03 14:59:15,031:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=class_report, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 14:59:15,031:INFO:Checking exceptions
2024-07-03 14:59:15,035:INFO:Preloading libraries
2024-07-03 14:59:15,045:INFO:Copying training dataset
2024-07-03 14:59:15,045:INFO:Plot type: class_report
2024-07-03 14:59:15,106:INFO:Fitting Model
2024-07-03 14:59:15,106:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2024-07-03 14:59:15,106:INFO:Scoring test/hold-out set
2024-07-03 14:59:15,301:INFO:Visual Rendered Successfully
2024-07-03 14:59:15,388:INFO:plot_model() successfully completed......................................
2024-07-03 15:36:40,841:INFO:Initializing create_model()
2024-07-03 15:36:40,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 15:36:40,841:INFO:Checking exceptions
2024-07-03 15:36:40,855:INFO:Importing libraries
2024-07-03 15:36:40,855:INFO:Copying training dataset
2024-07-03 15:36:40,860:INFO:Defining folds
2024-07-03 15:36:40,860:INFO:Declaring metric variables
2024-07-03 15:36:40,862:INFO:Importing untrained model
2024-07-03 15:36:40,865:INFO:Random Forest Classifier Imported successfully
2024-07-03 15:36:40,869:INFO:Starting cross validation
2024-07-03 15:36:40,870:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-07-03 15:36:42,085:INFO:Calculating mean and std
2024-07-03 15:36:42,086:INFO:Creating metrics dataframe
2024-07-03 15:36:42,091:INFO:Finalizing model
2024-07-03 15:36:42,272:INFO:Uploading results into container
2024-07-03 15:36:42,273:INFO:Uploading model into container now
2024-07-03 15:36:42,280:INFO:_master_model_container: 21
2024-07-03 15:36:42,280:INFO:_display_container: 7
2024-07-03 15:36:42,280:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 15:36:42,280:INFO:create_model() successfully completed......................................
2024-07-03 15:36:45,640:INFO:Initializing tune_model()
2024-07-03 15:36:45,640:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-03 15:36:45,640:INFO:Checking exceptions
2024-07-03 15:36:45,653:INFO:Copying training dataset
2024-07-03 15:36:45,657:INFO:Checking base model
2024-07-03 15:36:45,657:INFO:Base model : Random Forest Classifier
2024-07-03 15:36:45,660:INFO:Declaring metric variables
2024-07-03 15:36:45,663:INFO:Defining Hyperparameters
2024-07-03 15:36:45,745:INFO:Tuning with n_jobs=-1
2024-07-03 15:36:45,745:INFO:Initializing RandomizedSearchCV
2024-07-03 15:37:03,976:INFO:best_params: {'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2024-07-03 15:37:03,977:INFO:Hyperparameter search completed
2024-07-03 15:37:03,977:INFO:SubProcess create_model() called ==================================
2024-07-03 15:37:03,977:INFO:Initializing create_model()
2024-07-03 15:37:03,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4ed9e48450>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 160, 'min_samples_split': 7, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2024-07-03 15:37:03,977:INFO:Checking exceptions
2024-07-03 15:37:03,978:INFO:Importing libraries
2024-07-03 15:37:03,978:INFO:Copying training dataset
2024-07-03 15:37:03,984:INFO:Defining folds
2024-07-03 15:37:03,984:INFO:Declaring metric variables
2024-07-03 15:37:03,987:INFO:Importing untrained model
2024-07-03 15:37:03,987:INFO:Declaring custom model
2024-07-03 15:37:03,990:INFO:Random Forest Classifier Imported successfully
2024-07-03 15:37:03,995:INFO:Starting cross validation
2024-07-03 15:37:03,996:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 15:37:08,866:INFO:Calculating mean and std
2024-07-03 15:37:08,867:INFO:Creating metrics dataframe
2024-07-03 15:37:08,871:INFO:Finalizing model
2024-07-03 15:37:09,143:INFO:Uploading results into container
2024-07-03 15:37:09,144:INFO:Uploading model into container now
2024-07-03 15:37:09,144:INFO:_master_model_container: 22
2024-07-03 15:37:09,144:INFO:_display_container: 8
2024-07-03 15:37:09,145:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False)
2024-07-03 15:37:09,145:INFO:create_model() successfully completed......................................
2024-07-03 15:37:09,238:INFO:SubProcess create_model() end ==================================
2024-07-03 15:37:09,238:INFO:choose_better activated
2024-07-03 15:37:09,241:INFO:SubProcess create_model() called ==================================
2024-07-03 15:37:09,241:INFO:Initializing create_model()
2024-07-03 15:37:09,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 15:37:09,241:INFO:Checking exceptions
2024-07-03 15:37:09,242:INFO:Importing libraries
2024-07-03 15:37:09,242:INFO:Copying training dataset
2024-07-03 15:37:09,249:INFO:Defining folds
2024-07-03 15:37:09,249:INFO:Declaring metric variables
2024-07-03 15:37:09,249:INFO:Importing untrained model
2024-07-03 15:37:09,249:INFO:Declaring custom model
2024-07-03 15:37:09,249:INFO:Random Forest Classifier Imported successfully
2024-07-03 15:37:09,250:INFO:Starting cross validation
2024-07-03 15:37:09,250:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 15:37:12,046:INFO:Calculating mean and std
2024-07-03 15:37:12,047:INFO:Creating metrics dataframe
2024-07-03 15:37:12,048:INFO:Finalizing model
2024-07-03 15:37:12,233:INFO:Uploading results into container
2024-07-03 15:37:12,234:INFO:Uploading model into container now
2024-07-03 15:37:12,234:INFO:_master_model_container: 23
2024-07-03 15:37:12,234:INFO:_display_container: 9
2024-07-03 15:37:12,234:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 15:37:12,234:INFO:create_model() successfully completed......................................
2024-07-03 15:37:12,317:INFO:SubProcess create_model() end ==================================
2024-07-03 15:37:12,317:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False) result for Accuracy is 0.79
2024-07-03 15:37:12,317:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False) result for Accuracy is 0.7936
2024-07-03 15:37:12,318:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False) is best model
2024-07-03 15:37:12,318:INFO:choose_better completed
2024-07-03 15:37:12,325:INFO:_master_model_container: 23
2024-07-03 15:37:12,325:INFO:_display_container: 8
2024-07-03 15:37:12,325:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False)
2024-07-03 15:37:12,325:INFO:tune_model() successfully completed......................................
2024-07-03 15:37:24,100:INFO:Initializing evaluate_model()
2024-07-03 15:37:24,100:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-07-03 15:37:24,111:INFO:Initializing plot_model()
2024-07-03 15:37:24,111:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 15:37:24,111:INFO:Checking exceptions
2024-07-03 15:37:24,140:INFO:Preloading libraries
2024-07-03 15:37:24,160:INFO:Copying training dataset
2024-07-03 15:37:24,160:INFO:Plot type: pipeline
2024-07-03 15:37:24,279:INFO:Visual Rendered Successfully
2024-07-03 15:37:24,407:INFO:plot_model() successfully completed......................................
2024-07-03 15:37:27,913:INFO:Initializing plot_model()
2024-07-03 15:37:27,914:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False), plot=parameter, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 15:37:27,914:INFO:Checking exceptions
2024-07-03 15:37:27,996:INFO:Preloading libraries
2024-07-03 15:37:28,024:INFO:Copying training dataset
2024-07-03 15:37:28,024:INFO:Plot type: parameter
2024-07-03 15:37:28,028:INFO:Visual Rendered Successfully
2024-07-03 15:37:28,110:INFO:plot_model() successfully completed......................................
2024-07-03 15:37:29,941:INFO:Initializing plot_model()
2024-07-03 15:37:29,941:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 15:37:29,941:INFO:Checking exceptions
2024-07-03 15:37:29,981:INFO:Preloading libraries
2024-07-03 15:37:30,012:INFO:Copying training dataset
2024-07-03 15:37:30,013:INFO:Plot type: auc
2024-07-03 15:37:30,080:INFO:Fitting Model
2024-07-03 15:37:30,081:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-07-03 15:37:30,081:INFO:Scoring test/hold-out set
2024-07-03 15:37:30,300:INFO:Visual Rendered Successfully
2024-07-03 15:37:30,381:INFO:plot_model() successfully completed......................................
2024-07-03 15:37:51,488:INFO:Initializing plot_model()
2024-07-03 15:37:51,488:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False), plot=learning, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 15:37:51,489:INFO:Checking exceptions
2024-07-03 15:37:51,576:INFO:Preloading libraries
2024-07-03 15:37:51,610:INFO:Copying training dataset
2024-07-03 15:37:51,610:INFO:Plot type: learning
2024-07-03 15:37:51,682:INFO:Fitting Model
2024-07-03 15:38:17,923:INFO:Visual Rendered Successfully
2024-07-03 15:38:18,149:INFO:plot_model() successfully completed......................................
2024-07-03 15:59:59,866:INFO:Initializing predict_model()
2024-07-03 15:59:59,867:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f4f1c84ed40>)
2024-07-03 15:59:59,867:INFO:Checking exceptions
2024-07-03 15:59:59,867:INFO:Preloading libraries
2024-07-03 16:00:20,995:INFO:Initializing predict_model()
2024-07-03 16:00:20,995:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f4f1c84dee0>)
2024-07-03 16:00:20,996:INFO:Checking exceptions
2024-07-03 16:00:20,996:INFO:Preloading libraries
2024-07-03 16:01:32,573:INFO:Initializing finalize_model()
2024-07-03 16:01:32,574:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-07-03 16:01:32,576:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 16:01:32,595:INFO:Initializing create_model()
2024-07-03 16:01:32,595:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:01:32,595:INFO:Checking exceptions
2024-07-03 16:01:32,598:INFO:Importing libraries
2024-07-03 16:01:32,598:INFO:Copying training dataset
2024-07-03 16:01:32,599:INFO:Defining folds
2024-07-03 16:01:32,599:INFO:Declaring metric variables
2024-07-03 16:01:32,600:INFO:Importing untrained model
2024-07-03 16:01:32,600:INFO:Declaring custom model
2024-07-03 16:01:32,601:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 16:01:32,602:INFO:Cross validation set to False
2024-07-03 16:01:32,602:INFO:Fitting Model
2024-07-03 16:01:34,078:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-07-03 16:01:34,078:INFO:create_model() successfully completed......................................
2024-07-03 16:01:34,157:INFO:_master_model_container: 23
2024-07-03 16:01:34,158:INFO:_display_container: 10
2024-07-03 16:01:34,161:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-07-03 16:01:34,161:INFO:finalize_model() successfully completed......................................
2024-07-03 16:02:03,238:INFO:Initializing predict_model()
2024-07-03 16:02:03,238:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f4f1c84dee0>)
2024-07-03 16:02:03,238:INFO:Checking exceptions
2024-07-03 16:02:03,238:INFO:Preloading libraries
2024-07-03 16:03:40,328:INFO:Initializing predict_model()
2024-07-03 16:03:40,328:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f4f1c84e2a0>)
2024-07-03 16:03:40,328:INFO:Checking exceptions
2024-07-03 16:03:40,328:INFO:Preloading libraries
2024-07-03 16:03:40,330:INFO:Set up data.
2024-07-03 16:03:40,344:INFO:Set up index.
2024-07-03 16:06:20,093:INFO:Initializing predict_model()
2024-07-03 16:06:20,093:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f4ed2976fd0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f4f1f9b6fc0>)
2024-07-03 16:06:20,093:INFO:Checking exceptions
2024-07-03 16:06:20,093:INFO:Preloading libraries
2024-07-03 16:06:20,095:INFO:Set up data.
2024-07-03 16:06:20,107:INFO:Set up index.
2024-07-03 16:08:40,680:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:40,680:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:40,680:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:40,680:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:40,781:INFO:PyCaret ClassificationExperiment
2024-07-03 16:08:40,781:INFO:Logging name: clf-default-name
2024-07-03 16:08:40,781:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-03 16:08:40,781:INFO:version 3.3.2
2024-07-03 16:08:40,781:INFO:Initializing setup()
2024-07-03 16:08:40,781:INFO:self.USI: 8eca
2024-07-03 16:08:40,781:INFO:self._variable_keys: {'pipeline', 'idx', 'html_param', 'logging_param', 'fold_generator', 'y_train', 'USI', '_ml_usecase', 'seed', 'exp_name_log', 'log_plots_param', 'y', 'n_jobs_param', 'target_param', 'X_test', 'y_test', 'fix_imbalance', 'X_train', 'fold_groups_param', 'memory', 'gpu_n_jobs_param', '_available_plots', 'X', 'data', 'fold_shuffle_param', 'gpu_param', 'is_multiclass', 'exp_id'}
2024-07-03 16:08:40,781:INFO:Checking environment
2024-07-03 16:08:40,781:INFO:python_version: 3.11.9
2024-07-03 16:08:40,781:INFO:python_build: ('main', 'May 22 2024 17:28:32')
2024-07-03 16:08:40,781:INFO:machine: x86_64
2024-07-03 16:08:40,781:INFO:platform: Linux-6.1.0-22-amd64-x86_64-with-glibc2.36
2024-07-03 16:08:40,781:INFO:Memory: svmem(total=67150065664, available=61881171968, percent=7.8, used=3986997248, free=53089718272, active=2995613696, inactive=9527910400, buffers=451219456, cached=9622130688, shared=535322624, slab=775041024)
2024-07-03 16:08:40,782:INFO:Physical Core: 6
2024-07-03 16:08:40,782:INFO:Logical Core: 12
2024-07-03 16:08:40,782:INFO:Checking libraries
2024-07-03 16:08:40,782:INFO:System:
2024-07-03 16:08:40,782:INFO:    python: 3.11.9 (main, May 22 2024, 17:28:32) [GCC 12.2.0]
2024-07-03 16:08:40,782:INFO:executable: /home/yht/.pyenv/versions/3.11.9/envs/kaggle/bin/python
2024-07-03 16:08:40,782:INFO:   machine: Linux-6.1.0-22-amd64-x86_64-with-glibc2.36
2024-07-03 16:08:40,782:INFO:PyCaret required dependencies:
2024-07-03 16:08:40,796:INFO:                 pip: 24.1.1
2024-07-03 16:08:40,796:INFO:          setuptools: 65.5.0
2024-07-03 16:08:40,796:INFO:             pycaret: 3.3.2
2024-07-03 16:08:40,796:INFO:             IPython: 8.26.0
2024-07-03 16:08:40,796:INFO:          ipywidgets: 8.1.3
2024-07-03 16:08:40,796:INFO:                tqdm: 4.66.4
2024-07-03 16:08:40,796:INFO:               numpy: 1.26.4
2024-07-03 16:08:40,796:INFO:              pandas: 2.1.4
2024-07-03 16:08:40,796:INFO:              jinja2: 3.1.4
2024-07-03 16:08:40,796:INFO:               scipy: 1.11.4
2024-07-03 16:08:40,796:INFO:              joblib: 1.3.2
2024-07-03 16:08:40,796:INFO:             sklearn: 1.4.2
2024-07-03 16:08:40,796:INFO:                pyod: 2.0.1
2024-07-03 16:08:40,796:INFO:            imblearn: 0.12.3
2024-07-03 16:08:40,796:INFO:   category_encoders: 2.6.3
2024-07-03 16:08:40,796:INFO:            lightgbm: 4.4.0
2024-07-03 16:08:40,796:INFO:               numba: 0.60.0
2024-07-03 16:08:40,796:INFO:            requests: 2.32.3
2024-07-03 16:08:40,796:INFO:          matplotlib: 3.7.5
2024-07-03 16:08:40,796:INFO:          scikitplot: 0.3.7
2024-07-03 16:08:40,796:INFO:         yellowbrick: 1.5
2024-07-03 16:08:40,796:INFO:              plotly: 5.22.0
2024-07-03 16:08:40,796:INFO:    plotly-resampler: Not installed
2024-07-03 16:08:40,796:INFO:             kaleido: 0.2.1
2024-07-03 16:08:40,796:INFO:           schemdraw: 0.15
2024-07-03 16:08:40,796:INFO:         statsmodels: 0.14.2
2024-07-03 16:08:40,796:INFO:              sktime: 0.26.0
2024-07-03 16:08:40,796:INFO:               tbats: 1.1.3
2024-07-03 16:08:40,796:INFO:            pmdarima: 2.0.4
2024-07-03 16:08:40,796:INFO:              psutil: 6.0.0
2024-07-03 16:08:40,797:INFO:          markupsafe: 2.1.5
2024-07-03 16:08:40,797:INFO:             pickle5: Not installed
2024-07-03 16:08:40,797:INFO:         cloudpickle: 3.0.0
2024-07-03 16:08:40,797:INFO:         deprecation: 2.1.0
2024-07-03 16:08:40,797:INFO:              xxhash: 3.4.1
2024-07-03 16:08:40,797:INFO:           wurlitzer: 3.1.1
2024-07-03 16:08:40,797:INFO:PyCaret optional dependencies:
2024-07-03 16:08:40,808:INFO:                shap: Not installed
2024-07-03 16:08:40,808:INFO:           interpret: Not installed
2024-07-03 16:08:40,808:INFO:                umap: Not installed
2024-07-03 16:08:40,808:INFO:     ydata_profiling: Not installed
2024-07-03 16:08:40,808:INFO:  explainerdashboard: Not installed
2024-07-03 16:08:40,808:INFO:             autoviz: Not installed
2024-07-03 16:08:40,809:INFO:           fairlearn: Not installed
2024-07-03 16:08:40,809:INFO:          deepchecks: Not installed
2024-07-03 16:08:40,809:INFO:             xgboost: Not installed
2024-07-03 16:08:40,809:INFO:            catboost: Not installed
2024-07-03 16:08:40,809:INFO:              kmodes: Not installed
2024-07-03 16:08:40,809:INFO:             mlxtend: Not installed
2024-07-03 16:08:40,809:INFO:       statsforecast: Not installed
2024-07-03 16:08:40,809:INFO:        tune_sklearn: Not installed
2024-07-03 16:08:40,809:INFO:                 ray: Not installed
2024-07-03 16:08:40,809:INFO:            hyperopt: Not installed
2024-07-03 16:08:40,809:INFO:              optuna: Not installed
2024-07-03 16:08:40,809:INFO:               skopt: Not installed
2024-07-03 16:08:40,809:INFO:              mlflow: Not installed
2024-07-03 16:08:40,809:INFO:              gradio: Not installed
2024-07-03 16:08:40,809:INFO:             fastapi: Not installed
2024-07-03 16:08:40,809:INFO:             uvicorn: Not installed
2024-07-03 16:08:40,809:INFO:              m2cgen: Not installed
2024-07-03 16:08:40,809:INFO:           evidently: Not installed
2024-07-03 16:08:40,809:INFO:               fugue: Not installed
2024-07-03 16:08:40,809:INFO:           streamlit: Not installed
2024-07-03 16:08:40,809:INFO:             prophet: Not installed
2024-07-03 16:08:40,809:INFO:None
2024-07-03 16:08:40,809:INFO:Set up GPU usage.
2024-07-03 16:08:40,809:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:40,809:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-07-03 16:08:40,809:INFO:Set up data.
2024-07-03 16:08:40,813:INFO:Set up folding strategy.
2024-07-03 16:08:40,813:INFO:Set up train/test split.
2024-07-03 16:08:40,818:INFO:Set up index.
2024-07-03 16:08:40,818:INFO:Assigning column types.
2024-07-03 16:08:40,822:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-03 16:08:40,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:40,854:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-03 16:08:40,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:40,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:40,856:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 16:08:40,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:40,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:40,877:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:40,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:08:40,980:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:08:40,980:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:41,013:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-03 16:08:41,013:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:41,013:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:41,013:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 16:08:41,013:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:41,029:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:41,033:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:41,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:08:41,138:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:08:41,139:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-03 16:08:41,140:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:41,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:41,331:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:41,333:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 16:08:41,333:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:41,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:41,435:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:41,439:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:08:41,810:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:08:41,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:41,984:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:41,985:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:41,987:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 16:08:41,987:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:42,072:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:42,088:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:42,090:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:08:42,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:08:42,179:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-03 16:08:42,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:42,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:42,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:42,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:42,231:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:42,234:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:42,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:08:42,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:08:42,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:42,514:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:42,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:42,517:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:42,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:42,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:42,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:08:43,030:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:08:43,035:INFO:Preparing preprocessing pipeline...
2024-07-03 16:08:43,039:INFO:Set up simple imputation.
2024-07-03 16:08:43,128:INFO:Finished creating preprocessing pipeline.
2024-07-03 16:08:43,143:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-03 16:08:43,143:INFO:Creating final display dataframe.
2024-07-03 16:08:43,337:INFO:Setup _display_container:                     Description             Value
0                    Session id              8888
1                        Target       Transported
2                   Target type            Binary
3           Original data shape        (8693, 11)
4        Transformed data shape        (8693, 11)
5   Transformed train set shape        (6085, 11)
6    Transformed test set shape        (2608, 11)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              8eca
2024-07-03 16:08:43,341:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:43,373:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:43,373:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:43,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:43,390:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:43,393:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:43,394:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:08:43,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:08:43,512:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:43,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:43,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:43,694:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:43,781:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:43,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:08:43,802:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:08:44,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:08:44,178:INFO:setup() successfully completed in 3.4s...............
2024-07-03 16:08:44,195:INFO:Initializing compare_models()
2024-07-03 16:08:44,196:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-03 16:08:44,196:INFO:Checking exceptions
2024-07-03 16:08:44,218:INFO:Preparing display monitor
2024-07-03 16:08:44,306:INFO:Initializing Logistic Regression
2024-07-03 16:08:44,306:INFO:Total runtime is 5.098183949788411e-06 minutes
2024-07-03 16:08:44,318:INFO:SubProcess create_model() called ==================================
2024-07-03 16:08:44,319:INFO:Initializing create_model()
2024-07-03 16:08:44,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92c42bd990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:08:44,319:INFO:Checking exceptions
2024-07-03 16:08:44,319:INFO:Importing libraries
2024-07-03 16:08:44,319:INFO:Copying training dataset
2024-07-03 16:08:44,343:INFO:Defining folds
2024-07-03 16:08:44,344:INFO:Declaring metric variables
2024-07-03 16:08:44,354:INFO:Importing untrained model
2024-07-03 16:08:44,366:INFO:Logistic Regression Imported successfully
2024-07-03 16:08:44,391:INFO:Starting cross validation
2024-07-03 16:08:44,393:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:08:49,148:INFO:Calculating mean and std
2024-07-03 16:08:49,152:INFO:Creating metrics dataframe
2024-07-03 16:08:49,158:INFO:Uploading results into container
2024-07-03 16:08:49,159:INFO:Uploading model into container now
2024-07-03 16:08:49,160:INFO:_master_model_container: 1
2024-07-03 16:08:49,160:INFO:_display_container: 2
2024-07-03 16:08:49,162:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8888, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-03 16:08:49,162:INFO:create_model() successfully completed......................................
2024-07-03 16:08:49,288:INFO:SubProcess create_model() end ==================================
2024-07-03 16:08:49,288:INFO:Creating metrics dataframe
2024-07-03 16:08:49,295:INFO:Initializing K Neighbors Classifier
2024-07-03 16:08:49,295:INFO:Total runtime is 0.08314489920934041 minutes
2024-07-03 16:08:49,297:INFO:SubProcess create_model() called ==================================
2024-07-03 16:08:49,298:INFO:Initializing create_model()
2024-07-03 16:08:49,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92c42bd990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:08:49,298:INFO:Checking exceptions
2024-07-03 16:08:49,298:INFO:Importing libraries
2024-07-03 16:08:49,298:INFO:Copying training dataset
2024-07-03 16:08:49,305:INFO:Defining folds
2024-07-03 16:08:49,305:INFO:Declaring metric variables
2024-07-03 16:08:49,307:INFO:Importing untrained model
2024-07-03 16:08:49,310:INFO:K Neighbors Classifier Imported successfully
2024-07-03 16:08:49,315:INFO:Starting cross validation
2024-07-03 16:08:49,316:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:08:50,431:INFO:Calculating mean and std
2024-07-03 16:08:50,432:INFO:Creating metrics dataframe
2024-07-03 16:08:50,434:INFO:Uploading results into container
2024-07-03 16:08:50,434:INFO:Uploading model into container now
2024-07-03 16:08:50,434:INFO:_master_model_container: 2
2024-07-03 16:08:50,434:INFO:_display_container: 2
2024-07-03 16:08:50,434:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-03 16:08:50,434:INFO:create_model() successfully completed......................................
2024-07-03 16:08:50,492:INFO:SubProcess create_model() end ==================================
2024-07-03 16:08:50,492:INFO:Creating metrics dataframe
2024-07-03 16:08:50,498:INFO:Initializing Naive Bayes
2024-07-03 16:08:50,498:INFO:Total runtime is 0.10319337050120037 minutes
2024-07-03 16:08:50,500:INFO:SubProcess create_model() called ==================================
2024-07-03 16:08:50,500:INFO:Initializing create_model()
2024-07-03 16:08:50,500:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92c42bd990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:08:50,500:INFO:Checking exceptions
2024-07-03 16:08:50,500:INFO:Importing libraries
2024-07-03 16:08:50,500:INFO:Copying training dataset
2024-07-03 16:08:50,505:INFO:Defining folds
2024-07-03 16:08:50,505:INFO:Declaring metric variables
2024-07-03 16:08:50,507:INFO:Importing untrained model
2024-07-03 16:08:50,510:INFO:Naive Bayes Imported successfully
2024-07-03 16:08:50,514:INFO:Starting cross validation
2024-07-03 16:08:50,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:08:50,759:INFO:Calculating mean and std
2024-07-03 16:08:50,759:INFO:Creating metrics dataframe
2024-07-03 16:08:50,761:INFO:Uploading results into container
2024-07-03 16:08:50,761:INFO:Uploading model into container now
2024-07-03 16:08:50,761:INFO:_master_model_container: 3
2024-07-03 16:08:50,761:INFO:_display_container: 2
2024-07-03 16:08:50,761:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-03 16:08:50,762:INFO:create_model() successfully completed......................................
2024-07-03 16:08:50,823:INFO:SubProcess create_model() end ==================================
2024-07-03 16:08:50,823:INFO:Creating metrics dataframe
2024-07-03 16:08:50,829:INFO:Initializing Decision Tree Classifier
2024-07-03 16:08:50,829:INFO:Total runtime is 0.10871402819951376 minutes
2024-07-03 16:08:50,831:INFO:SubProcess create_model() called ==================================
2024-07-03 16:08:50,831:INFO:Initializing create_model()
2024-07-03 16:08:50,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92c42bd990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:08:50,831:INFO:Checking exceptions
2024-07-03 16:08:50,831:INFO:Importing libraries
2024-07-03 16:08:50,831:INFO:Copying training dataset
2024-07-03 16:08:50,837:INFO:Defining folds
2024-07-03 16:08:50,838:INFO:Declaring metric variables
2024-07-03 16:08:50,840:INFO:Importing untrained model
2024-07-03 16:08:50,842:INFO:Decision Tree Classifier Imported successfully
2024-07-03 16:08:50,848:INFO:Starting cross validation
2024-07-03 16:08:50,848:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:08:51,208:INFO:Calculating mean and std
2024-07-03 16:08:51,209:INFO:Creating metrics dataframe
2024-07-03 16:08:51,210:INFO:Uploading results into container
2024-07-03 16:08:51,210:INFO:Uploading model into container now
2024-07-03 16:08:51,210:INFO:_master_model_container: 4
2024-07-03 16:08:51,210:INFO:_display_container: 2
2024-07-03 16:08:51,211:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8888, splitter='best')
2024-07-03 16:08:51,211:INFO:create_model() successfully completed......................................
2024-07-03 16:08:51,272:INFO:SubProcess create_model() end ==================================
2024-07-03 16:08:51,272:INFO:Creating metrics dataframe
2024-07-03 16:08:51,277:INFO:Initializing SVM - Linear Kernel
2024-07-03 16:08:51,277:INFO:Total runtime is 0.11618910630544027 minutes
2024-07-03 16:08:51,279:INFO:SubProcess create_model() called ==================================
2024-07-03 16:08:51,280:INFO:Initializing create_model()
2024-07-03 16:08:51,280:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92c42bd990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:08:51,280:INFO:Checking exceptions
2024-07-03 16:08:51,280:INFO:Importing libraries
2024-07-03 16:08:51,280:INFO:Copying training dataset
2024-07-03 16:08:51,285:INFO:Defining folds
2024-07-03 16:08:51,285:INFO:Declaring metric variables
2024-07-03 16:08:51,287:INFO:Importing untrained model
2024-07-03 16:08:51,289:INFO:SVM - Linear Kernel Imported successfully
2024-07-03 16:08:51,293:INFO:Starting cross validation
2024-07-03 16:08:51,294:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:08:51,656:INFO:Calculating mean and std
2024-07-03 16:08:51,657:INFO:Creating metrics dataframe
2024-07-03 16:08:51,658:INFO:Uploading results into container
2024-07-03 16:08:51,658:INFO:Uploading model into container now
2024-07-03 16:08:51,658:INFO:_master_model_container: 5
2024-07-03 16:08:51,658:INFO:_display_container: 2
2024-07-03 16:08:51,659:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8888, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-03 16:08:51,659:INFO:create_model() successfully completed......................................
2024-07-03 16:08:51,720:INFO:SubProcess create_model() end ==================================
2024-07-03 16:08:51,720:INFO:Creating metrics dataframe
2024-07-03 16:08:51,726:INFO:Initializing Ridge Classifier
2024-07-03 16:08:51,726:INFO:Total runtime is 0.12366978724797567 minutes
2024-07-03 16:08:51,728:INFO:SubProcess create_model() called ==================================
2024-07-03 16:08:51,728:INFO:Initializing create_model()
2024-07-03 16:08:51,729:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92c42bd990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:08:51,729:INFO:Checking exceptions
2024-07-03 16:08:51,729:INFO:Importing libraries
2024-07-03 16:08:51,729:INFO:Copying training dataset
2024-07-03 16:08:51,734:INFO:Defining folds
2024-07-03 16:08:51,734:INFO:Declaring metric variables
2024-07-03 16:08:51,736:INFO:Importing untrained model
2024-07-03 16:08:51,738:INFO:Ridge Classifier Imported successfully
2024-07-03 16:08:51,743:INFO:Starting cross validation
2024-07-03 16:08:51,743:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:08:51,756:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.37152e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:08:51,781:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.52883e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:08:51,808:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.31264e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:08:51,904:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.5489e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:08:52,029:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.57491e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:08:52,152:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.40388e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:08:52,274:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.48847e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:08:52,397:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.59372e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:08:52,518:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.87456e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:08:52,644:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.36341e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:08:52,722:INFO:Calculating mean and std
2024-07-03 16:08:52,725:INFO:Creating metrics dataframe
2024-07-03 16:08:52,732:INFO:Uploading results into container
2024-07-03 16:08:52,733:INFO:Uploading model into container now
2024-07-03 16:08:52,735:INFO:_master_model_container: 6
2024-07-03 16:08:52,735:INFO:_display_container: 2
2024-07-03 16:08:52,736:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8888, solver='auto',
                tol=0.0001)
2024-07-03 16:08:52,737:INFO:create_model() successfully completed......................................
2024-07-03 16:08:52,851:INFO:SubProcess create_model() end ==================================
2024-07-03 16:08:52,851:INFO:Creating metrics dataframe
2024-07-03 16:08:52,857:INFO:Initializing Random Forest Classifier
2024-07-03 16:08:52,857:INFO:Total runtime is 0.14251189629236857 minutes
2024-07-03 16:08:52,859:INFO:SubProcess create_model() called ==================================
2024-07-03 16:08:52,859:INFO:Initializing create_model()
2024-07-03 16:08:52,859:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92c42bd990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:08:52,859:INFO:Checking exceptions
2024-07-03 16:08:52,859:INFO:Importing libraries
2024-07-03 16:08:52,859:INFO:Copying training dataset
2024-07-03 16:08:52,865:INFO:Defining folds
2024-07-03 16:08:52,865:INFO:Declaring metric variables
2024-07-03 16:08:52,867:INFO:Importing untrained model
2024-07-03 16:08:52,870:INFO:Random Forest Classifier Imported successfully
2024-07-03 16:08:52,874:INFO:Starting cross validation
2024-07-03 16:08:52,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:08:55,496:INFO:Calculating mean and std
2024-07-03 16:08:55,497:INFO:Creating metrics dataframe
2024-07-03 16:08:55,498:INFO:Uploading results into container
2024-07-03 16:08:55,499:INFO:Uploading model into container now
2024-07-03 16:08:55,499:INFO:_master_model_container: 7
2024-07-03 16:08:55,499:INFO:_display_container: 2
2024-07-03 16:08:55,499:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 16:08:55,500:INFO:create_model() successfully completed......................................
2024-07-03 16:08:55,560:INFO:SubProcess create_model() end ==================================
2024-07-03 16:08:55,560:INFO:Creating metrics dataframe
2024-07-03 16:08:55,566:INFO:Initializing Quadratic Discriminant Analysis
2024-07-03 16:08:55,566:INFO:Total runtime is 0.18767210642496746 minutes
2024-07-03 16:08:55,569:INFO:SubProcess create_model() called ==================================
2024-07-03 16:08:55,569:INFO:Initializing create_model()
2024-07-03 16:08:55,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92c42bd990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:08:55,569:INFO:Checking exceptions
2024-07-03 16:08:55,569:INFO:Importing libraries
2024-07-03 16:08:55,569:INFO:Copying training dataset
2024-07-03 16:08:55,574:INFO:Defining folds
2024-07-03 16:08:55,574:INFO:Declaring metric variables
2024-07-03 16:08:55,576:INFO:Importing untrained model
2024-07-03 16:08:55,578:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-03 16:08:55,583:INFO:Starting cross validation
2024-07-03 16:08:55,584:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:08:55,595:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:08:55,655:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:08:55,699:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:08:55,744:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:08:55,767:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 16:08:55,792:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:08:55,836:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:08:55,856:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 16:08:55,900:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:08:55,947:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:08:55,993:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:08:56,027:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 16:08:56,049:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:08:56,081:INFO:Calculating mean and std
2024-07-03 16:08:56,083:INFO:Creating metrics dataframe
2024-07-03 16:08:56,085:INFO:Uploading results into container
2024-07-03 16:08:56,085:INFO:Uploading model into container now
2024-07-03 16:08:56,086:INFO:_master_model_container: 8
2024-07-03 16:08:56,086:INFO:_display_container: 2
2024-07-03 16:08:56,086:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-03 16:08:56,086:INFO:create_model() successfully completed......................................
2024-07-03 16:08:56,214:INFO:SubProcess create_model() end ==================================
2024-07-03 16:08:56,214:INFO:Creating metrics dataframe
2024-07-03 16:08:56,245:INFO:Initializing Ada Boost Classifier
2024-07-03 16:08:56,246:INFO:Total runtime is 0.1989926258722941 minutes
2024-07-03 16:08:56,258:INFO:SubProcess create_model() called ==================================
2024-07-03 16:08:56,259:INFO:Initializing create_model()
2024-07-03 16:08:56,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92c42bd990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:08:56,259:INFO:Checking exceptions
2024-07-03 16:08:56,259:INFO:Importing libraries
2024-07-03 16:08:56,259:INFO:Copying training dataset
2024-07-03 16:08:56,286:INFO:Defining folds
2024-07-03 16:08:56,286:INFO:Declaring metric variables
2024-07-03 16:08:56,299:INFO:Importing untrained model
2024-07-03 16:08:56,311:INFO:Ada Boost Classifier Imported successfully
2024-07-03 16:08:56,336:INFO:Starting cross validation
2024-07-03 16:08:56,339:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:08:56,391:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:08:57,190:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:08:57,353:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:08:57,511:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:08:57,674:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:08:57,833:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:08:57,996:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:08:58,165:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:08:58,332:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:08:58,493:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:08:58,649:INFO:Calculating mean and std
2024-07-03 16:08:58,650:INFO:Creating metrics dataframe
2024-07-03 16:08:58,651:INFO:Uploading results into container
2024-07-03 16:08:58,652:INFO:Uploading model into container now
2024-07-03 16:08:58,652:INFO:_master_model_container: 9
2024-07-03 16:08:58,652:INFO:_display_container: 2
2024-07-03 16:08:58,652:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8888)
2024-07-03 16:08:58,653:INFO:create_model() successfully completed......................................
2024-07-03 16:08:58,709:INFO:SubProcess create_model() end ==================================
2024-07-03 16:08:58,709:INFO:Creating metrics dataframe
2024-07-03 16:08:58,716:INFO:Initializing Gradient Boosting Classifier
2024-07-03 16:08:58,716:INFO:Total runtime is 0.24017157554626464 minutes
2024-07-03 16:08:58,718:INFO:SubProcess create_model() called ==================================
2024-07-03 16:08:58,719:INFO:Initializing create_model()
2024-07-03 16:08:58,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92c42bd990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:08:58,719:INFO:Checking exceptions
2024-07-03 16:08:58,719:INFO:Importing libraries
2024-07-03 16:08:58,719:INFO:Copying training dataset
2024-07-03 16:08:58,724:INFO:Defining folds
2024-07-03 16:08:58,724:INFO:Declaring metric variables
2024-07-03 16:08:58,726:INFO:Importing untrained model
2024-07-03 16:08:58,728:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 16:08:58,733:INFO:Starting cross validation
2024-07-03 16:08:58,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:09:02,958:INFO:Calculating mean and std
2024-07-03 16:09:02,959:INFO:Creating metrics dataframe
2024-07-03 16:09:02,960:INFO:Uploading results into container
2024-07-03 16:09:02,960:INFO:Uploading model into container now
2024-07-03 16:09:02,960:INFO:_master_model_container: 10
2024-07-03 16:09:02,961:INFO:_display_container: 2
2024-07-03 16:09:02,961:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 16:09:02,961:INFO:create_model() successfully completed......................................
2024-07-03 16:09:03,019:INFO:SubProcess create_model() end ==================================
2024-07-03 16:09:03,019:INFO:Creating metrics dataframe
2024-07-03 16:09:03,025:INFO:Initializing Linear Discriminant Analysis
2024-07-03 16:09:03,025:INFO:Total runtime is 0.3119892438252767 minutes
2024-07-03 16:09:03,028:INFO:SubProcess create_model() called ==================================
2024-07-03 16:09:03,028:INFO:Initializing create_model()
2024-07-03 16:09:03,028:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92c42bd990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:09:03,028:INFO:Checking exceptions
2024-07-03 16:09:03,028:INFO:Importing libraries
2024-07-03 16:09:03,028:INFO:Copying training dataset
2024-07-03 16:09:03,033:INFO:Defining folds
2024-07-03 16:09:03,033:INFO:Declaring metric variables
2024-07-03 16:09:03,035:INFO:Importing untrained model
2024-07-03 16:09:03,037:INFO:Linear Discriminant Analysis Imported successfully
2024-07-03 16:09:03,042:INFO:Starting cross validation
2024-07-03 16:09:03,042:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:09:03,509:INFO:Calculating mean and std
2024-07-03 16:09:03,510:INFO:Creating metrics dataframe
2024-07-03 16:09:03,513:INFO:Uploading results into container
2024-07-03 16:09:03,513:INFO:Uploading model into container now
2024-07-03 16:09:03,514:INFO:_master_model_container: 11
2024-07-03 16:09:03,514:INFO:_display_container: 2
2024-07-03 16:09:03,514:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-03 16:09:03,514:INFO:create_model() successfully completed......................................
2024-07-03 16:09:03,595:INFO:SubProcess create_model() end ==================================
2024-07-03 16:09:03,595:INFO:Creating metrics dataframe
2024-07-03 16:09:03,602:INFO:Initializing Extra Trees Classifier
2024-07-03 16:09:03,602:INFO:Total runtime is 0.3216043512026469 minutes
2024-07-03 16:09:03,605:INFO:SubProcess create_model() called ==================================
2024-07-03 16:09:03,605:INFO:Initializing create_model()
2024-07-03 16:09:03,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92c42bd990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:09:03,605:INFO:Checking exceptions
2024-07-03 16:09:03,605:INFO:Importing libraries
2024-07-03 16:09:03,605:INFO:Copying training dataset
2024-07-03 16:09:03,610:INFO:Defining folds
2024-07-03 16:09:03,610:INFO:Declaring metric variables
2024-07-03 16:09:03,613:INFO:Importing untrained model
2024-07-03 16:09:03,616:INFO:Extra Trees Classifier Imported successfully
2024-07-03 16:09:03,621:INFO:Starting cross validation
2024-07-03 16:09:03,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:09:05,789:INFO:Calculating mean and std
2024-07-03 16:09:05,790:INFO:Creating metrics dataframe
2024-07-03 16:09:05,792:INFO:Uploading results into container
2024-07-03 16:09:05,793:INFO:Uploading model into container now
2024-07-03 16:09:05,793:INFO:_master_model_container: 12
2024-07-03 16:09:05,793:INFO:_display_container: 2
2024-07-03 16:09:05,794:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8888, verbose=0,
                     warm_start=False)
2024-07-03 16:09:05,794:INFO:create_model() successfully completed......................................
2024-07-03 16:09:05,853:INFO:SubProcess create_model() end ==================================
2024-07-03 16:09:05,853:INFO:Creating metrics dataframe
2024-07-03 16:09:05,860:INFO:Initializing Light Gradient Boosting Machine
2024-07-03 16:09:05,860:INFO:Total runtime is 0.35922858317693074 minutes
2024-07-03 16:09:05,862:INFO:SubProcess create_model() called ==================================
2024-07-03 16:09:05,862:INFO:Initializing create_model()
2024-07-03 16:09:05,862:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92c42bd990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:09:05,862:INFO:Checking exceptions
2024-07-03 16:09:05,863:INFO:Importing libraries
2024-07-03 16:09:05,863:INFO:Copying training dataset
2024-07-03 16:09:05,869:INFO:Defining folds
2024-07-03 16:09:05,869:INFO:Declaring metric variables
2024-07-03 16:09:05,871:INFO:Importing untrained model
2024-07-03 16:09:05,873:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-03 16:09:05,879:INFO:Starting cross validation
2024-07-03 16:09:05,880:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:09:05,893:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 16:09:05,893:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:09:05,893:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 16:09:05,893:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 16:09:06,081:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:09:06,081:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:09:06,146:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:09:06,153:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:09:06,157:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.002296 secs. 1 sparse feature groups
2024-07-03 16:09:06,158:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 16:09:06,159:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 16:09:08,150:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 16:09:08,151:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:09:08,152:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 16:09:08,152:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 16:09:08,361:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:09:08,361:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:09:08,430:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:09:08,436:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:09:08,440:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.002427 secs. 1 sparse feature groups
2024-07-03 16:09:08,441:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 16:09:08,441:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 16:09:10,177:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 16:09:10,177:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:09:10,177:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-03 16:09:10,177:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 16:09:10,239:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:09:10,239:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:09:10,244:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:09:10,245:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:09:10,245:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000225 secs. 1 sparse feature groups
2024-07-03 16:09:10,245:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 16:09:10,245:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 16:09:12,161:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 16:09:12,161:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:09:12,162:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 16:09:12,163:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 16:09:12,350:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:09:12,350:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:09:12,358:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:09:12,361:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:09:12,374:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.013551 secs. 1 sparse feature groups
2024-07-03 16:09:12,374:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 16:09:12,374:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 16:09:13,785:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 16:09:13,785:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:09:13,786:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-03 16:09:13,787:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 16:09:13,995:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:09:13,996:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:09:14,062:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:09:14,068:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:09:14,074:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.003708 secs. 1 sparse feature groups
2024-07-03 16:09:14,074:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 16:09:14,075:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 16:09:15,609:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 16:09:15,609:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:09:15,610:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-03 16:09:15,610:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 16:09:15,664:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:09:15,664:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:09:15,669:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:09:15,670:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:09:15,670:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000245 secs. 1 sparse feature groups
2024-07-03 16:09:15,670:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 16:09:15,670:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 16:09:17,309:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 16:09:17,310:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:09:17,311:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 16:09:17,311:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 16:09:17,478:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:09:17,478:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:09:17,499:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:09:17,505:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:09:17,507:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000957 secs. 1 sparse feature groups
2024-07-03 16:09:17,507:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 16:09:17,508:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 16:09:19,439:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 16:09:19,440:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:09:19,441:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-03 16:09:19,441:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 16:09:19,655:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:09:19,656:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:09:19,706:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:09:19,712:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:09:19,713:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000957 secs. 1 sparse feature groups
2024-07-03 16:09:19,714:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 16:09:19,714:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 16:09:21,144:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 16:09:21,144:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:09:21,145:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 16:09:21,146:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 16:09:21,357:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:09:21,357:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:09:21,408:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:09:21,414:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:09:21,415:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000896 secs. 1 sparse feature groups
2024-07-03 16:09:21,416:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 16:09:21,416:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 16:09:23,062:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 16:09:23,063:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:09:23,064:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 16:09:23,064:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 16:09:23,175:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:09:23,175:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:09:23,181:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:09:23,182:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:09:23,182:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000295 secs. 1 sparse feature groups
2024-07-03 16:09:23,183:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 16:09:23,183:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 16:09:24,664:INFO:Calculating mean and std
2024-07-03 16:09:24,669:INFO:Creating metrics dataframe
2024-07-03 16:09:24,676:INFO:Uploading results into container
2024-07-03 16:09:24,677:INFO:Uploading model into container now
2024-07-03 16:09:24,679:INFO:_master_model_container: 13
2024-07-03 16:09:24,679:INFO:_display_container: 2
2024-07-03 16:09:24,681:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=8888, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-07-03 16:09:24,681:INFO:create_model() successfully completed......................................
2024-07-03 16:09:24,845:INFO:SubProcess create_model() end ==================================
2024-07-03 16:09:24,845:INFO:Creating metrics dataframe
2024-07-03 16:09:24,884:INFO:Initializing Dummy Classifier
2024-07-03 16:09:24,884:INFO:Total runtime is 0.6762971401214599 minutes
2024-07-03 16:09:24,895:INFO:SubProcess create_model() called ==================================
2024-07-03 16:09:24,897:INFO:Initializing create_model()
2024-07-03 16:09:24,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92c42bd990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:09:24,897:INFO:Checking exceptions
2024-07-03 16:09:24,897:INFO:Importing libraries
2024-07-03 16:09:24,897:INFO:Copying training dataset
2024-07-03 16:09:24,922:INFO:Defining folds
2024-07-03 16:09:24,923:INFO:Declaring metric variables
2024-07-03 16:09:24,934:INFO:Importing untrained model
2024-07-03 16:09:24,946:INFO:Dummy Classifier Imported successfully
2024-07-03 16:09:24,969:INFO:Starting cross validation
2024-07-03 16:09:24,971:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:09:25,431:INFO:Calculating mean and std
2024-07-03 16:09:25,431:INFO:Creating metrics dataframe
2024-07-03 16:09:25,433:INFO:Uploading results into container
2024-07-03 16:09:25,433:INFO:Uploading model into container now
2024-07-03 16:09:25,433:INFO:_master_model_container: 14
2024-07-03 16:09:25,433:INFO:_display_container: 2
2024-07-03 16:09:25,433:INFO:DummyClassifier(constant=None, random_state=8888, strategy='prior')
2024-07-03 16:09:25,433:INFO:create_model() successfully completed......................................
2024-07-03 16:09:25,492:INFO:SubProcess create_model() end ==================================
2024-07-03 16:09:25,492:INFO:Creating metrics dataframe
2024-07-03 16:09:25,500:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-03 16:09:25,506:INFO:Initializing create_model()
2024-07-03 16:09:25,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:09:25,506:INFO:Checking exceptions
2024-07-03 16:09:25,507:INFO:Importing libraries
2024-07-03 16:09:25,507:INFO:Copying training dataset
2024-07-03 16:09:25,511:INFO:Defining folds
2024-07-03 16:09:25,511:INFO:Declaring metric variables
2024-07-03 16:09:25,512:INFO:Importing untrained model
2024-07-03 16:09:25,512:INFO:Declaring custom model
2024-07-03 16:09:25,512:INFO:Random Forest Classifier Imported successfully
2024-07-03 16:09:25,513:INFO:Cross validation set to False
2024-07-03 16:09:25,513:INFO:Fitting Model
2024-07-03 16:09:25,714:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 16:09:25,714:INFO:create_model() successfully completed......................................
2024-07-03 16:09:25,804:INFO:_master_model_container: 14
2024-07-03 16:09:25,804:INFO:_display_container: 2
2024-07-03 16:09:25,805:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 16:09:25,805:INFO:compare_models() successfully completed......................................
2024-07-03 16:09:25,812:INFO:Initializing create_model()
2024-07-03 16:09:25,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=gbc, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:09:25,812:INFO:Checking exceptions
2024-07-03 16:09:25,823:INFO:Importing libraries
2024-07-03 16:09:25,824:INFO:Copying training dataset
2024-07-03 16:09:25,833:INFO:Defining folds
2024-07-03 16:09:25,833:INFO:Declaring metric variables
2024-07-03 16:09:25,835:INFO:Importing untrained model
2024-07-03 16:09:25,838:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 16:09:25,843:INFO:Starting cross validation
2024-07-03 16:09:25,844:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:09:27,803:INFO:Calculating mean and std
2024-07-03 16:09:27,804:INFO:Creating metrics dataframe
2024-07-03 16:09:27,807:INFO:Finalizing model
2024-07-03 16:09:28,270:INFO:Uploading results into container
2024-07-03 16:09:28,271:INFO:Uploading model into container now
2024-07-03 16:09:28,277:INFO:_master_model_container: 15
2024-07-03 16:09:28,277:INFO:_display_container: 3
2024-07-03 16:09:28,277:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 16:09:28,277:INFO:create_model() successfully completed......................................
2024-07-03 16:09:28,342:INFO:Initializing tune_model()
2024-07-03 16:09:28,342:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-03 16:09:28,342:INFO:Checking exceptions
2024-07-03 16:09:28,357:INFO:Copying training dataset
2024-07-03 16:09:28,361:INFO:Checking base model
2024-07-03 16:09:28,361:INFO:Base model : Gradient Boosting Classifier
2024-07-03 16:09:28,364:INFO:Declaring metric variables
2024-07-03 16:09:28,366:INFO:Defining Hyperparameters
2024-07-03 16:09:28,426:INFO:Tuning with n_jobs=-1
2024-07-03 16:09:28,426:INFO:Initializing RandomizedSearchCV
2024-07-03 16:10:09,907:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.2, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.001}
2024-07-03 16:10:09,911:INFO:Hyperparameter search completed
2024-07-03 16:10:09,911:INFO:SubProcess create_model() called ==================================
2024-07-03 16:10:09,913:INFO:Initializing create_model()
2024-07-03 16:10:09,914:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9334286790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'n_estimators': 160, 'min_samples_split': 7, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.2, 'max_features': 'log2', 'max_depth': 9, 'learning_rate': 0.001})
2024-07-03 16:10:09,914:INFO:Checking exceptions
2024-07-03 16:10:09,914:INFO:Importing libraries
2024-07-03 16:10:09,914:INFO:Copying training dataset
2024-07-03 16:10:09,942:INFO:Defining folds
2024-07-03 16:10:09,942:INFO:Declaring metric variables
2024-07-03 16:10:09,955:INFO:Importing untrained model
2024-07-03 16:10:09,955:INFO:Declaring custom model
2024-07-03 16:10:09,970:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 16:10:09,992:INFO:Starting cross validation
2024-07-03 16:10:09,995:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:10:21,695:INFO:Calculating mean and std
2024-07-03 16:10:21,696:INFO:Creating metrics dataframe
2024-07-03 16:10:21,700:INFO:Finalizing model
2024-07-03 16:10:22,838:INFO:Uploading results into container
2024-07-03 16:10:22,839:INFO:Uploading model into container now
2024-07-03 16:10:22,839:INFO:_master_model_container: 16
2024-07-03 16:10:22,840:INFO:_display_container: 4
2024-07-03 16:10:22,840:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 16:10:22,840:INFO:create_model() successfully completed......................................
2024-07-03 16:10:22,907:INFO:SubProcess create_model() end ==================================
2024-07-03 16:10:22,907:INFO:choose_better activated
2024-07-03 16:10:22,909:INFO:SubProcess create_model() called ==================================
2024-07-03 16:10:22,910:INFO:Initializing create_model()
2024-07-03 16:10:22,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:10:22,910:INFO:Checking exceptions
2024-07-03 16:10:22,911:INFO:Importing libraries
2024-07-03 16:10:22,911:INFO:Copying training dataset
2024-07-03 16:10:22,916:INFO:Defining folds
2024-07-03 16:10:22,916:INFO:Declaring metric variables
2024-07-03 16:10:22,916:INFO:Importing untrained model
2024-07-03 16:10:22,916:INFO:Declaring custom model
2024-07-03 16:10:22,916:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 16:10:22,917:INFO:Starting cross validation
2024-07-03 16:10:22,917:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:10:27,276:INFO:Calculating mean and std
2024-07-03 16:10:27,277:INFO:Creating metrics dataframe
2024-07-03 16:10:27,278:INFO:Finalizing model
2024-07-03 16:10:27,734:INFO:Uploading results into container
2024-07-03 16:10:27,734:INFO:Uploading model into container now
2024-07-03 16:10:27,735:INFO:_master_model_container: 17
2024-07-03 16:10:27,735:INFO:_display_container: 5
2024-07-03 16:10:27,735:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 16:10:27,735:INFO:create_model() successfully completed......................................
2024-07-03 16:10:27,796:INFO:SubProcess create_model() end ==================================
2024-07-03 16:10:27,796:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.7896
2024-07-03 16:10:27,797:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.7936
2024-07-03 16:10:27,797:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-07-03 16:10:27,797:INFO:choose_better completed
2024-07-03 16:10:27,804:INFO:_master_model_container: 17
2024-07-03 16:10:27,804:INFO:_display_container: 4
2024-07-03 16:10:27,804:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 16:10:27,804:INFO:tune_model() successfully completed......................................
2024-07-03 16:10:27,873:INFO:Initializing evaluate_model()
2024-07-03 16:10:27,873:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-07-03 16:10:27,883:INFO:Initializing plot_model()
2024-07-03 16:10:27,883:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 16:10:27,884:INFO:Checking exceptions
2024-07-03 16:10:27,887:INFO:Preloading libraries
2024-07-03 16:10:27,897:INFO:Copying training dataset
2024-07-03 16:10:27,897:INFO:Plot type: pipeline
2024-07-03 16:10:27,998:INFO:Visual Rendered Successfully
2024-07-03 16:10:28,088:INFO:plot_model() successfully completed......................................
2024-07-03 16:10:28,099:INFO:Initializing create_model()
2024-07-03 16:10:28,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:10:28,100:INFO:Checking exceptions
2024-07-03 16:10:28,112:INFO:Importing libraries
2024-07-03 16:10:28,112:INFO:Copying training dataset
2024-07-03 16:10:28,117:INFO:Defining folds
2024-07-03 16:10:28,117:INFO:Declaring metric variables
2024-07-03 16:10:28,119:INFO:Importing untrained model
2024-07-03 16:10:28,123:INFO:Random Forest Classifier Imported successfully
2024-07-03 16:10:28,128:INFO:Starting cross validation
2024-07-03 16:10:28,129:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:10:30,171:INFO:Calculating mean and std
2024-07-03 16:10:30,172:INFO:Creating metrics dataframe
2024-07-03 16:10:30,175:INFO:Finalizing model
2024-07-03 16:10:30,383:INFO:Uploading results into container
2024-07-03 16:10:30,384:INFO:Uploading model into container now
2024-07-03 16:10:30,391:INFO:_master_model_container: 18
2024-07-03 16:10:30,392:INFO:_display_container: 5
2024-07-03 16:10:30,392:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 16:10:30,392:INFO:create_model() successfully completed......................................
2024-07-03 16:10:30,457:INFO:Initializing tune_model()
2024-07-03 16:10:30,457:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-03 16:10:30,457:INFO:Checking exceptions
2024-07-03 16:10:30,469:INFO:Copying training dataset
2024-07-03 16:10:30,473:INFO:Checking base model
2024-07-03 16:10:30,473:INFO:Base model : Random Forest Classifier
2024-07-03 16:10:30,476:INFO:Declaring metric variables
2024-07-03 16:10:30,478:INFO:Defining Hyperparameters
2024-07-03 16:10:30,539:INFO:Tuning with n_jobs=-1
2024-07-03 16:10:30,539:INFO:Initializing RandomizedSearchCV
2024-07-03 16:10:57,599:INFO:best_params: {'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2024-07-03 16:10:57,600:INFO:Hyperparameter search completed
2024-07-03 16:10:57,600:INFO:SubProcess create_model() called ==================================
2024-07-03 16:10:57,601:INFO:Initializing create_model()
2024-07-03 16:10:57,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f92d4687250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 160, 'min_samples_split': 7, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2024-07-03 16:10:57,601:INFO:Checking exceptions
2024-07-03 16:10:57,601:INFO:Importing libraries
2024-07-03 16:10:57,601:INFO:Copying training dataset
2024-07-03 16:10:57,606:INFO:Defining folds
2024-07-03 16:10:57,606:INFO:Declaring metric variables
2024-07-03 16:10:57,608:INFO:Importing untrained model
2024-07-03 16:10:57,608:INFO:Declaring custom model
2024-07-03 16:10:57,611:INFO:Random Forest Classifier Imported successfully
2024-07-03 16:10:57,615:INFO:Starting cross validation
2024-07-03 16:10:57,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:11:01,261:INFO:Calculating mean and std
2024-07-03 16:11:01,261:INFO:Creating metrics dataframe
2024-07-03 16:11:01,265:INFO:Finalizing model
2024-07-03 16:11:01,668:INFO:Uploading results into container
2024-07-03 16:11:01,669:INFO:Uploading model into container now
2024-07-03 16:11:01,670:INFO:_master_model_container: 19
2024-07-03 16:11:01,670:INFO:_display_container: 6
2024-07-03 16:11:01,671:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False)
2024-07-03 16:11:01,671:INFO:create_model() successfully completed......................................
2024-07-03 16:11:01,765:INFO:SubProcess create_model() end ==================================
2024-07-03 16:11:01,766:INFO:choose_better activated
2024-07-03 16:11:01,768:INFO:SubProcess create_model() called ==================================
2024-07-03 16:11:01,769:INFO:Initializing create_model()
2024-07-03 16:11:01,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:11:01,769:INFO:Checking exceptions
2024-07-03 16:11:01,770:INFO:Importing libraries
2024-07-03 16:11:01,770:INFO:Copying training dataset
2024-07-03 16:11:01,775:INFO:Defining folds
2024-07-03 16:11:01,776:INFO:Declaring metric variables
2024-07-03 16:11:01,776:INFO:Importing untrained model
2024-07-03 16:11:01,776:INFO:Declaring custom model
2024-07-03 16:11:01,776:INFO:Random Forest Classifier Imported successfully
2024-07-03 16:11:01,776:INFO:Starting cross validation
2024-07-03 16:11:01,777:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:11:04,455:INFO:Calculating mean and std
2024-07-03 16:11:04,455:INFO:Creating metrics dataframe
2024-07-03 16:11:04,457:INFO:Finalizing model
2024-07-03 16:11:04,642:INFO:Uploading results into container
2024-07-03 16:11:04,642:INFO:Uploading model into container now
2024-07-03 16:11:04,643:INFO:_master_model_container: 20
2024-07-03 16:11:04,643:INFO:_display_container: 7
2024-07-03 16:11:04,643:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 16:11:04,643:INFO:create_model() successfully completed......................................
2024-07-03 16:11:04,703:INFO:SubProcess create_model() end ==================================
2024-07-03 16:11:04,703:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False) result for Accuracy is 0.79
2024-07-03 16:11:04,703:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False) result for Accuracy is 0.7936
2024-07-03 16:11:04,704:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False) is best model
2024-07-03 16:11:04,704:INFO:choose_better completed
2024-07-03 16:11:04,710:INFO:_master_model_container: 20
2024-07-03 16:11:04,710:INFO:_display_container: 6
2024-07-03 16:11:04,711:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False)
2024-07-03 16:11:04,711:INFO:tune_model() successfully completed......................................
2024-07-03 16:11:04,775:INFO:Initializing evaluate_model()
2024-07-03 16:11:04,775:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-07-03 16:11:04,784:INFO:Initializing plot_model()
2024-07-03 16:11:04,784:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 16:11:04,784:INFO:Checking exceptions
2024-07-03 16:11:04,810:INFO:Preloading libraries
2024-07-03 16:11:04,820:INFO:Copying training dataset
2024-07-03 16:11:04,820:INFO:Plot type: pipeline
2024-07-03 16:11:04,880:INFO:Visual Rendered Successfully
2024-07-03 16:11:04,954:INFO:plot_model() successfully completed......................................
2024-07-03 16:11:04,959:INFO:Initializing predict_model()
2024-07-03 16:11:04,959:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f92c4dcfa60>)
2024-07-03 16:11:04,959:INFO:Checking exceptions
2024-07-03 16:11:04,959:INFO:Preloading libraries
2024-07-03 16:11:05,111:INFO:Initializing predict_model()
2024-07-03 16:11:05,112:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f92c4dcdf80>)
2024-07-03 16:11:05,112:INFO:Checking exceptions
2024-07-03 16:11:05,112:INFO:Preloading libraries
2024-07-03 16:11:05,294:INFO:Initializing finalize_model()
2024-07-03 16:11:05,294:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-07-03 16:11:05,295:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 16:11:05,298:INFO:Initializing create_model()
2024-07-03 16:11:05,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:11:05,298:INFO:Checking exceptions
2024-07-03 16:11:05,300:INFO:Importing libraries
2024-07-03 16:11:05,300:INFO:Copying training dataset
2024-07-03 16:11:05,301:INFO:Defining folds
2024-07-03 16:11:05,301:INFO:Declaring metric variables
2024-07-03 16:11:05,301:INFO:Importing untrained model
2024-07-03 16:11:05,301:INFO:Declaring custom model
2024-07-03 16:11:05,301:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 16:11:05,302:INFO:Cross validation set to False
2024-07-03 16:11:05,302:INFO:Fitting Model
2024-07-03 16:11:06,749:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-07-03 16:11:06,749:INFO:create_model() successfully completed......................................
2024-07-03 16:11:06,807:INFO:_master_model_container: 20
2024-07-03 16:11:06,807:INFO:_display_container: 8
2024-07-03 16:11:06,810:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-07-03 16:11:06,810:INFO:finalize_model() successfully completed......................................
2024-07-03 16:11:06,878:INFO:Initializing predict_model()
2024-07-03 16:11:06,878:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f92c4dceb60>)
2024-07-03 16:11:06,878:INFO:Checking exceptions
2024-07-03 16:11:06,878:INFO:Preloading libraries
2024-07-03 16:11:07,056:INFO:Initializing predict_model()
2024-07-03 16:11:07,056:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f92c4dcf1a0>)
2024-07-03 16:11:07,056:INFO:Checking exceptions
2024-07-03 16:11:07,056:INFO:Preloading libraries
2024-07-03 16:11:07,057:INFO:Set up data.
2024-07-03 16:11:07,068:INFO:Set up index.
2024-07-03 16:11:29,712:INFO:Initializing predict_model()
2024-07-03 16:11:29,712:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f92c4cb9120>)
2024-07-03 16:11:29,712:INFO:Checking exceptions
2024-07-03 16:11:29,712:INFO:Preloading libraries
2024-07-03 16:11:29,714:INFO:Set up data.
2024-07-03 16:11:29,726:INFO:Set up index.
2024-07-03 16:14:36,400:INFO:Initializing predict_model()
2024-07-03 16:14:36,400:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f92d4132b50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f92e8f7ec00>)
2024-07-03 16:14:36,401:INFO:Checking exceptions
2024-07-03 16:14:36,401:INFO:Preloading libraries
2024-07-03 16:14:36,403:INFO:Set up data.
2024-07-03 16:14:36,414:INFO:Set up index.
2024-07-03 16:32:10,992:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:10,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:10,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:10,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:11,167:INFO:PyCaret ClassificationExperiment
2024-07-03 16:32:11,167:INFO:Logging name: clf-default-name
2024-07-03 16:32:11,167:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-03 16:32:11,167:INFO:version 3.3.2
2024-07-03 16:32:11,167:INFO:Initializing setup()
2024-07-03 16:32:11,167:INFO:self.USI: c7af
2024-07-03 16:32:11,167:INFO:self._variable_keys: {'seed', 'exp_name_log', 'data', 'fold_groups_param', 'idx', 'target_param', 'log_plots_param', 'logging_param', 'gpu_param', 'X_train', 'fix_imbalance', 'fold_generator', 'y_train', 'html_param', 'y', 'is_multiclass', 'memory', 'X_test', 'gpu_n_jobs_param', 'USI', '_ml_usecase', '_available_plots', 'X', 'pipeline', 'y_test', 'exp_id', 'fold_shuffle_param', 'n_jobs_param'}
2024-07-03 16:32:11,167:INFO:Checking environment
2024-07-03 16:32:11,167:INFO:python_version: 3.11.9
2024-07-03 16:32:11,167:INFO:python_build: ('main', 'May 22 2024 17:28:32')
2024-07-03 16:32:11,167:INFO:machine: x86_64
2024-07-03 16:32:11,167:INFO:platform: Linux-6.1.0-22-amd64-x86_64-with-glibc2.36
2024-07-03 16:32:11,168:INFO:Memory: svmem(total=67150065664, available=63761403904, percent=5.0, used=2288705536, free=62566371328, active=582074368, inactive=3044237312, buffers=121958400, cached=2173030400, shared=444272640, slab=204521472)
2024-07-03 16:32:11,168:INFO:Physical Core: 6
2024-07-03 16:32:11,168:INFO:Logical Core: 12
2024-07-03 16:32:11,168:INFO:Checking libraries
2024-07-03 16:32:11,168:INFO:System:
2024-07-03 16:32:11,168:INFO:    python: 3.11.9 (main, May 22 2024, 17:28:32) [GCC 12.2.0]
2024-07-03 16:32:11,168:INFO:executable: /home/yht/.pyenv/versions/3.11.9/envs/kaggle/bin/python
2024-07-03 16:32:11,168:INFO:   machine: Linux-6.1.0-22-amd64-x86_64-with-glibc2.36
2024-07-03 16:32:11,168:INFO:PyCaret required dependencies:
2024-07-03 16:32:11,188:INFO:                 pip: 24.1.1
2024-07-03 16:32:11,188:INFO:          setuptools: 65.5.0
2024-07-03 16:32:11,188:INFO:             pycaret: 3.3.2
2024-07-03 16:32:11,188:INFO:             IPython: 8.26.0
2024-07-03 16:32:11,188:INFO:          ipywidgets: 8.1.3
2024-07-03 16:32:11,188:INFO:                tqdm: 4.66.4
2024-07-03 16:32:11,188:INFO:               numpy: 1.26.4
2024-07-03 16:32:11,188:INFO:              pandas: 2.1.4
2024-07-03 16:32:11,188:INFO:              jinja2: 3.1.4
2024-07-03 16:32:11,188:INFO:               scipy: 1.11.4
2024-07-03 16:32:11,188:INFO:              joblib: 1.3.2
2024-07-03 16:32:11,188:INFO:             sklearn: 1.4.2
2024-07-03 16:32:11,188:INFO:                pyod: 2.0.1
2024-07-03 16:32:11,188:INFO:            imblearn: 0.12.3
2024-07-03 16:32:11,188:INFO:   category_encoders: 2.6.3
2024-07-03 16:32:11,188:INFO:            lightgbm: 4.4.0
2024-07-03 16:32:11,188:INFO:               numba: 0.60.0
2024-07-03 16:32:11,188:INFO:            requests: 2.32.3
2024-07-03 16:32:11,188:INFO:          matplotlib: 3.7.5
2024-07-03 16:32:11,188:INFO:          scikitplot: 0.3.7
2024-07-03 16:32:11,188:INFO:         yellowbrick: 1.5
2024-07-03 16:32:11,189:INFO:              plotly: 5.22.0
2024-07-03 16:32:11,189:INFO:    plotly-resampler: Not installed
2024-07-03 16:32:11,189:INFO:             kaleido: 0.2.1
2024-07-03 16:32:11,189:INFO:           schemdraw: 0.15
2024-07-03 16:32:11,189:INFO:         statsmodels: 0.14.2
2024-07-03 16:32:11,189:INFO:              sktime: 0.26.0
2024-07-03 16:32:11,189:INFO:               tbats: 1.1.3
2024-07-03 16:32:11,189:INFO:            pmdarima: 2.0.4
2024-07-03 16:32:11,189:INFO:              psutil: 6.0.0
2024-07-03 16:32:11,189:INFO:          markupsafe: 2.1.5
2024-07-03 16:32:11,189:INFO:             pickle5: Not installed
2024-07-03 16:32:11,189:INFO:         cloudpickle: 3.0.0
2024-07-03 16:32:11,189:INFO:         deprecation: 2.1.0
2024-07-03 16:32:11,189:INFO:              xxhash: 3.4.1
2024-07-03 16:32:11,189:INFO:           wurlitzer: 3.1.1
2024-07-03 16:32:11,189:INFO:PyCaret optional dependencies:
2024-07-03 16:32:11,201:INFO:                shap: Not installed
2024-07-03 16:32:11,201:INFO:           interpret: Not installed
2024-07-03 16:32:11,201:INFO:                umap: Not installed
2024-07-03 16:32:11,201:INFO:     ydata_profiling: Not installed
2024-07-03 16:32:11,201:INFO:  explainerdashboard: Not installed
2024-07-03 16:32:11,201:INFO:             autoviz: Not installed
2024-07-03 16:32:11,201:INFO:           fairlearn: Not installed
2024-07-03 16:32:11,201:INFO:          deepchecks: Not installed
2024-07-03 16:32:11,201:INFO:             xgboost: Not installed
2024-07-03 16:32:11,201:INFO:            catboost: Not installed
2024-07-03 16:32:11,201:INFO:              kmodes: Not installed
2024-07-03 16:32:11,201:INFO:             mlxtend: Not installed
2024-07-03 16:32:11,201:INFO:       statsforecast: Not installed
2024-07-03 16:32:11,201:INFO:        tune_sklearn: Not installed
2024-07-03 16:32:11,201:INFO:                 ray: Not installed
2024-07-03 16:32:11,201:INFO:            hyperopt: Not installed
2024-07-03 16:32:11,201:INFO:              optuna: Not installed
2024-07-03 16:32:11,201:INFO:               skopt: Not installed
2024-07-03 16:32:11,201:INFO:              mlflow: Not installed
2024-07-03 16:32:11,201:INFO:              gradio: Not installed
2024-07-03 16:32:11,201:INFO:             fastapi: Not installed
2024-07-03 16:32:11,201:INFO:             uvicorn: Not installed
2024-07-03 16:32:11,201:INFO:              m2cgen: Not installed
2024-07-03 16:32:11,201:INFO:           evidently: Not installed
2024-07-03 16:32:11,201:INFO:               fugue: Not installed
2024-07-03 16:32:11,201:INFO:           streamlit: Not installed
2024-07-03 16:32:11,201:INFO:             prophet: Not installed
2024-07-03 16:32:11,201:INFO:None
2024-07-03 16:32:11,201:INFO:Set up GPU usage.
2024-07-03 16:32:11,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:11,201:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-07-03 16:32:11,201:INFO:Set up data.
2024-07-03 16:32:11,206:INFO:Set up folding strategy.
2024-07-03 16:32:11,206:INFO:Set up train/test split.
2024-07-03 16:32:11,211:INFO:Set up index.
2024-07-03 16:32:11,211:INFO:Assigning column types.
2024-07-03 16:32:11,215:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-03 16:32:11,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:11,247:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-03 16:32:11,247:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:11,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:11,250:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 16:32:11,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:11,269:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:11,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:11,273:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:32:14,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:32:14,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:14,778:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-03 16:32:14,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:14,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:14,778:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 16:32:14,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:14,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:14,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:14,798:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:32:14,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:32:14,862:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-03 16:32:14,862:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:14,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:14,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:14,899:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 16:32:14,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:14,915:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:14,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:14,919:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:32:14,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:32:14,980:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,017:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,017:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,017:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 16:32:15,017:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,033:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,037:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,037:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:32:15,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:32:15,099:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-03 16:32:15,099:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,136:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,136:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,136:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,156:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,156:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:32:15,217:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:32:15,218:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,255:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,255:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,255:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:32:15,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:32:15,340:INFO:Preparing preprocessing pipeline...
2024-07-03 16:32:15,341:INFO:Set up simple imputation.
2024-07-03 16:32:15,361:INFO:Finished creating preprocessing pipeline.
2024-07-03 16:32:15,364:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-03 16:32:15,364:INFO:Creating final display dataframe.
2024-07-03 16:32:15,422:INFO:Setup _display_container:                     Description             Value
0                    Session id              8888
1                        Target       Transported
2                   Target type            Binary
3           Original data shape        (8693, 11)
4        Transformed data shape        (8693, 11)
5   Transformed train set shape        (6085, 11)
6    Transformed test set shape        (2608, 11)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              c7af
2024-07-03 16:32:15,427:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,459:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,477:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,482:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:32:15,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:32:15,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,581:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,597:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 16:32:15,601:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:32:15,662:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 16:32:15,663:INFO:setup() successfully completed in 4.5s...............
2024-07-03 16:32:15,667:INFO:Initializing compare_models()
2024-07-03 16:32:15,668:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-03 16:32:15,668:INFO:Checking exceptions
2024-07-03 16:32:15,673:INFO:Preparing display monitor
2024-07-03 16:32:15,693:INFO:Initializing Logistic Regression
2024-07-03 16:32:15,693:INFO:Total runtime is 2.0305315653483075e-06 minutes
2024-07-03 16:32:15,696:INFO:SubProcess create_model() called ==================================
2024-07-03 16:32:15,696:INFO:Initializing create_model()
2024-07-03 16:32:15,696:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f78b0337b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:32:15,697:INFO:Checking exceptions
2024-07-03 16:32:15,697:INFO:Importing libraries
2024-07-03 16:32:15,697:INFO:Copying training dataset
2024-07-03 16:32:15,702:INFO:Defining folds
2024-07-03 16:32:15,702:INFO:Declaring metric variables
2024-07-03 16:32:15,704:INFO:Importing untrained model
2024-07-03 16:32:15,706:INFO:Logistic Regression Imported successfully
2024-07-03 16:32:15,711:INFO:Starting cross validation
2024-07-03 16:32:15,712:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:32:17,265:INFO:Calculating mean and std
2024-07-03 16:32:17,267:INFO:Creating metrics dataframe
2024-07-03 16:32:17,268:INFO:Uploading results into container
2024-07-03 16:32:17,269:INFO:Uploading model into container now
2024-07-03 16:32:17,269:INFO:_master_model_container: 1
2024-07-03 16:32:17,269:INFO:_display_container: 2
2024-07-03 16:32:17,270:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8888, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-03 16:32:17,270:INFO:create_model() successfully completed......................................
2024-07-03 16:32:17,352:INFO:SubProcess create_model() end ==================================
2024-07-03 16:32:17,352:INFO:Creating metrics dataframe
2024-07-03 16:32:17,357:INFO:Initializing K Neighbors Classifier
2024-07-03 16:32:17,357:INFO:Total runtime is 0.02773391008377075 minutes
2024-07-03 16:32:17,359:INFO:SubProcess create_model() called ==================================
2024-07-03 16:32:17,359:INFO:Initializing create_model()
2024-07-03 16:32:17,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f78b0337b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:32:17,359:INFO:Checking exceptions
2024-07-03 16:32:17,359:INFO:Importing libraries
2024-07-03 16:32:17,359:INFO:Copying training dataset
2024-07-03 16:32:17,364:INFO:Defining folds
2024-07-03 16:32:17,364:INFO:Declaring metric variables
2024-07-03 16:32:17,366:INFO:Importing untrained model
2024-07-03 16:32:17,369:INFO:K Neighbors Classifier Imported successfully
2024-07-03 16:32:17,374:INFO:Starting cross validation
2024-07-03 16:32:17,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:32:18,528:INFO:Calculating mean and std
2024-07-03 16:32:18,529:INFO:Creating metrics dataframe
2024-07-03 16:32:18,532:INFO:Uploading results into container
2024-07-03 16:32:18,532:INFO:Uploading model into container now
2024-07-03 16:32:18,533:INFO:_master_model_container: 2
2024-07-03 16:32:18,533:INFO:_display_container: 2
2024-07-03 16:32:18,533:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-03 16:32:18,533:INFO:create_model() successfully completed......................................
2024-07-03 16:32:18,591:INFO:SubProcess create_model() end ==================================
2024-07-03 16:32:18,591:INFO:Creating metrics dataframe
2024-07-03 16:32:18,597:INFO:Initializing Naive Bayes
2024-07-03 16:32:18,597:INFO:Total runtime is 0.04840522607167562 minutes
2024-07-03 16:32:18,600:INFO:SubProcess create_model() called ==================================
2024-07-03 16:32:18,600:INFO:Initializing create_model()
2024-07-03 16:32:18,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f78b0337b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:32:18,600:INFO:Checking exceptions
2024-07-03 16:32:18,600:INFO:Importing libraries
2024-07-03 16:32:18,600:INFO:Copying training dataset
2024-07-03 16:32:18,605:INFO:Defining folds
2024-07-03 16:32:18,605:INFO:Declaring metric variables
2024-07-03 16:32:18,607:INFO:Importing untrained model
2024-07-03 16:32:18,609:INFO:Naive Bayes Imported successfully
2024-07-03 16:32:18,614:INFO:Starting cross validation
2024-07-03 16:32:18,615:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:32:18,838:INFO:Calculating mean and std
2024-07-03 16:32:18,839:INFO:Creating metrics dataframe
2024-07-03 16:32:18,840:INFO:Uploading results into container
2024-07-03 16:32:18,840:INFO:Uploading model into container now
2024-07-03 16:32:18,841:INFO:_master_model_container: 3
2024-07-03 16:32:18,841:INFO:_display_container: 2
2024-07-03 16:32:18,841:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-03 16:32:18,841:INFO:create_model() successfully completed......................................
2024-07-03 16:32:18,896:INFO:SubProcess create_model() end ==================================
2024-07-03 16:32:18,896:INFO:Creating metrics dataframe
2024-07-03 16:32:18,902:INFO:Initializing Decision Tree Classifier
2024-07-03 16:32:18,902:INFO:Total runtime is 0.05348863204320272 minutes
2024-07-03 16:32:18,904:INFO:SubProcess create_model() called ==================================
2024-07-03 16:32:18,905:INFO:Initializing create_model()
2024-07-03 16:32:18,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f78b0337b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:32:18,905:INFO:Checking exceptions
2024-07-03 16:32:18,905:INFO:Importing libraries
2024-07-03 16:32:18,905:INFO:Copying training dataset
2024-07-03 16:32:18,910:INFO:Defining folds
2024-07-03 16:32:18,910:INFO:Declaring metric variables
2024-07-03 16:32:18,912:INFO:Importing untrained model
2024-07-03 16:32:18,914:INFO:Decision Tree Classifier Imported successfully
2024-07-03 16:32:18,919:INFO:Starting cross validation
2024-07-03 16:32:18,919:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:32:19,272:INFO:Calculating mean and std
2024-07-03 16:32:19,273:INFO:Creating metrics dataframe
2024-07-03 16:32:19,274:INFO:Uploading results into container
2024-07-03 16:32:19,274:INFO:Uploading model into container now
2024-07-03 16:32:19,274:INFO:_master_model_container: 4
2024-07-03 16:32:19,274:INFO:_display_container: 2
2024-07-03 16:32:19,275:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8888, splitter='best')
2024-07-03 16:32:19,275:INFO:create_model() successfully completed......................................
2024-07-03 16:32:19,331:INFO:SubProcess create_model() end ==================================
2024-07-03 16:32:19,331:INFO:Creating metrics dataframe
2024-07-03 16:32:19,336:INFO:Initializing SVM - Linear Kernel
2024-07-03 16:32:19,336:INFO:Total runtime is 0.06072592735290527 minutes
2024-07-03 16:32:19,339:INFO:SubProcess create_model() called ==================================
2024-07-03 16:32:19,339:INFO:Initializing create_model()
2024-07-03 16:32:19,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f78b0337b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:32:19,339:INFO:Checking exceptions
2024-07-03 16:32:19,339:INFO:Importing libraries
2024-07-03 16:32:19,339:INFO:Copying training dataset
2024-07-03 16:32:19,344:INFO:Defining folds
2024-07-03 16:32:19,344:INFO:Declaring metric variables
2024-07-03 16:32:19,346:INFO:Importing untrained model
2024-07-03 16:32:19,348:INFO:SVM - Linear Kernel Imported successfully
2024-07-03 16:32:19,353:INFO:Starting cross validation
2024-07-03 16:32:19,354:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:32:19,680:INFO:Calculating mean and std
2024-07-03 16:32:19,681:INFO:Creating metrics dataframe
2024-07-03 16:32:19,682:INFO:Uploading results into container
2024-07-03 16:32:19,682:INFO:Uploading model into container now
2024-07-03 16:32:19,683:INFO:_master_model_container: 5
2024-07-03 16:32:19,683:INFO:_display_container: 2
2024-07-03 16:32:19,683:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8888, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-03 16:32:19,683:INFO:create_model() successfully completed......................................
2024-07-03 16:32:19,739:INFO:SubProcess create_model() end ==================================
2024-07-03 16:32:19,739:INFO:Creating metrics dataframe
2024-07-03 16:32:19,745:INFO:Initializing Ridge Classifier
2024-07-03 16:32:19,745:INFO:Total runtime is 0.06753513018290201 minutes
2024-07-03 16:32:19,747:INFO:SubProcess create_model() called ==================================
2024-07-03 16:32:19,748:INFO:Initializing create_model()
2024-07-03 16:32:19,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f78b0337b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:32:19,748:INFO:Checking exceptions
2024-07-03 16:32:19,748:INFO:Importing libraries
2024-07-03 16:32:19,748:INFO:Copying training dataset
2024-07-03 16:32:19,753:INFO:Defining folds
2024-07-03 16:32:19,753:INFO:Declaring metric variables
2024-07-03 16:32:19,755:INFO:Importing untrained model
2024-07-03 16:32:19,757:INFO:Ridge Classifier Imported successfully
2024-07-03 16:32:19,763:INFO:Starting cross validation
2024-07-03 16:32:19,763:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:32:19,780:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.37152e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:32:19,804:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.52883e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:32:19,827:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.31264e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:32:19,850:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.5489e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:32:19,873:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.57491e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:32:19,896:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.40388e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:32:19,919:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.48847e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:32:19,942:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.59372e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:32:19,965:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.87456e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:32:19,988:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.36341e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 16:32:20,003:INFO:Calculating mean and std
2024-07-03 16:32:20,004:INFO:Creating metrics dataframe
2024-07-03 16:32:20,005:INFO:Uploading results into container
2024-07-03 16:32:20,005:INFO:Uploading model into container now
2024-07-03 16:32:20,006:INFO:_master_model_container: 6
2024-07-03 16:32:20,006:INFO:_display_container: 2
2024-07-03 16:32:20,006:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8888, solver='auto',
                tol=0.0001)
2024-07-03 16:32:20,006:INFO:create_model() successfully completed......................................
2024-07-03 16:32:20,063:INFO:SubProcess create_model() end ==================================
2024-07-03 16:32:20,063:INFO:Creating metrics dataframe
2024-07-03 16:32:20,068:INFO:Initializing Random Forest Classifier
2024-07-03 16:32:20,069:INFO:Total runtime is 0.07292908430099487 minutes
2024-07-03 16:32:20,071:INFO:SubProcess create_model() called ==================================
2024-07-03 16:32:20,071:INFO:Initializing create_model()
2024-07-03 16:32:20,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f78b0337b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:32:20,071:INFO:Checking exceptions
2024-07-03 16:32:20,071:INFO:Importing libraries
2024-07-03 16:32:20,071:INFO:Copying training dataset
2024-07-03 16:32:20,076:INFO:Defining folds
2024-07-03 16:32:20,076:INFO:Declaring metric variables
2024-07-03 16:32:20,078:INFO:Importing untrained model
2024-07-03 16:32:20,081:INFO:Random Forest Classifier Imported successfully
2024-07-03 16:32:20,085:INFO:Starting cross validation
2024-07-03 16:32:20,085:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:32:22,429:INFO:Calculating mean and std
2024-07-03 16:32:22,430:INFO:Creating metrics dataframe
2024-07-03 16:32:22,432:INFO:Uploading results into container
2024-07-03 16:32:22,432:INFO:Uploading model into container now
2024-07-03 16:32:22,432:INFO:_master_model_container: 7
2024-07-03 16:32:22,433:INFO:_display_container: 2
2024-07-03 16:32:22,433:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 16:32:22,433:INFO:create_model() successfully completed......................................
2024-07-03 16:32:22,492:INFO:SubProcess create_model() end ==================================
2024-07-03 16:32:22,492:INFO:Creating metrics dataframe
2024-07-03 16:32:22,498:INFO:Initializing Quadratic Discriminant Analysis
2024-07-03 16:32:22,498:INFO:Total runtime is 0.11342800060908 minutes
2024-07-03 16:32:22,501:INFO:SubProcess create_model() called ==================================
2024-07-03 16:32:22,501:INFO:Initializing create_model()
2024-07-03 16:32:22,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f78b0337b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:32:22,501:INFO:Checking exceptions
2024-07-03 16:32:22,501:INFO:Importing libraries
2024-07-03 16:32:22,501:INFO:Copying training dataset
2024-07-03 16:32:22,506:INFO:Defining folds
2024-07-03 16:32:22,506:INFO:Declaring metric variables
2024-07-03 16:32:22,508:INFO:Importing untrained model
2024-07-03 16:32:22,510:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-03 16:32:22,514:INFO:Starting cross validation
2024-07-03 16:32:22,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:32:22,529:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:32:22,564:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:32:22,600:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:32:22,635:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:32:22,653:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 16:32:22,672:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:32:22,707:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:32:22,725:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 16:32:22,744:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:32:22,780:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:32:22,816:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:32:22,833:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 16:32:22,852:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 16:32:22,876:INFO:Calculating mean and std
2024-07-03 16:32:22,878:INFO:Creating metrics dataframe
2024-07-03 16:32:22,880:INFO:Uploading results into container
2024-07-03 16:32:22,880:INFO:Uploading model into container now
2024-07-03 16:32:22,880:INFO:_master_model_container: 8
2024-07-03 16:32:22,881:INFO:_display_container: 2
2024-07-03 16:32:22,881:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-03 16:32:22,881:INFO:create_model() successfully completed......................................
2024-07-03 16:32:22,950:INFO:SubProcess create_model() end ==================================
2024-07-03 16:32:22,950:INFO:Creating metrics dataframe
2024-07-03 16:32:22,959:INFO:Initializing Ada Boost Classifier
2024-07-03 16:32:22,959:INFO:Total runtime is 0.1211023211479187 minutes
2024-07-03 16:32:22,961:INFO:SubProcess create_model() called ==================================
2024-07-03 16:32:22,961:INFO:Initializing create_model()
2024-07-03 16:32:22,961:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f78b0337b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:32:22,961:INFO:Checking exceptions
2024-07-03 16:32:22,961:INFO:Importing libraries
2024-07-03 16:32:22,962:INFO:Copying training dataset
2024-07-03 16:32:22,966:INFO:Defining folds
2024-07-03 16:32:22,966:INFO:Declaring metric variables
2024-07-03 16:32:22,968:INFO:Importing untrained model
2024-07-03 16:32:22,970:INFO:Ada Boost Classifier Imported successfully
2024-07-03 16:32:22,975:INFO:Starting cross validation
2024-07-03 16:32:22,975:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:32:22,986:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:32:23,150:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:32:23,310:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:32:23,470:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:32:23,630:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:32:23,790:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:32:23,950:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:32:24,110:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:32:24,268:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:32:24,426:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 16:32:24,579:INFO:Calculating mean and std
2024-07-03 16:32:24,579:INFO:Creating metrics dataframe
2024-07-03 16:32:24,580:INFO:Uploading results into container
2024-07-03 16:32:24,581:INFO:Uploading model into container now
2024-07-03 16:32:24,581:INFO:_master_model_container: 9
2024-07-03 16:32:24,581:INFO:_display_container: 2
2024-07-03 16:32:24,581:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8888)
2024-07-03 16:32:24,581:INFO:create_model() successfully completed......................................
2024-07-03 16:32:24,637:INFO:SubProcess create_model() end ==================================
2024-07-03 16:32:24,637:INFO:Creating metrics dataframe
2024-07-03 16:32:24,644:INFO:Initializing Gradient Boosting Classifier
2024-07-03 16:32:24,644:INFO:Total runtime is 0.14918737411499022 minutes
2024-07-03 16:32:24,646:INFO:SubProcess create_model() called ==================================
2024-07-03 16:32:24,646:INFO:Initializing create_model()
2024-07-03 16:32:24,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f78b0337b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:32:24,647:INFO:Checking exceptions
2024-07-03 16:32:24,647:INFO:Importing libraries
2024-07-03 16:32:24,647:INFO:Copying training dataset
2024-07-03 16:32:24,652:INFO:Defining folds
2024-07-03 16:32:24,652:INFO:Declaring metric variables
2024-07-03 16:32:24,654:INFO:Importing untrained model
2024-07-03 16:32:24,656:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 16:32:24,661:INFO:Starting cross validation
2024-07-03 16:32:24,662:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:32:28,865:INFO:Calculating mean and std
2024-07-03 16:32:28,866:INFO:Creating metrics dataframe
2024-07-03 16:32:28,867:INFO:Uploading results into container
2024-07-03 16:32:28,868:INFO:Uploading model into container now
2024-07-03 16:32:28,868:INFO:_master_model_container: 10
2024-07-03 16:32:28,868:INFO:_display_container: 2
2024-07-03 16:32:28,869:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 16:32:28,869:INFO:create_model() successfully completed......................................
2024-07-03 16:32:28,930:INFO:SubProcess create_model() end ==================================
2024-07-03 16:32:28,930:INFO:Creating metrics dataframe
2024-07-03 16:32:28,936:INFO:Initializing Linear Discriminant Analysis
2024-07-03 16:32:28,936:INFO:Total runtime is 0.2207194447517395 minutes
2024-07-03 16:32:28,938:INFO:SubProcess create_model() called ==================================
2024-07-03 16:32:28,938:INFO:Initializing create_model()
2024-07-03 16:32:28,938:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f78b0337b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:32:28,939:INFO:Checking exceptions
2024-07-03 16:32:28,939:INFO:Importing libraries
2024-07-03 16:32:28,939:INFO:Copying training dataset
2024-07-03 16:32:28,943:INFO:Defining folds
2024-07-03 16:32:28,944:INFO:Declaring metric variables
2024-07-03 16:32:28,946:INFO:Importing untrained model
2024-07-03 16:32:28,948:INFO:Linear Discriminant Analysis Imported successfully
2024-07-03 16:32:28,953:INFO:Starting cross validation
2024-07-03 16:32:28,953:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:32:29,330:INFO:Calculating mean and std
2024-07-03 16:32:29,331:INFO:Creating metrics dataframe
2024-07-03 16:32:29,333:INFO:Uploading results into container
2024-07-03 16:32:29,333:INFO:Uploading model into container now
2024-07-03 16:32:29,334:INFO:_master_model_container: 11
2024-07-03 16:32:29,334:INFO:_display_container: 2
2024-07-03 16:32:29,334:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-03 16:32:29,334:INFO:create_model() successfully completed......................................
2024-07-03 16:32:29,405:INFO:SubProcess create_model() end ==================================
2024-07-03 16:32:29,405:INFO:Creating metrics dataframe
2024-07-03 16:32:29,413:INFO:Initializing Extra Trees Classifier
2024-07-03 16:32:29,413:INFO:Total runtime is 0.2286748210589091 minutes
2024-07-03 16:32:29,416:INFO:SubProcess create_model() called ==================================
2024-07-03 16:32:29,416:INFO:Initializing create_model()
2024-07-03 16:32:29,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f78b0337b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:32:29,416:INFO:Checking exceptions
2024-07-03 16:32:29,416:INFO:Importing libraries
2024-07-03 16:32:29,416:INFO:Copying training dataset
2024-07-03 16:32:29,420:INFO:Defining folds
2024-07-03 16:32:29,420:INFO:Declaring metric variables
2024-07-03 16:32:29,423:INFO:Importing untrained model
2024-07-03 16:32:29,425:INFO:Extra Trees Classifier Imported successfully
2024-07-03 16:32:29,429:INFO:Starting cross validation
2024-07-03 16:32:29,429:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:32:31,671:INFO:Calculating mean and std
2024-07-03 16:32:31,672:INFO:Creating metrics dataframe
2024-07-03 16:32:31,673:INFO:Uploading results into container
2024-07-03 16:32:31,674:INFO:Uploading model into container now
2024-07-03 16:32:31,674:INFO:_master_model_container: 12
2024-07-03 16:32:31,674:INFO:_display_container: 2
2024-07-03 16:32:31,674:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8888, verbose=0,
                     warm_start=False)
2024-07-03 16:32:31,674:INFO:create_model() successfully completed......................................
2024-07-03 16:32:31,733:INFO:SubProcess create_model() end ==================================
2024-07-03 16:32:31,733:INFO:Creating metrics dataframe
2024-07-03 16:32:31,741:INFO:Initializing Light Gradient Boosting Machine
2024-07-03 16:32:31,741:INFO:Total runtime is 0.2674631992975871 minutes
2024-07-03 16:32:31,743:INFO:SubProcess create_model() called ==================================
2024-07-03 16:32:31,743:INFO:Initializing create_model()
2024-07-03 16:32:31,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f78b0337b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:32:31,743:INFO:Checking exceptions
2024-07-03 16:32:31,743:INFO:Importing libraries
2024-07-03 16:32:31,743:INFO:Copying training dataset
2024-07-03 16:32:31,748:INFO:Defining folds
2024-07-03 16:32:31,748:INFO:Declaring metric variables
2024-07-03 16:32:31,750:INFO:Importing untrained model
2024-07-03 16:32:31,753:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-03 16:32:31,757:INFO:Starting cross validation
2024-07-03 16:32:31,758:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:32:31,773:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 16:32:31,773:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:32:31,773:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 16:32:31,773:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 16:32:31,825:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:32:31,825:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:32:31,839:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:32:31,840:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:32:31,840:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000227 secs. 1 sparse feature groups
2024-07-03 16:32:31,841:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 16:32:31,841:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 16:32:32,053:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 16:32:32,053:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:32:32,053:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 16:32:32,053:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 16:32:32,091:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:32:32,091:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:32:32,097:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:32:32,098:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:32:32,098:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000220 secs. 1 sparse feature groups
2024-07-03 16:32:32,098:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 16:32:32,098:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 16:32:32,310:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 16:32:32,311:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:32:32,311:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-03 16:32:32,311:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 16:32:32,349:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:32:32,349:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:32:32,354:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:32:32,355:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:32:32,355:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000250 secs. 1 sparse feature groups
2024-07-03 16:32:32,355:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 16:32:32,356:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 16:32:32,565:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 16:32:32,565:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:32:32,565:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 16:32:32,565:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 16:32:32,603:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:32:32,603:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:32:32,608:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:32:32,609:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:32:32,609:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000241 secs. 1 sparse feature groups
2024-07-03 16:32:32,610:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 16:32:32,610:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 16:32:32,823:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 16:32:32,823:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:32:32,823:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-03 16:32:32,823:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 16:32:32,864:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:32:32,864:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:32:32,870:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:32:32,870:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:32:32,871:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000241 secs. 1 sparse feature groups
2024-07-03 16:32:32,871:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 16:32:32,871:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 16:32:33,081:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 16:32:33,081:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:32:33,081:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-03 16:32:33,081:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 16:32:33,120:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:32:33,121:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:32:33,125:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:32:33,126:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:32:33,127:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000243 secs. 1 sparse feature groups
2024-07-03 16:32:33,127:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 16:32:33,127:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 16:32:33,334:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 16:32:33,334:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:32:33,334:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 16:32:33,335:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 16:32:33,372:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:32:33,372:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:32:33,378:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:32:33,379:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:32:33,379:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000253 secs. 1 sparse feature groups
2024-07-03 16:32:33,379:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 16:32:33,379:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 16:32:33,586:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 16:32:33,586:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:32:33,586:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-03 16:32:33,587:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 16:32:33,626:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:32:33,627:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:32:33,632:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:32:33,633:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:32:33,633:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000222 secs. 1 sparse feature groups
2024-07-03 16:32:33,633:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 16:32:33,633:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 16:32:33,844:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 16:32:33,844:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:32:33,845:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 16:32:33,845:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 16:32:33,883:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:32:33,883:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:32:33,888:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:32:33,889:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:32:33,889:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000243 secs. 1 sparse feature groups
2024-07-03 16:32:33,889:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 16:32:33,889:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 16:32:34,098:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 16:32:34,098:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 16:32:34,098:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 16:32:34,098:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 16:32:34,137:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 16:32:34,137:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 16:32:34,142:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 16:32:34,143:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 16:32:34,143:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000230 secs. 1 sparse feature groups
2024-07-03 16:32:34,143:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 16:32:34,143:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 16:32:34,344:INFO:Calculating mean and std
2024-07-03 16:32:34,345:INFO:Creating metrics dataframe
2024-07-03 16:32:34,346:INFO:Uploading results into container
2024-07-03 16:32:34,347:INFO:Uploading model into container now
2024-07-03 16:32:34,347:INFO:_master_model_container: 13
2024-07-03 16:32:34,347:INFO:_display_container: 2
2024-07-03 16:32:34,348:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=8888, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-07-03 16:32:34,348:INFO:create_model() successfully completed......................................
2024-07-03 16:32:34,404:INFO:SubProcess create_model() end ==================================
2024-07-03 16:32:34,404:INFO:Creating metrics dataframe
2024-07-03 16:32:34,412:INFO:Initializing Dummy Classifier
2024-07-03 16:32:34,412:INFO:Total runtime is 0.3119824886322022 minutes
2024-07-03 16:32:34,414:INFO:SubProcess create_model() called ==================================
2024-07-03 16:32:34,414:INFO:Initializing create_model()
2024-07-03 16:32:34,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f78b0337b10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:32:34,414:INFO:Checking exceptions
2024-07-03 16:32:34,414:INFO:Importing libraries
2024-07-03 16:32:34,415:INFO:Copying training dataset
2024-07-03 16:32:34,419:INFO:Defining folds
2024-07-03 16:32:34,419:INFO:Declaring metric variables
2024-07-03 16:32:34,422:INFO:Importing untrained model
2024-07-03 16:32:34,424:INFO:Dummy Classifier Imported successfully
2024-07-03 16:32:34,429:INFO:Starting cross validation
2024-07-03 16:32:34,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:32:34,627:INFO:Calculating mean and std
2024-07-03 16:32:34,628:INFO:Creating metrics dataframe
2024-07-03 16:32:34,629:INFO:Uploading results into container
2024-07-03 16:32:34,629:INFO:Uploading model into container now
2024-07-03 16:32:34,629:INFO:_master_model_container: 14
2024-07-03 16:32:34,629:INFO:_display_container: 2
2024-07-03 16:32:34,630:INFO:DummyClassifier(constant=None, random_state=8888, strategy='prior')
2024-07-03 16:32:34,630:INFO:create_model() successfully completed......................................
2024-07-03 16:32:34,687:INFO:SubProcess create_model() end ==================================
2024-07-03 16:32:34,687:INFO:Creating metrics dataframe
2024-07-03 16:32:34,696:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-03 16:32:34,701:INFO:Initializing create_model()
2024-07-03 16:32:34,701:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:32:34,702:INFO:Checking exceptions
2024-07-03 16:32:34,703:INFO:Importing libraries
2024-07-03 16:32:34,703:INFO:Copying training dataset
2024-07-03 16:32:34,707:INFO:Defining folds
2024-07-03 16:32:34,707:INFO:Declaring metric variables
2024-07-03 16:32:34,707:INFO:Importing untrained model
2024-07-03 16:32:34,707:INFO:Declaring custom model
2024-07-03 16:32:34,708:INFO:Random Forest Classifier Imported successfully
2024-07-03 16:32:34,708:INFO:Cross validation set to False
2024-07-03 16:32:34,708:INFO:Fitting Model
2024-07-03 16:32:34,879:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 16:32:34,879:INFO:create_model() successfully completed......................................
2024-07-03 16:32:34,955:INFO:_master_model_container: 14
2024-07-03 16:32:34,955:INFO:_display_container: 2
2024-07-03 16:32:34,955:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 16:32:34,955:INFO:compare_models() successfully completed......................................
2024-07-03 16:32:34,962:INFO:Initializing create_model()
2024-07-03 16:32:34,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=gbc, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:32:34,962:INFO:Checking exceptions
2024-07-03 16:32:34,974:INFO:Importing libraries
2024-07-03 16:32:34,974:INFO:Copying training dataset
2024-07-03 16:32:34,980:INFO:Defining folds
2024-07-03 16:32:34,980:INFO:Declaring metric variables
2024-07-03 16:32:34,983:INFO:Importing untrained model
2024-07-03 16:32:34,985:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 16:32:34,990:INFO:Starting cross validation
2024-07-03 16:32:34,990:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:32:36,950:INFO:Calculating mean and std
2024-07-03 16:32:36,951:INFO:Creating metrics dataframe
2024-07-03 16:32:36,955:INFO:Finalizing model
2024-07-03 16:32:37,403:INFO:Uploading results into container
2024-07-03 16:32:37,404:INFO:Uploading model into container now
2024-07-03 16:32:37,410:INFO:_master_model_container: 15
2024-07-03 16:32:37,410:INFO:_display_container: 3
2024-07-03 16:32:37,411:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 16:32:37,411:INFO:create_model() successfully completed......................................
2024-07-03 16:32:37,471:INFO:Initializing tune_model()
2024-07-03 16:32:37,471:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-03 16:32:37,472:INFO:Checking exceptions
2024-07-03 16:32:37,485:INFO:Copying training dataset
2024-07-03 16:32:37,489:INFO:Checking base model
2024-07-03 16:32:37,489:INFO:Base model : Gradient Boosting Classifier
2024-07-03 16:32:37,492:INFO:Declaring metric variables
2024-07-03 16:32:37,495:INFO:Defining Hyperparameters
2024-07-03 16:32:37,552:INFO:Tuning with n_jobs=-1
2024-07-03 16:32:37,552:INFO:Initializing RandomizedSearchCV
2024-07-03 16:32:58,400:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.2, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.001}
2024-07-03 16:32:58,401:INFO:Hyperparameter search completed
2024-07-03 16:32:58,401:INFO:SubProcess create_model() called ==================================
2024-07-03 16:32:58,402:INFO:Initializing create_model()
2024-07-03 16:32:58,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f79245d4d10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'n_estimators': 160, 'min_samples_split': 7, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.2, 'max_features': 'log2', 'max_depth': 9, 'learning_rate': 0.001})
2024-07-03 16:32:58,402:INFO:Checking exceptions
2024-07-03 16:32:58,402:INFO:Importing libraries
2024-07-03 16:32:58,402:INFO:Copying training dataset
2024-07-03 16:32:58,407:INFO:Defining folds
2024-07-03 16:32:58,408:INFO:Declaring metric variables
2024-07-03 16:32:58,410:INFO:Importing untrained model
2024-07-03 16:32:58,410:INFO:Declaring custom model
2024-07-03 16:32:58,413:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 16:32:58,418:INFO:Starting cross validation
2024-07-03 16:32:58,419:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:33:08,870:INFO:Calculating mean and std
2024-07-03 16:33:08,871:INFO:Creating metrics dataframe
2024-07-03 16:33:08,875:INFO:Finalizing model
2024-07-03 16:33:09,969:INFO:Uploading results into container
2024-07-03 16:33:09,970:INFO:Uploading model into container now
2024-07-03 16:33:09,970:INFO:_master_model_container: 16
2024-07-03 16:33:09,970:INFO:_display_container: 4
2024-07-03 16:33:09,971:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 16:33:09,971:INFO:create_model() successfully completed......................................
2024-07-03 16:33:10,035:INFO:SubProcess create_model() end ==================================
2024-07-03 16:33:10,035:INFO:choose_better activated
2024-07-03 16:33:10,038:INFO:SubProcess create_model() called ==================================
2024-07-03 16:33:10,038:INFO:Initializing create_model()
2024-07-03 16:33:10,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:33:10,038:INFO:Checking exceptions
2024-07-03 16:33:10,039:INFO:Importing libraries
2024-07-03 16:33:10,039:INFO:Copying training dataset
2024-07-03 16:33:10,044:INFO:Defining folds
2024-07-03 16:33:10,044:INFO:Declaring metric variables
2024-07-03 16:33:10,044:INFO:Importing untrained model
2024-07-03 16:33:10,044:INFO:Declaring custom model
2024-07-03 16:33:10,044:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 16:33:10,044:INFO:Starting cross validation
2024-07-03 16:33:10,045:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:33:14,432:INFO:Calculating mean and std
2024-07-03 16:33:14,432:INFO:Creating metrics dataframe
2024-07-03 16:33:14,433:INFO:Finalizing model
2024-07-03 16:33:14,890:INFO:Uploading results into container
2024-07-03 16:33:14,891:INFO:Uploading model into container now
2024-07-03 16:33:14,891:INFO:_master_model_container: 17
2024-07-03 16:33:14,891:INFO:_display_container: 5
2024-07-03 16:33:14,891:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 16:33:14,891:INFO:create_model() successfully completed......................................
2024-07-03 16:33:14,947:INFO:SubProcess create_model() end ==================================
2024-07-03 16:33:14,947:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.7896
2024-07-03 16:33:14,948:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.7936
2024-07-03 16:33:14,948:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-07-03 16:33:14,948:INFO:choose_better completed
2024-07-03 16:33:14,955:INFO:_master_model_container: 17
2024-07-03 16:33:14,955:INFO:_display_container: 4
2024-07-03 16:33:14,955:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 16:33:14,955:INFO:tune_model() successfully completed......................................
2024-07-03 16:33:15,019:INFO:Initializing evaluate_model()
2024-07-03 16:33:15,020:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-07-03 16:33:15,031:INFO:Initializing plot_model()
2024-07-03 16:33:15,031:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 16:33:15,031:INFO:Checking exceptions
2024-07-03 16:33:15,034:INFO:Preloading libraries
2024-07-03 16:33:15,045:INFO:Copying training dataset
2024-07-03 16:33:15,045:INFO:Plot type: pipeline
2024-07-03 16:33:15,145:INFO:Visual Rendered Successfully
2024-07-03 16:33:15,218:INFO:plot_model() successfully completed......................................
2024-07-03 16:33:15,227:INFO:Initializing create_model()
2024-07-03 16:33:15,227:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:33:15,227:INFO:Checking exceptions
2024-07-03 16:33:15,237:INFO:Importing libraries
2024-07-03 16:33:15,237:INFO:Copying training dataset
2024-07-03 16:33:15,242:INFO:Defining folds
2024-07-03 16:33:15,242:INFO:Declaring metric variables
2024-07-03 16:33:15,244:INFO:Importing untrained model
2024-07-03 16:33:15,247:INFO:Random Forest Classifier Imported successfully
2024-07-03 16:33:15,251:INFO:Starting cross validation
2024-07-03 16:33:15,252:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:33:16,422:INFO:Calculating mean and std
2024-07-03 16:33:16,423:INFO:Creating metrics dataframe
2024-07-03 16:33:16,427:INFO:Finalizing model
2024-07-03 16:33:16,601:INFO:Uploading results into container
2024-07-03 16:33:16,601:INFO:Uploading model into container now
2024-07-03 16:33:16,607:INFO:_master_model_container: 18
2024-07-03 16:33:16,607:INFO:_display_container: 5
2024-07-03 16:33:16,607:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 16:33:16,607:INFO:create_model() successfully completed......................................
2024-07-03 16:33:16,669:INFO:Initializing tune_model()
2024-07-03 16:33:16,669:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-03 16:33:16,670:INFO:Checking exceptions
2024-07-03 16:33:16,682:INFO:Copying training dataset
2024-07-03 16:33:16,685:INFO:Checking base model
2024-07-03 16:33:16,685:INFO:Base model : Random Forest Classifier
2024-07-03 16:33:16,688:INFO:Declaring metric variables
2024-07-03 16:33:16,691:INFO:Defining Hyperparameters
2024-07-03 16:33:16,751:INFO:Tuning with n_jobs=-1
2024-07-03 16:33:16,751:INFO:Initializing RandomizedSearchCV
2024-07-03 16:33:23,390:INFO:best_params: {'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2024-07-03 16:33:23,391:INFO:Hyperparameter search completed
2024-07-03 16:33:23,391:INFO:SubProcess create_model() called ==================================
2024-07-03 16:33:23,392:INFO:Initializing create_model()
2024-07-03 16:33:23,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f78b91215d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 160, 'min_samples_split': 7, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2024-07-03 16:33:23,392:INFO:Checking exceptions
2024-07-03 16:33:23,392:INFO:Importing libraries
2024-07-03 16:33:23,392:INFO:Copying training dataset
2024-07-03 16:33:23,397:INFO:Defining folds
2024-07-03 16:33:23,397:INFO:Declaring metric variables
2024-07-03 16:33:23,399:INFO:Importing untrained model
2024-07-03 16:33:23,399:INFO:Declaring custom model
2024-07-03 16:33:23,402:INFO:Random Forest Classifier Imported successfully
2024-07-03 16:33:23,407:INFO:Starting cross validation
2024-07-03 16:33:23,407:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:33:26,293:INFO:Calculating mean and std
2024-07-03 16:33:26,294:INFO:Creating metrics dataframe
2024-07-03 16:33:26,297:INFO:Finalizing model
2024-07-03 16:33:26,539:INFO:Uploading results into container
2024-07-03 16:33:26,540:INFO:Uploading model into container now
2024-07-03 16:33:26,540:INFO:_master_model_container: 19
2024-07-03 16:33:26,540:INFO:_display_container: 6
2024-07-03 16:33:26,541:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False)
2024-07-03 16:33:26,541:INFO:create_model() successfully completed......................................
2024-07-03 16:33:26,601:INFO:SubProcess create_model() end ==================================
2024-07-03 16:33:26,601:INFO:choose_better activated
2024-07-03 16:33:26,604:INFO:SubProcess create_model() called ==================================
2024-07-03 16:33:26,604:INFO:Initializing create_model()
2024-07-03 16:33:26,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:33:26,604:INFO:Checking exceptions
2024-07-03 16:33:26,605:INFO:Importing libraries
2024-07-03 16:33:26,605:INFO:Copying training dataset
2024-07-03 16:33:26,610:INFO:Defining folds
2024-07-03 16:33:26,610:INFO:Declaring metric variables
2024-07-03 16:33:26,610:INFO:Importing untrained model
2024-07-03 16:33:26,610:INFO:Declaring custom model
2024-07-03 16:33:26,611:INFO:Random Forest Classifier Imported successfully
2024-07-03 16:33:26,611:INFO:Starting cross validation
2024-07-03 16:33:26,611:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 16:33:29,235:INFO:Calculating mean and std
2024-07-03 16:33:29,236:INFO:Creating metrics dataframe
2024-07-03 16:33:29,237:INFO:Finalizing model
2024-07-03 16:33:29,401:INFO:Uploading results into container
2024-07-03 16:33:29,401:INFO:Uploading model into container now
2024-07-03 16:33:29,401:INFO:_master_model_container: 20
2024-07-03 16:33:29,401:INFO:_display_container: 7
2024-07-03 16:33:29,402:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 16:33:29,402:INFO:create_model() successfully completed......................................
2024-07-03 16:33:29,459:INFO:SubProcess create_model() end ==================================
2024-07-03 16:33:29,460:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False) result for Accuracy is 0.79
2024-07-03 16:33:29,460:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False) result for Accuracy is 0.7936
2024-07-03 16:33:29,460:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False) is best model
2024-07-03 16:33:29,460:INFO:choose_better completed
2024-07-03 16:33:29,467:INFO:_master_model_container: 20
2024-07-03 16:33:29,467:INFO:_display_container: 6
2024-07-03 16:33:29,467:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False)
2024-07-03 16:33:29,467:INFO:tune_model() successfully completed......................................
2024-07-03 16:33:29,529:INFO:Initializing evaluate_model()
2024-07-03 16:33:29,529:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-07-03 16:33:29,538:INFO:Initializing plot_model()
2024-07-03 16:33:29,538:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 16:33:29,538:INFO:Checking exceptions
2024-07-03 16:33:29,567:INFO:Preloading libraries
2024-07-03 16:33:29,577:INFO:Copying training dataset
2024-07-03 16:33:29,577:INFO:Plot type: pipeline
2024-07-03 16:33:29,633:INFO:Visual Rendered Successfully
2024-07-03 16:33:29,694:INFO:plot_model() successfully completed......................................
2024-07-03 16:33:29,700:INFO:Initializing predict_model()
2024-07-03 16:33:29,700:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f790d2abb00>)
2024-07-03 16:33:29,700:INFO:Checking exceptions
2024-07-03 16:33:29,700:INFO:Preloading libraries
2024-07-03 16:33:29,855:INFO:Initializing predict_model()
2024-07-03 16:33:29,855:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f790d2aa7a0>)
2024-07-03 16:33:29,855:INFO:Checking exceptions
2024-07-03 16:33:29,855:INFO:Preloading libraries
2024-07-03 16:33:30,037:INFO:Initializing finalize_model()
2024-07-03 16:33:30,037:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-07-03 16:33:30,037:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 16:33:30,043:INFO:Initializing create_model()
2024-07-03 16:33:30,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 16:33:30,043:INFO:Checking exceptions
2024-07-03 16:33:30,045:INFO:Importing libraries
2024-07-03 16:33:30,045:INFO:Copying training dataset
2024-07-03 16:33:30,046:INFO:Defining folds
2024-07-03 16:33:30,046:INFO:Declaring metric variables
2024-07-03 16:33:30,046:INFO:Importing untrained model
2024-07-03 16:33:30,046:INFO:Declaring custom model
2024-07-03 16:33:30,047:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 16:33:30,047:INFO:Cross validation set to False
2024-07-03 16:33:30,048:INFO:Fitting Model
2024-07-03 16:33:31,504:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-07-03 16:33:31,505:INFO:create_model() successfully completed......................................
2024-07-03 16:33:31,563:INFO:_master_model_container: 20
2024-07-03 16:33:31,563:INFO:_display_container: 8
2024-07-03 16:33:31,566:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-07-03 16:33:31,566:INFO:finalize_model() successfully completed......................................
2024-07-03 16:33:31,632:INFO:Initializing predict_model()
2024-07-03 16:33:31,632:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f790d2aa7a0>)
2024-07-03 16:33:31,632:INFO:Checking exceptions
2024-07-03 16:33:31,632:INFO:Preloading libraries
2024-07-03 16:33:31,816:INFO:Initializing predict_model()
2024-07-03 16:33:31,816:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f790d2abba0>)
2024-07-03 16:33:31,816:INFO:Checking exceptions
2024-07-03 16:33:31,816:INFO:Preloading libraries
2024-07-03 16:33:31,818:INFO:Set up data.
2024-07-03 16:33:31,829:INFO:Set up index.
2024-07-03 16:35:15,804:INFO:Initializing predict_model()
2024-07-03 16:35:15,804:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f78b03304a0>)
2024-07-03 16:35:15,804:INFO:Checking exceptions
2024-07-03 16:35:15,804:INFO:Preloading libraries
2024-07-03 16:35:15,805:INFO:Set up data.
2024-07-03 16:35:15,817:INFO:Set up index.
2024-07-03 16:36:34,929:INFO:Initializing predict_model()
2024-07-03 16:36:34,929:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f78ba4fb3d0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f78b85eb6a0>)
2024-07-03 16:36:34,929:INFO:Checking exceptions
2024-07-03 16:36:34,930:INFO:Preloading libraries
2024-07-03 16:36:34,932:INFO:Set up data.
2024-07-03 16:36:34,943:INFO:Set up index.
2024-07-03 17:00:25,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:25,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:25,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:25,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:25,768:INFO:PyCaret ClassificationExperiment
2024-07-03 17:00:25,768:INFO:Logging name: clf-default-name
2024-07-03 17:00:25,768:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-03 17:00:25,768:INFO:version 3.3.2
2024-07-03 17:00:25,768:INFO:Initializing setup()
2024-07-03 17:00:25,768:INFO:self.USI: b73c
2024-07-03 17:00:25,768:INFO:self._variable_keys: {'exp_name_log', 'fold_groups_param', 'X_test', 'y_test', 'fold_shuffle_param', 'exp_id', 'y', '_available_plots', 'is_multiclass', 'logging_param', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'fold_generator', 'pipeline', 'gpu_param', '_ml_usecase', 'y_train', 'html_param', 'X_train', 'X', 'n_jobs_param', 'fix_imbalance', 'seed', 'USI', 'idx', 'target_param', 'data'}
2024-07-03 17:00:25,768:INFO:Checking environment
2024-07-03 17:00:25,769:INFO:python_version: 3.11.9
2024-07-03 17:00:25,769:INFO:python_build: ('main', 'May 22 2024 17:28:32')
2024-07-03 17:00:25,769:INFO:machine: x86_64
2024-07-03 17:00:25,769:INFO:platform: Linux-6.1.0-22-amd64-x86_64-with-glibc2.36
2024-07-03 17:00:25,769:INFO:Memory: svmem(total=67150065664, available=62564220928, percent=6.8, used=3317653504, free=61116596224, active=805605376, inactive=4062572544, buffers=145698816, cached=2570117120, shared=606076928, slab=228925440)
2024-07-03 17:00:25,769:INFO:Physical Core: 6
2024-07-03 17:00:25,769:INFO:Logical Core: 12
2024-07-03 17:00:25,769:INFO:Checking libraries
2024-07-03 17:00:25,769:INFO:System:
2024-07-03 17:00:25,769:INFO:    python: 3.11.9 (main, May 22 2024, 17:28:32) [GCC 12.2.0]
2024-07-03 17:00:25,769:INFO:executable: /home/yht/.pyenv/versions/3.11.9/envs/kaggle/bin/python
2024-07-03 17:00:25,769:INFO:   machine: Linux-6.1.0-22-amd64-x86_64-with-glibc2.36
2024-07-03 17:00:25,769:INFO:PyCaret required dependencies:
2024-07-03 17:00:25,783:INFO:                 pip: 24.1.1
2024-07-03 17:00:25,783:INFO:          setuptools: 65.5.0
2024-07-03 17:00:25,783:INFO:             pycaret: 3.3.2
2024-07-03 17:00:25,783:INFO:             IPython: 8.26.0
2024-07-03 17:00:25,783:INFO:          ipywidgets: 8.1.3
2024-07-03 17:00:25,783:INFO:                tqdm: 4.66.4
2024-07-03 17:00:25,783:INFO:               numpy: 1.26.4
2024-07-03 17:00:25,783:INFO:              pandas: 2.1.4
2024-07-03 17:00:25,783:INFO:              jinja2: 3.1.4
2024-07-03 17:00:25,783:INFO:               scipy: 1.11.4
2024-07-03 17:00:25,783:INFO:              joblib: 1.3.2
2024-07-03 17:00:25,783:INFO:             sklearn: 1.4.2
2024-07-03 17:00:25,783:INFO:                pyod: 2.0.1
2024-07-03 17:00:25,784:INFO:            imblearn: 0.12.3
2024-07-03 17:00:25,784:INFO:   category_encoders: 2.6.3
2024-07-03 17:00:25,784:INFO:            lightgbm: 4.4.0
2024-07-03 17:00:25,784:INFO:               numba: 0.60.0
2024-07-03 17:00:25,784:INFO:            requests: 2.32.3
2024-07-03 17:00:25,784:INFO:          matplotlib: 3.7.5
2024-07-03 17:00:25,784:INFO:          scikitplot: 0.3.7
2024-07-03 17:00:25,784:INFO:         yellowbrick: 1.5
2024-07-03 17:00:25,784:INFO:              plotly: 5.22.0
2024-07-03 17:00:25,784:INFO:    plotly-resampler: Not installed
2024-07-03 17:00:25,784:INFO:             kaleido: 0.2.1
2024-07-03 17:00:25,784:INFO:           schemdraw: 0.15
2024-07-03 17:00:25,784:INFO:         statsmodels: 0.14.2
2024-07-03 17:00:25,784:INFO:              sktime: 0.26.0
2024-07-03 17:00:25,784:INFO:               tbats: 1.1.3
2024-07-03 17:00:25,784:INFO:            pmdarima: 2.0.4
2024-07-03 17:00:25,784:INFO:              psutil: 6.0.0
2024-07-03 17:00:25,784:INFO:          markupsafe: 2.1.5
2024-07-03 17:00:25,784:INFO:             pickle5: Not installed
2024-07-03 17:00:25,784:INFO:         cloudpickle: 3.0.0
2024-07-03 17:00:25,784:INFO:         deprecation: 2.1.0
2024-07-03 17:00:25,784:INFO:              xxhash: 3.4.1
2024-07-03 17:00:25,784:INFO:           wurlitzer: 3.1.1
2024-07-03 17:00:25,784:INFO:PyCaret optional dependencies:
2024-07-03 17:00:25,794:INFO:                shap: Not installed
2024-07-03 17:00:25,794:INFO:           interpret: Not installed
2024-07-03 17:00:25,794:INFO:                umap: Not installed
2024-07-03 17:00:25,794:INFO:     ydata_profiling: Not installed
2024-07-03 17:00:25,794:INFO:  explainerdashboard: Not installed
2024-07-03 17:00:25,794:INFO:             autoviz: Not installed
2024-07-03 17:00:25,794:INFO:           fairlearn: Not installed
2024-07-03 17:00:25,794:INFO:          deepchecks: Not installed
2024-07-03 17:00:25,795:INFO:             xgboost: Not installed
2024-07-03 17:00:25,795:INFO:            catboost: Not installed
2024-07-03 17:00:25,795:INFO:              kmodes: Not installed
2024-07-03 17:00:25,795:INFO:             mlxtend: Not installed
2024-07-03 17:00:25,795:INFO:       statsforecast: Not installed
2024-07-03 17:00:25,795:INFO:        tune_sklearn: Not installed
2024-07-03 17:00:25,795:INFO:                 ray: Not installed
2024-07-03 17:00:25,795:INFO:            hyperopt: Not installed
2024-07-03 17:00:25,795:INFO:              optuna: Not installed
2024-07-03 17:00:25,795:INFO:               skopt: Not installed
2024-07-03 17:00:25,795:INFO:              mlflow: Not installed
2024-07-03 17:00:25,795:INFO:              gradio: Not installed
2024-07-03 17:00:25,795:INFO:             fastapi: Not installed
2024-07-03 17:00:25,795:INFO:             uvicorn: Not installed
2024-07-03 17:00:25,795:INFO:              m2cgen: Not installed
2024-07-03 17:00:25,795:INFO:           evidently: Not installed
2024-07-03 17:00:25,795:INFO:               fugue: Not installed
2024-07-03 17:00:25,795:INFO:           streamlit: Not installed
2024-07-03 17:00:25,795:INFO:             prophet: Not installed
2024-07-03 17:00:25,795:INFO:None
2024-07-03 17:00:25,795:INFO:Set up GPU usage.
2024-07-03 17:00:25,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:25,795:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-07-03 17:00:25,795:INFO:Set up data.
2024-07-03 17:00:25,799:INFO:Set up folding strategy.
2024-07-03 17:00:25,799:INFO:Set up train/test split.
2024-07-03 17:00:25,804:INFO:Set up index.
2024-07-03 17:00:25,804:INFO:Assigning column types.
2024-07-03 17:00:25,808:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-03 17:00:25,808:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:25,840:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-03 17:00:25,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:25,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:25,842:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 17:00:25,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:25,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:25,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:25,864:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 17:00:25,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 17:00:25,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:25,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-03 17:00:25,991:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:25,991:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:25,991:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 17:00:25,991:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,007:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 17:00:26,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 17:00:26,080:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-03 17:00:26,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,113:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,113:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,114:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 17:00:26,114:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,133:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,134:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 17:00:26,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 17:00:26,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,225:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,225:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,226:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-03 17:00:26,226:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,242:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 17:00:26,303:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 17:00:26,304:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-03 17:00:26,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,337:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,337:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,337:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,357:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 17:00:26,422:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 17:00:26,422:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,456:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,475:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 17:00:26,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 17:00:26,534:INFO:Preparing preprocessing pipeline...
2024-07-03 17:00:26,535:INFO:Set up simple imputation.
2024-07-03 17:00:26,552:INFO:Finished creating preprocessing pipeline.
2024-07-03 17:00:26,555:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-07-03 17:00:26,555:INFO:Creating final display dataframe.
2024-07-03 17:00:26,613:INFO:Setup _display_container:                     Description             Value
0                    Session id              8888
1                        Target       Transported
2                   Target type            Binary
3           Original data shape        (8693, 11)
4        Transformed data shape        (8693, 11)
5   Transformed train set shape        (6085, 11)
6    Transformed test set shape        (2608, 11)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              b73c
2024-07-03 17:00:26,617:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,650:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,650:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,650:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,670:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,671:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 17:00:26,729:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 17:00:26,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,762:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,762:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,763:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,779:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,783:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-03 17:00:26,783:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 17:00:26,841:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-03 17:00:26,842:INFO:setup() successfully completed in 1.07s...............
2024-07-03 17:00:26,846:INFO:Initializing compare_models()
2024-07-03 17:00:26,847:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-03 17:00:26,847:INFO:Checking exceptions
2024-07-03 17:00:26,852:INFO:Preparing display monitor
2024-07-03 17:00:26,871:INFO:Initializing Logistic Regression
2024-07-03 17:00:26,871:INFO:Total runtime is 2.3802121480305988e-06 minutes
2024-07-03 17:00:26,874:INFO:SubProcess create_model() called ==================================
2024-07-03 17:00:26,875:INFO:Initializing create_model()
2024-07-03 17:00:26,875:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b9515f090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:00:26,875:INFO:Checking exceptions
2024-07-03 17:00:26,875:INFO:Importing libraries
2024-07-03 17:00:26,875:INFO:Copying training dataset
2024-07-03 17:00:26,880:INFO:Defining folds
2024-07-03 17:00:26,880:INFO:Declaring metric variables
2024-07-03 17:00:26,882:INFO:Importing untrained model
2024-07-03 17:00:26,885:INFO:Logistic Regression Imported successfully
2024-07-03 17:00:26,889:INFO:Starting cross validation
2024-07-03 17:00:26,890:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:00:28,725:INFO:Calculating mean and std
2024-07-03 17:00:28,727:INFO:Creating metrics dataframe
2024-07-03 17:00:28,729:INFO:Uploading results into container
2024-07-03 17:00:28,729:INFO:Uploading model into container now
2024-07-03 17:00:28,730:INFO:_master_model_container: 1
2024-07-03 17:00:28,730:INFO:_display_container: 2
2024-07-03 17:00:28,730:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8888, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-03 17:00:28,730:INFO:create_model() successfully completed......................................
2024-07-03 17:00:28,801:INFO:SubProcess create_model() end ==================================
2024-07-03 17:00:28,801:INFO:Creating metrics dataframe
2024-07-03 17:00:28,808:INFO:Initializing K Neighbors Classifier
2024-07-03 17:00:28,808:INFO:Total runtime is 0.03227402766545614 minutes
2024-07-03 17:00:28,810:INFO:SubProcess create_model() called ==================================
2024-07-03 17:00:28,810:INFO:Initializing create_model()
2024-07-03 17:00:28,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b9515f090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:00:28,810:INFO:Checking exceptions
2024-07-03 17:00:28,810:INFO:Importing libraries
2024-07-03 17:00:28,810:INFO:Copying training dataset
2024-07-03 17:00:28,814:INFO:Defining folds
2024-07-03 17:00:28,814:INFO:Declaring metric variables
2024-07-03 17:00:28,816:INFO:Importing untrained model
2024-07-03 17:00:28,819:INFO:K Neighbors Classifier Imported successfully
2024-07-03 17:00:28,823:INFO:Starting cross validation
2024-07-03 17:00:28,823:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:00:29,978:INFO:Calculating mean and std
2024-07-03 17:00:29,978:INFO:Creating metrics dataframe
2024-07-03 17:00:29,980:INFO:Uploading results into container
2024-07-03 17:00:29,980:INFO:Uploading model into container now
2024-07-03 17:00:29,980:INFO:_master_model_container: 2
2024-07-03 17:00:29,980:INFO:_display_container: 2
2024-07-03 17:00:29,981:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-03 17:00:29,981:INFO:create_model() successfully completed......................................
2024-07-03 17:00:30,039:INFO:SubProcess create_model() end ==================================
2024-07-03 17:00:30,039:INFO:Creating metrics dataframe
2024-07-03 17:00:30,044:INFO:Initializing Naive Bayes
2024-07-03 17:00:30,044:INFO:Total runtime is 0.052880986531575525 minutes
2024-07-03 17:00:30,046:INFO:SubProcess create_model() called ==================================
2024-07-03 17:00:30,046:INFO:Initializing create_model()
2024-07-03 17:00:30,046:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b9515f090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:00:30,046:INFO:Checking exceptions
2024-07-03 17:00:30,046:INFO:Importing libraries
2024-07-03 17:00:30,047:INFO:Copying training dataset
2024-07-03 17:00:30,051:INFO:Defining folds
2024-07-03 17:00:30,051:INFO:Declaring metric variables
2024-07-03 17:00:30,053:INFO:Importing untrained model
2024-07-03 17:00:30,055:INFO:Naive Bayes Imported successfully
2024-07-03 17:00:30,059:INFO:Starting cross validation
2024-07-03 17:00:30,060:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:00:30,288:INFO:Calculating mean and std
2024-07-03 17:00:30,289:INFO:Creating metrics dataframe
2024-07-03 17:00:30,290:INFO:Uploading results into container
2024-07-03 17:00:30,290:INFO:Uploading model into container now
2024-07-03 17:00:30,291:INFO:_master_model_container: 3
2024-07-03 17:00:30,291:INFO:_display_container: 2
2024-07-03 17:00:30,291:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-03 17:00:30,291:INFO:create_model() successfully completed......................................
2024-07-03 17:00:30,350:INFO:SubProcess create_model() end ==================================
2024-07-03 17:00:30,350:INFO:Creating metrics dataframe
2024-07-03 17:00:30,355:INFO:Initializing Decision Tree Classifier
2024-07-03 17:00:30,356:INFO:Total runtime is 0.05807354052861532 minutes
2024-07-03 17:00:30,358:INFO:SubProcess create_model() called ==================================
2024-07-03 17:00:30,358:INFO:Initializing create_model()
2024-07-03 17:00:30,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b9515f090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:00:30,359:INFO:Checking exceptions
2024-07-03 17:00:30,359:INFO:Importing libraries
2024-07-03 17:00:30,359:INFO:Copying training dataset
2024-07-03 17:00:30,363:INFO:Defining folds
2024-07-03 17:00:30,363:INFO:Declaring metric variables
2024-07-03 17:00:30,365:INFO:Importing untrained model
2024-07-03 17:00:30,368:INFO:Decision Tree Classifier Imported successfully
2024-07-03 17:00:30,373:INFO:Starting cross validation
2024-07-03 17:00:30,374:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:00:30,726:INFO:Calculating mean and std
2024-07-03 17:00:30,727:INFO:Creating metrics dataframe
2024-07-03 17:00:30,729:INFO:Uploading results into container
2024-07-03 17:00:30,730:INFO:Uploading model into container now
2024-07-03 17:00:30,730:INFO:_master_model_container: 4
2024-07-03 17:00:30,730:INFO:_display_container: 2
2024-07-03 17:00:30,731:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8888, splitter='best')
2024-07-03 17:00:30,731:INFO:create_model() successfully completed......................................
2024-07-03 17:00:30,787:INFO:SubProcess create_model() end ==================================
2024-07-03 17:00:30,787:INFO:Creating metrics dataframe
2024-07-03 17:00:30,792:INFO:Initializing SVM - Linear Kernel
2024-07-03 17:00:30,792:INFO:Total runtime is 0.06535356442133586 minutes
2024-07-03 17:00:30,795:INFO:SubProcess create_model() called ==================================
2024-07-03 17:00:30,795:INFO:Initializing create_model()
2024-07-03 17:00:30,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b9515f090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:00:30,795:INFO:Checking exceptions
2024-07-03 17:00:30,795:INFO:Importing libraries
2024-07-03 17:00:30,795:INFO:Copying training dataset
2024-07-03 17:00:30,800:INFO:Defining folds
2024-07-03 17:00:30,800:INFO:Declaring metric variables
2024-07-03 17:00:30,802:INFO:Importing untrained model
2024-07-03 17:00:30,805:INFO:SVM - Linear Kernel Imported successfully
2024-07-03 17:00:30,809:INFO:Starting cross validation
2024-07-03 17:00:30,810:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:00:31,150:INFO:Calculating mean and std
2024-07-03 17:00:31,150:INFO:Creating metrics dataframe
2024-07-03 17:00:31,152:INFO:Uploading results into container
2024-07-03 17:00:31,152:INFO:Uploading model into container now
2024-07-03 17:00:31,152:INFO:_master_model_container: 5
2024-07-03 17:00:31,152:INFO:_display_container: 2
2024-07-03 17:00:31,152:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8888, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-03 17:00:31,153:INFO:create_model() successfully completed......................................
2024-07-03 17:00:31,209:INFO:SubProcess create_model() end ==================================
2024-07-03 17:00:31,209:INFO:Creating metrics dataframe
2024-07-03 17:00:31,215:INFO:Initializing Ridge Classifier
2024-07-03 17:00:31,215:INFO:Total runtime is 0.07239477634429932 minutes
2024-07-03 17:00:31,217:INFO:SubProcess create_model() called ==================================
2024-07-03 17:00:31,217:INFO:Initializing create_model()
2024-07-03 17:00:31,217:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b9515f090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:00:31,217:INFO:Checking exceptions
2024-07-03 17:00:31,217:INFO:Importing libraries
2024-07-03 17:00:31,217:INFO:Copying training dataset
2024-07-03 17:00:31,222:INFO:Defining folds
2024-07-03 17:00:31,222:INFO:Declaring metric variables
2024-07-03 17:00:31,224:INFO:Importing untrained model
2024-07-03 17:00:31,226:INFO:Ridge Classifier Imported successfully
2024-07-03 17:00:31,231:INFO:Starting cross validation
2024-07-03 17:00:31,231:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:00:31,244:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.37152e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 17:00:31,278:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.52883e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 17:00:31,312:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.31264e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 17:00:31,340:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.5489e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 17:00:31,364:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.57491e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 17:00:31,387:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.40388e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 17:00:31,409:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.48847e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 17:00:31,432:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.59372e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 17:00:31,455:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.87456e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 17:00:31,478:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=5.36341e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-07-03 17:00:31,493:INFO:Calculating mean and std
2024-07-03 17:00:31,493:INFO:Creating metrics dataframe
2024-07-03 17:00:31,495:INFO:Uploading results into container
2024-07-03 17:00:31,495:INFO:Uploading model into container now
2024-07-03 17:00:31,495:INFO:_master_model_container: 6
2024-07-03 17:00:31,496:INFO:_display_container: 2
2024-07-03 17:00:31,496:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8888, solver='auto',
                tol=0.0001)
2024-07-03 17:00:31,496:INFO:create_model() successfully completed......................................
2024-07-03 17:00:31,554:INFO:SubProcess create_model() end ==================================
2024-07-03 17:00:31,555:INFO:Creating metrics dataframe
2024-07-03 17:00:31,560:INFO:Initializing Random Forest Classifier
2024-07-03 17:00:31,560:INFO:Total runtime is 0.0781524658203125 minutes
2024-07-03 17:00:31,563:INFO:SubProcess create_model() called ==================================
2024-07-03 17:00:31,563:INFO:Initializing create_model()
2024-07-03 17:00:31,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b9515f090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:00:31,563:INFO:Checking exceptions
2024-07-03 17:00:31,563:INFO:Importing libraries
2024-07-03 17:00:31,563:INFO:Copying training dataset
2024-07-03 17:00:31,568:INFO:Defining folds
2024-07-03 17:00:31,568:INFO:Declaring metric variables
2024-07-03 17:00:31,570:INFO:Importing untrained model
2024-07-03 17:00:31,572:INFO:Random Forest Classifier Imported successfully
2024-07-03 17:00:31,577:INFO:Starting cross validation
2024-07-03 17:00:31,578:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:00:34,062:INFO:Calculating mean and std
2024-07-03 17:00:34,063:INFO:Creating metrics dataframe
2024-07-03 17:00:34,064:INFO:Uploading results into container
2024-07-03 17:00:34,065:INFO:Uploading model into container now
2024-07-03 17:00:34,065:INFO:_master_model_container: 7
2024-07-03 17:00:34,065:INFO:_display_container: 2
2024-07-03 17:00:34,065:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 17:00:34,065:INFO:create_model() successfully completed......................................
2024-07-03 17:00:34,124:INFO:SubProcess create_model() end ==================================
2024-07-03 17:00:34,124:INFO:Creating metrics dataframe
2024-07-03 17:00:34,130:INFO:Initializing Quadratic Discriminant Analysis
2024-07-03 17:00:34,130:INFO:Total runtime is 0.12098847627639771 minutes
2024-07-03 17:00:34,133:INFO:SubProcess create_model() called ==================================
2024-07-03 17:00:34,133:INFO:Initializing create_model()
2024-07-03 17:00:34,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b9515f090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:00:34,133:INFO:Checking exceptions
2024-07-03 17:00:34,133:INFO:Importing libraries
2024-07-03 17:00:34,133:INFO:Copying training dataset
2024-07-03 17:00:34,138:INFO:Defining folds
2024-07-03 17:00:34,138:INFO:Declaring metric variables
2024-07-03 17:00:34,140:INFO:Importing untrained model
2024-07-03 17:00:34,142:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-03 17:00:34,147:INFO:Starting cross validation
2024-07-03 17:00:34,147:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:00:34,159:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 17:00:34,194:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 17:00:34,229:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 17:00:34,264:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 17:00:34,281:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 17:00:34,300:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 17:00:34,335:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 17:00:34,351:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 17:00:34,370:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 17:00:34,405:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 17:00:34,441:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 17:00:34,458:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-03 17:00:34,477:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-03 17:00:34,501:INFO:Calculating mean and std
2024-07-03 17:00:34,502:INFO:Creating metrics dataframe
2024-07-03 17:00:34,504:INFO:Uploading results into container
2024-07-03 17:00:34,504:INFO:Uploading model into container now
2024-07-03 17:00:34,505:INFO:_master_model_container: 8
2024-07-03 17:00:34,505:INFO:_display_container: 2
2024-07-03 17:00:34,505:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-03 17:00:34,505:INFO:create_model() successfully completed......................................
2024-07-03 17:00:34,576:INFO:SubProcess create_model() end ==================================
2024-07-03 17:00:34,576:INFO:Creating metrics dataframe
2024-07-03 17:00:34,584:INFO:Initializing Ada Boost Classifier
2024-07-03 17:00:34,584:INFO:Total runtime is 0.12855210304260253 minutes
2024-07-03 17:00:34,586:INFO:SubProcess create_model() called ==================================
2024-07-03 17:00:34,587:INFO:Initializing create_model()
2024-07-03 17:00:34,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b9515f090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:00:34,587:INFO:Checking exceptions
2024-07-03 17:00:34,587:INFO:Importing libraries
2024-07-03 17:00:34,587:INFO:Copying training dataset
2024-07-03 17:00:34,591:INFO:Defining folds
2024-07-03 17:00:34,591:INFO:Declaring metric variables
2024-07-03 17:00:34,593:INFO:Importing untrained model
2024-07-03 17:00:34,595:INFO:Ada Boost Classifier Imported successfully
2024-07-03 17:00:34,600:INFO:Starting cross validation
2024-07-03 17:00:34,600:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:00:34,611:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 17:00:34,772:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 17:00:34,931:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 17:00:35,089:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 17:00:35,248:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 17:00:35,405:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 17:00:35,562:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 17:00:35,721:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 17:00:35,883:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 17:00:36,042:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-03 17:00:36,197:INFO:Calculating mean and std
2024-07-03 17:00:36,198:INFO:Creating metrics dataframe
2024-07-03 17:00:36,199:INFO:Uploading results into container
2024-07-03 17:00:36,199:INFO:Uploading model into container now
2024-07-03 17:00:36,199:INFO:_master_model_container: 9
2024-07-03 17:00:36,200:INFO:_display_container: 2
2024-07-03 17:00:36,200:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8888)
2024-07-03 17:00:36,200:INFO:create_model() successfully completed......................................
2024-07-03 17:00:36,259:INFO:SubProcess create_model() end ==================================
2024-07-03 17:00:36,259:INFO:Creating metrics dataframe
2024-07-03 17:00:36,265:INFO:Initializing Gradient Boosting Classifier
2024-07-03 17:00:36,265:INFO:Total runtime is 0.15657146374384562 minutes
2024-07-03 17:00:36,268:INFO:SubProcess create_model() called ==================================
2024-07-03 17:00:36,268:INFO:Initializing create_model()
2024-07-03 17:00:36,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b9515f090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:00:36,268:INFO:Checking exceptions
2024-07-03 17:00:36,268:INFO:Importing libraries
2024-07-03 17:00:36,268:INFO:Copying training dataset
2024-07-03 17:00:36,272:INFO:Defining folds
2024-07-03 17:00:36,272:INFO:Declaring metric variables
2024-07-03 17:00:36,274:INFO:Importing untrained model
2024-07-03 17:00:36,277:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 17:00:36,281:INFO:Starting cross validation
2024-07-03 17:00:36,282:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:00:40,520:INFO:Calculating mean and std
2024-07-03 17:00:40,520:INFO:Creating metrics dataframe
2024-07-03 17:00:40,522:INFO:Uploading results into container
2024-07-03 17:00:40,522:INFO:Uploading model into container now
2024-07-03 17:00:40,522:INFO:_master_model_container: 10
2024-07-03 17:00:40,522:INFO:_display_container: 2
2024-07-03 17:00:40,523:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 17:00:40,523:INFO:create_model() successfully completed......................................
2024-07-03 17:00:40,579:INFO:SubProcess create_model() end ==================================
2024-07-03 17:00:40,579:INFO:Creating metrics dataframe
2024-07-03 17:00:40,586:INFO:Initializing Linear Discriminant Analysis
2024-07-03 17:00:40,586:INFO:Total runtime is 0.22858173449834188 minutes
2024-07-03 17:00:40,588:INFO:SubProcess create_model() called ==================================
2024-07-03 17:00:40,588:INFO:Initializing create_model()
2024-07-03 17:00:40,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b9515f090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:00:40,589:INFO:Checking exceptions
2024-07-03 17:00:40,589:INFO:Importing libraries
2024-07-03 17:00:40,589:INFO:Copying training dataset
2024-07-03 17:00:40,593:INFO:Defining folds
2024-07-03 17:00:40,593:INFO:Declaring metric variables
2024-07-03 17:00:40,595:INFO:Importing untrained model
2024-07-03 17:00:40,598:INFO:Linear Discriminant Analysis Imported successfully
2024-07-03 17:00:40,602:INFO:Starting cross validation
2024-07-03 17:00:40,603:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:00:40,968:INFO:Calculating mean and std
2024-07-03 17:00:40,970:INFO:Creating metrics dataframe
2024-07-03 17:00:40,972:INFO:Uploading results into container
2024-07-03 17:00:40,972:INFO:Uploading model into container now
2024-07-03 17:00:40,972:INFO:_master_model_container: 11
2024-07-03 17:00:40,972:INFO:_display_container: 2
2024-07-03 17:00:40,973:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-03 17:00:40,973:INFO:create_model() successfully completed......................................
2024-07-03 17:00:41,045:INFO:SubProcess create_model() end ==================================
2024-07-03 17:00:41,046:INFO:Creating metrics dataframe
2024-07-03 17:00:41,053:INFO:Initializing Extra Trees Classifier
2024-07-03 17:00:41,054:INFO:Total runtime is 0.23637301524480184 minutes
2024-07-03 17:00:41,056:INFO:SubProcess create_model() called ==================================
2024-07-03 17:00:41,056:INFO:Initializing create_model()
2024-07-03 17:00:41,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b9515f090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:00:41,056:INFO:Checking exceptions
2024-07-03 17:00:41,056:INFO:Importing libraries
2024-07-03 17:00:41,056:INFO:Copying training dataset
2024-07-03 17:00:41,060:INFO:Defining folds
2024-07-03 17:00:41,060:INFO:Declaring metric variables
2024-07-03 17:00:41,062:INFO:Importing untrained model
2024-07-03 17:00:41,065:INFO:Extra Trees Classifier Imported successfully
2024-07-03 17:00:41,069:INFO:Starting cross validation
2024-07-03 17:00:41,069:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:00:43,095:INFO:Calculating mean and std
2024-07-03 17:00:43,096:INFO:Creating metrics dataframe
2024-07-03 17:00:43,097:INFO:Uploading results into container
2024-07-03 17:00:43,098:INFO:Uploading model into container now
2024-07-03 17:00:43,098:INFO:_master_model_container: 12
2024-07-03 17:00:43,098:INFO:_display_container: 2
2024-07-03 17:00:43,098:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8888, verbose=0,
                     warm_start=False)
2024-07-03 17:00:43,098:INFO:create_model() successfully completed......................................
2024-07-03 17:00:43,157:INFO:SubProcess create_model() end ==================================
2024-07-03 17:00:43,157:INFO:Creating metrics dataframe
2024-07-03 17:00:43,165:INFO:Initializing Light Gradient Boosting Machine
2024-07-03 17:00:43,165:INFO:Total runtime is 0.27156157890955607 minutes
2024-07-03 17:00:43,167:INFO:SubProcess create_model() called ==================================
2024-07-03 17:00:43,167:INFO:Initializing create_model()
2024-07-03 17:00:43,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b9515f090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:00:43,167:INFO:Checking exceptions
2024-07-03 17:00:43,167:INFO:Importing libraries
2024-07-03 17:00:43,168:INFO:Copying training dataset
2024-07-03 17:00:43,172:INFO:Defining folds
2024-07-03 17:00:43,172:INFO:Declaring metric variables
2024-07-03 17:00:43,174:INFO:Importing untrained model
2024-07-03 17:00:43,177:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-03 17:00:43,181:INFO:Starting cross validation
2024-07-03 17:00:43,182:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:00:43,198:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 17:00:43,198:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 17:00:43,199:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 17:00:43,199:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 17:00:43,246:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 17:00:43,246:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 17:00:43,251:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 17:00:43,252:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 17:00:43,253:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000229 secs. 1 sparse feature groups
2024-07-03 17:00:43,253:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 17:00:43,253:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 17:00:43,462:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 17:00:43,462:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 17:00:43,462:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 17:00:43,463:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 17:00:43,501:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 17:00:43,501:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 17:00:43,506:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 17:00:43,507:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 17:00:43,507:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000246 secs. 1 sparse feature groups
2024-07-03 17:00:43,507:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 17:00:43,507:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 17:00:43,716:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 17:00:43,716:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 17:00:43,716:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-03 17:00:43,716:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 17:00:43,755:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 17:00:43,755:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 17:00:43,760:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 17:00:43,761:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 17:00:43,761:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000222 secs. 1 sparse feature groups
2024-07-03 17:00:43,761:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 17:00:43,761:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 17:00:43,970:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 17:00:43,970:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 17:00:43,970:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 17:00:43,970:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 17:00:44,009:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 17:00:44,009:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 17:00:44,016:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 17:00:44,017:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 17:00:44,028:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.010312 secs. 1 sparse feature groups
2024-07-03 17:00:44,028:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 17:00:44,028:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 17:00:44,236:INFO:[LightGBM] [Info] Number of positive: 2758, number of negative: 2718
2024-07-03 17:00:44,236:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 17:00:44,237:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-03 17:00:44,237:INFO:[LightGBM] [Info] Number of data points in the train set: 5476, number of used features: 10
2024-07-03 17:00:44,272:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 17:00:44,272:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 17:00:44,278:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 17:00:44,279:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 17:00:44,279:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000223 secs. 1 sparse feature groups
2024-07-03 17:00:44,279:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503652 -> initscore=0.014609
2024-07-03 17:00:44,279:INFO:[LightGBM] [Info] Start training from score 0.014609
2024-07-03 17:00:44,487:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 17:00:44,487:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 17:00:44,487:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-03 17:00:44,487:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 17:00:44,525:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 17:00:44,525:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 17:00:44,530:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 17:00:44,531:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 17:00:44,531:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000224 secs. 1 sparse feature groups
2024-07-03 17:00:44,532:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 17:00:44,532:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 17:00:44,743:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 17:00:44,743:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 17:00:44,743:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 17:00:44,743:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 17:00:44,783:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 17:00:44,783:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 17:00:44,788:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 17:00:44,789:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 17:00:44,790:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000227 secs. 1 sparse feature groups
2024-07-03 17:00:44,790:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 17:00:44,790:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 17:00:44,998:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 17:00:44,998:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 17:00:44,998:INFO:[LightGBM] [Info] Total Bins 1360
2024-07-03 17:00:44,998:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 17:00:45,037:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 17:00:45,037:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 17:00:45,042:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 17:00:45,043:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 17:00:45,043:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000224 secs. 1 sparse feature groups
2024-07-03 17:00:45,044:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 17:00:45,044:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 17:00:45,253:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 17:00:45,254:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 17:00:45,254:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 17:00:45,254:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 17:00:45,294:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 17:00:45,294:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 17:00:45,299:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 17:00:45,300:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 17:00:45,301:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000246 secs. 1 sparse feature groups
2024-07-03 17:00:45,301:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 17:00:45,301:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 17:00:45,510:INFO:[LightGBM] [Info] Number of positive: 2759, number of negative: 2718
2024-07-03 17:00:45,510:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-07-03 17:00:45,510:INFO:[LightGBM] [Info] Total Bins 1361
2024-07-03 17:00:45,510:INFO:[LightGBM] [Info] Number of data points in the train set: 5477, number of used features: 10
2024-07-03 17:00:45,549:INFO:[LightGBM] [Info] Using GPU Device: Quadro T1000, Vendor: NVIDIA Corporation
2024-07-03 17:00:45,549:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-07-03 17:00:45,554:INFO:[LightGBM] [Info] GPU programs have been built
2024-07-03 17:00:45,555:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-07-03 17:00:45,555:INFO:[LightGBM] [Info] 2 dense feature groups (0.02 MB) transferred to GPU in 0.000243 secs. 1 sparse feature groups
2024-07-03 17:00:45,556:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503743 -> initscore=0.014972
2024-07-03 17:00:45,556:INFO:[LightGBM] [Info] Start training from score 0.014972
2024-07-03 17:00:45,758:INFO:Calculating mean and std
2024-07-03 17:00:45,759:INFO:Creating metrics dataframe
2024-07-03 17:00:45,760:INFO:Uploading results into container
2024-07-03 17:00:45,760:INFO:Uploading model into container now
2024-07-03 17:00:45,761:INFO:_master_model_container: 13
2024-07-03 17:00:45,761:INFO:_display_container: 2
2024-07-03 17:00:45,761:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=8888, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-07-03 17:00:45,761:INFO:create_model() successfully completed......................................
2024-07-03 17:00:45,818:INFO:SubProcess create_model() end ==================================
2024-07-03 17:00:45,818:INFO:Creating metrics dataframe
2024-07-03 17:00:45,825:INFO:Initializing Dummy Classifier
2024-07-03 17:00:45,825:INFO:Total runtime is 0.3159030715624491 minutes
2024-07-03 17:00:45,827:INFO:SubProcess create_model() called ==================================
2024-07-03 17:00:45,828:INFO:Initializing create_model()
2024-07-03 17:00:45,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b9515f090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:00:45,828:INFO:Checking exceptions
2024-07-03 17:00:45,828:INFO:Importing libraries
2024-07-03 17:00:45,828:INFO:Copying training dataset
2024-07-03 17:00:45,833:INFO:Defining folds
2024-07-03 17:00:45,833:INFO:Declaring metric variables
2024-07-03 17:00:45,835:INFO:Importing untrained model
2024-07-03 17:00:45,837:INFO:Dummy Classifier Imported successfully
2024-07-03 17:00:45,841:INFO:Starting cross validation
2024-07-03 17:00:45,842:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:00:46,045:INFO:Calculating mean and std
2024-07-03 17:00:46,046:INFO:Creating metrics dataframe
2024-07-03 17:00:46,047:INFO:Uploading results into container
2024-07-03 17:00:46,047:INFO:Uploading model into container now
2024-07-03 17:00:46,048:INFO:_master_model_container: 14
2024-07-03 17:00:46,048:INFO:_display_container: 2
2024-07-03 17:00:46,048:INFO:DummyClassifier(constant=None, random_state=8888, strategy='prior')
2024-07-03 17:00:46,048:INFO:create_model() successfully completed......................................
2024-07-03 17:00:46,105:INFO:SubProcess create_model() end ==================================
2024-07-03 17:00:46,105:INFO:Creating metrics dataframe
2024-07-03 17:00:46,113:WARNING:/home/yht/.pyenv/versions/3.11.9/envs/kaggle/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-03 17:00:46,118:INFO:Initializing create_model()
2024-07-03 17:00:46,119:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:00:46,119:INFO:Checking exceptions
2024-07-03 17:00:46,120:INFO:Importing libraries
2024-07-03 17:00:46,120:INFO:Copying training dataset
2024-07-03 17:00:46,124:INFO:Defining folds
2024-07-03 17:00:46,124:INFO:Declaring metric variables
2024-07-03 17:00:46,124:INFO:Importing untrained model
2024-07-03 17:00:46,124:INFO:Declaring custom model
2024-07-03 17:00:46,125:INFO:Random Forest Classifier Imported successfully
2024-07-03 17:00:46,125:INFO:Cross validation set to False
2024-07-03 17:00:46,125:INFO:Fitting Model
2024-07-03 17:00:46,300:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 17:00:46,301:INFO:create_model() successfully completed......................................
2024-07-03 17:00:46,377:INFO:_master_model_container: 14
2024-07-03 17:00:46,377:INFO:_display_container: 2
2024-07-03 17:00:46,377:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 17:00:46,377:INFO:compare_models() successfully completed......................................
2024-07-03 17:00:46,384:INFO:Initializing create_model()
2024-07-03 17:00:46,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=gbc, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:00:46,385:INFO:Checking exceptions
2024-07-03 17:00:46,395:INFO:Importing libraries
2024-07-03 17:00:46,396:INFO:Copying training dataset
2024-07-03 17:00:46,405:INFO:Defining folds
2024-07-03 17:00:46,405:INFO:Declaring metric variables
2024-07-03 17:00:46,408:INFO:Importing untrained model
2024-07-03 17:00:46,412:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 17:00:46,416:INFO:Starting cross validation
2024-07-03 17:00:46,417:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:00:48,359:INFO:Calculating mean and std
2024-07-03 17:00:48,359:INFO:Creating metrics dataframe
2024-07-03 17:00:48,363:INFO:Finalizing model
2024-07-03 17:00:48,810:INFO:Uploading results into container
2024-07-03 17:00:48,811:INFO:Uploading model into container now
2024-07-03 17:00:48,817:INFO:_master_model_container: 15
2024-07-03 17:00:48,817:INFO:_display_container: 3
2024-07-03 17:00:48,817:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 17:00:48,817:INFO:create_model() successfully completed......................................
2024-07-03 17:00:48,878:INFO:Initializing tune_model()
2024-07-03 17:00:48,878:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-03 17:00:48,879:INFO:Checking exceptions
2024-07-03 17:00:48,893:INFO:Copying training dataset
2024-07-03 17:00:48,896:INFO:Checking base model
2024-07-03 17:00:48,897:INFO:Base model : Gradient Boosting Classifier
2024-07-03 17:00:48,899:INFO:Declaring metric variables
2024-07-03 17:00:48,901:INFO:Defining Hyperparameters
2024-07-03 17:00:48,965:INFO:Tuning with n_jobs=-1
2024-07-03 17:00:48,965:INFO:Initializing RandomizedSearchCV
2024-07-03 17:01:09,977:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.2, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.001}
2024-07-03 17:01:09,978:INFO:Hyperparameter search completed
2024-07-03 17:01:09,978:INFO:SubProcess create_model() called ==================================
2024-07-03 17:01:09,978:INFO:Initializing create_model()
2024-07-03 17:01:09,978:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9beaf25290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'n_estimators': 160, 'min_samples_split': 7, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.2, 'max_features': 'log2', 'max_depth': 9, 'learning_rate': 0.001})
2024-07-03 17:01:09,978:INFO:Checking exceptions
2024-07-03 17:01:09,978:INFO:Importing libraries
2024-07-03 17:01:09,979:INFO:Copying training dataset
2024-07-03 17:01:09,984:INFO:Defining folds
2024-07-03 17:01:09,984:INFO:Declaring metric variables
2024-07-03 17:01:09,987:INFO:Importing untrained model
2024-07-03 17:01:09,987:INFO:Declaring custom model
2024-07-03 17:01:09,989:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 17:01:09,994:INFO:Starting cross validation
2024-07-03 17:01:09,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:01:21,187:INFO:Calculating mean and std
2024-07-03 17:01:21,188:INFO:Creating metrics dataframe
2024-07-03 17:01:21,191:INFO:Finalizing model
2024-07-03 17:01:22,351:INFO:Uploading results into container
2024-07-03 17:01:22,351:INFO:Uploading model into container now
2024-07-03 17:01:22,352:INFO:_master_model_container: 16
2024-07-03 17:01:22,352:INFO:_display_container: 4
2024-07-03 17:01:22,352:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 17:01:22,352:INFO:create_model() successfully completed......................................
2024-07-03 17:01:22,418:INFO:SubProcess create_model() end ==================================
2024-07-03 17:01:22,418:INFO:choose_better activated
2024-07-03 17:01:22,421:INFO:SubProcess create_model() called ==================================
2024-07-03 17:01:22,421:INFO:Initializing create_model()
2024-07-03 17:01:22,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:01:22,421:INFO:Checking exceptions
2024-07-03 17:01:22,422:INFO:Importing libraries
2024-07-03 17:01:22,422:INFO:Copying training dataset
2024-07-03 17:01:22,427:INFO:Defining folds
2024-07-03 17:01:22,427:INFO:Declaring metric variables
2024-07-03 17:01:22,427:INFO:Importing untrained model
2024-07-03 17:01:22,427:INFO:Declaring custom model
2024-07-03 17:01:22,427:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 17:01:22,427:INFO:Starting cross validation
2024-07-03 17:01:22,428:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:01:26,688:INFO:Calculating mean and std
2024-07-03 17:01:26,688:INFO:Creating metrics dataframe
2024-07-03 17:01:26,689:INFO:Finalizing model
2024-07-03 17:01:27,134:INFO:Uploading results into container
2024-07-03 17:01:27,134:INFO:Uploading model into container now
2024-07-03 17:01:27,134:INFO:_master_model_container: 17
2024-07-03 17:01:27,134:INFO:_display_container: 5
2024-07-03 17:01:27,135:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 17:01:27,135:INFO:create_model() successfully completed......................................
2024-07-03 17:01:27,192:INFO:SubProcess create_model() end ==================================
2024-07-03 17:01:27,192:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8888, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.7896
2024-07-03 17:01:27,192:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.7936
2024-07-03 17:01:27,193:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-07-03 17:01:27,193:INFO:choose_better completed
2024-07-03 17:01:27,199:INFO:_master_model_container: 17
2024-07-03 17:01:27,199:INFO:_display_container: 4
2024-07-03 17:01:27,199:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 17:01:27,200:INFO:tune_model() successfully completed......................................
2024-07-03 17:01:27,261:INFO:Initializing evaluate_model()
2024-07-03 17:01:27,261:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-07-03 17:01:27,269:INFO:Initializing plot_model()
2024-07-03 17:01:27,269:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 17:01:27,269:INFO:Checking exceptions
2024-07-03 17:01:27,272:INFO:Preloading libraries
2024-07-03 17:01:27,282:INFO:Copying training dataset
2024-07-03 17:01:27,282:INFO:Plot type: pipeline
2024-07-03 17:01:27,372:INFO:Visual Rendered Successfully
2024-07-03 17:01:27,446:INFO:plot_model() successfully completed......................................
2024-07-03 17:01:27,455:INFO:Initializing create_model()
2024-07-03 17:01:27,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:01:27,455:INFO:Checking exceptions
2024-07-03 17:01:27,465:INFO:Importing libraries
2024-07-03 17:01:27,465:INFO:Copying training dataset
2024-07-03 17:01:27,469:INFO:Defining folds
2024-07-03 17:01:27,470:INFO:Declaring metric variables
2024-07-03 17:01:27,472:INFO:Importing untrained model
2024-07-03 17:01:27,474:INFO:Random Forest Classifier Imported successfully
2024-07-03 17:01:27,478:INFO:Starting cross validation
2024-07-03 17:01:27,479:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:01:28,691:INFO:Calculating mean and std
2024-07-03 17:01:28,692:INFO:Creating metrics dataframe
2024-07-03 17:01:28,696:INFO:Finalizing model
2024-07-03 17:01:28,864:INFO:Uploading results into container
2024-07-03 17:01:28,864:INFO:Uploading model into container now
2024-07-03 17:01:28,870:INFO:_master_model_container: 18
2024-07-03 17:01:28,870:INFO:_display_container: 5
2024-07-03 17:01:28,870:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 17:01:28,870:INFO:create_model() successfully completed......................................
2024-07-03 17:01:28,934:INFO:Initializing tune_model()
2024-07-03 17:01:28,934:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-03 17:01:28,934:INFO:Checking exceptions
2024-07-03 17:01:28,946:INFO:Copying training dataset
2024-07-03 17:01:28,950:INFO:Checking base model
2024-07-03 17:01:28,950:INFO:Base model : Random Forest Classifier
2024-07-03 17:01:28,953:INFO:Declaring metric variables
2024-07-03 17:01:28,955:INFO:Defining Hyperparameters
2024-07-03 17:01:29,017:INFO:Tuning with n_jobs=-1
2024-07-03 17:01:29,017:INFO:Initializing RandomizedSearchCV
2024-07-03 17:01:35,579:INFO:best_params: {'actual_estimator__n_estimators': 160, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2024-07-03 17:01:35,580:INFO:Hyperparameter search completed
2024-07-03 17:01:35,580:INFO:SubProcess create_model() called ==================================
2024-07-03 17:01:35,580:INFO:Initializing create_model()
2024-07-03 17:01:35,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9b8cccb810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 160, 'min_samples_split': 7, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2024-07-03 17:01:35,580:INFO:Checking exceptions
2024-07-03 17:01:35,580:INFO:Importing libraries
2024-07-03 17:01:35,580:INFO:Copying training dataset
2024-07-03 17:01:35,585:INFO:Defining folds
2024-07-03 17:01:35,585:INFO:Declaring metric variables
2024-07-03 17:01:35,588:INFO:Importing untrained model
2024-07-03 17:01:35,588:INFO:Declaring custom model
2024-07-03 17:01:35,590:INFO:Random Forest Classifier Imported successfully
2024-07-03 17:01:35,595:INFO:Starting cross validation
2024-07-03 17:01:35,595:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:01:38,777:INFO:Calculating mean and std
2024-07-03 17:01:38,778:INFO:Creating metrics dataframe
2024-07-03 17:01:38,784:INFO:Finalizing model
2024-07-03 17:01:39,024:INFO:Uploading results into container
2024-07-03 17:01:39,024:INFO:Uploading model into container now
2024-07-03 17:01:39,025:INFO:_master_model_container: 19
2024-07-03 17:01:39,025:INFO:_display_container: 6
2024-07-03 17:01:39,025:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False)
2024-07-03 17:01:39,025:INFO:create_model() successfully completed......................................
2024-07-03 17:01:39,090:INFO:SubProcess create_model() end ==================================
2024-07-03 17:01:39,090:INFO:choose_better activated
2024-07-03 17:01:39,092:INFO:SubProcess create_model() called ==================================
2024-07-03 17:01:39,092:INFO:Initializing create_model()
2024-07-03 17:01:39,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:01:39,093:INFO:Checking exceptions
2024-07-03 17:01:39,093:INFO:Importing libraries
2024-07-03 17:01:39,094:INFO:Copying training dataset
2024-07-03 17:01:39,099:INFO:Defining folds
2024-07-03 17:01:39,099:INFO:Declaring metric variables
2024-07-03 17:01:39,099:INFO:Importing untrained model
2024-07-03 17:01:39,099:INFO:Declaring custom model
2024-07-03 17:01:39,099:INFO:Random Forest Classifier Imported successfully
2024-07-03 17:01:39,099:INFO:Starting cross validation
2024-07-03 17:01:39,100:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-07-03 17:01:41,663:INFO:Calculating mean and std
2024-07-03 17:01:41,663:INFO:Creating metrics dataframe
2024-07-03 17:01:41,665:INFO:Finalizing model
2024-07-03 17:01:41,838:INFO:Uploading results into container
2024-07-03 17:01:41,838:INFO:Uploading model into container now
2024-07-03 17:01:41,838:INFO:_master_model_container: 20
2024-07-03 17:01:41,838:INFO:_display_container: 7
2024-07-03 17:01:41,839:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False)
2024-07-03 17:01:41,839:INFO:create_model() successfully completed......................................
2024-07-03 17:01:41,902:INFO:SubProcess create_model() end ==================================
2024-07-03 17:01:41,902:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8888, verbose=0,
                       warm_start=False) result for Accuracy is 0.79
2024-07-03 17:01:41,902:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False) result for Accuracy is 0.7936
2024-07-03 17:01:41,903:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False) is best model
2024-07-03 17:01:41,903:INFO:choose_better completed
2024-07-03 17:01:41,910:INFO:_master_model_container: 20
2024-07-03 17:01:41,910:INFO:_display_container: 6
2024-07-03 17:01:41,910:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False)
2024-07-03 17:01:41,910:INFO:tune_model() successfully completed......................................
2024-07-03 17:01:41,979:INFO:Initializing evaluate_model()
2024-07-03 17:01:41,980:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-07-03 17:01:41,990:INFO:Initializing plot_model()
2024-07-03 17:01:41,990:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-07-03 17:01:41,990:INFO:Checking exceptions
2024-07-03 17:01:42,018:INFO:Preloading libraries
2024-07-03 17:01:42,028:INFO:Copying training dataset
2024-07-03 17:01:42,028:INFO:Plot type: pipeline
2024-07-03 17:01:42,095:INFO:Visual Rendered Successfully
2024-07-03 17:01:42,162:INFO:plot_model() successfully completed......................................
2024-07-03 17:01:42,168:INFO:Initializing predict_model()
2024-07-03 17:01:42,168:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9b8c15bec0>)
2024-07-03 17:01:42,168:INFO:Checking exceptions
2024-07-03 17:01:42,168:INFO:Preloading libraries
2024-07-03 17:01:42,328:INFO:Initializing predict_model()
2024-07-03 17:01:42,329:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=160, n_jobs=-1, oob_score=False,
                       random_state=8888, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9b8c15b6a0>)
2024-07-03 17:01:42,329:INFO:Checking exceptions
2024-07-03 17:01:42,329:INFO:Preloading libraries
2024-07-03 17:01:42,525:INFO:Initializing finalize_model()
2024-07-03 17:01:42,525:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-07-03 17:01:42,525:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-03 17:01:42,530:INFO:Initializing create_model()
2024-07-03 17:01:42,530:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.001, loss='log_loss', max_depth=9,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=160, n_iter_no_change=None,
                           random_state=8888, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-07-03 17:01:42,530:INFO:Checking exceptions
2024-07-03 17:01:42,532:INFO:Importing libraries
2024-07-03 17:01:42,532:INFO:Copying training dataset
2024-07-03 17:01:42,532:INFO:Defining folds
2024-07-03 17:01:42,533:INFO:Declaring metric variables
2024-07-03 17:01:42,533:INFO:Importing untrained model
2024-07-03 17:01:42,533:INFO:Declaring custom model
2024-07-03 17:01:42,533:INFO:Gradient Boosting Classifier Imported successfully
2024-07-03 17:01:42,534:INFO:Cross validation set to False
2024-07-03 17:01:42,534:INFO:Fitting Model
2024-07-03 17:01:44,076:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-07-03 17:01:44,076:INFO:create_model() successfully completed......................................
2024-07-03 17:01:44,136:INFO:_master_model_container: 20
2024-07-03 17:01:44,136:INFO:_display_container: 8
2024-07-03 17:01:44,139:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-07-03 17:01:44,139:INFO:finalize_model() successfully completed......................................
2024-07-03 17:01:44,207:INFO:Initializing predict_model()
2024-07-03 17:01:44,207:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9b8c15ba60>)
2024-07-03 17:01:44,207:INFO:Checking exceptions
2024-07-03 17:01:44,207:INFO:Preloading libraries
2024-07-03 17:01:44,381:INFO:Initializing predict_model()
2024-07-03 17:01:44,381:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9b950af6d0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RoomService', 'FoodCourt',
                                             'ShoppingMall', 'Spa', 'VRDeck'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.001,
                                            loss='log_loss', max_depth=9,
                                            max_features='log2',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.2,
                                            min_samples_leaf=3,
                                            min_samples_split=7,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=160,
                                            n_iter_no_change=None,
                                            random_state=8888, subsample=0.7,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9b8c159940>)
2024-07-03 17:01:44,381:INFO:Checking exceptions
2024-07-03 17:01:44,381:INFO:Preloading libraries
2024-07-03 17:01:44,383:INFO:Set up data.
2024-07-03 17:01:44,393:INFO:Set up index.
